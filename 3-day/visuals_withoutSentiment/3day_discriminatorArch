digraph {
	graph [size="12.45,12.45"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1977870849664 [label="
 ()" fillcolor=darkolivegreen1]
	1977870825744 [label=MeanBackward0]
	1977870826752 -> 1977870825744
	1977870826752 [label=AddmmBackward0]
	1977870826608 -> 1977870826752
	1979393307968 [label="dense_layer14.bias
 (1)" fillcolor=lightblue]
	1979393307968 -> 1977870826608
	1977870826608 [label=AccumulateGrad]
	1977870826464 -> 1977870826752
	1977870826464 [label=ReluBackward0]
	1977870825792 -> 1977870826464
	1977870825792 [label=MmBackward0]
	1977870826368 -> 1977870825792
	1977870826368 [label=LeakyReluBackward0]
	1977870826224 -> 1977870826368
	1977870826224 [label=MmBackward0]
	1977870826128 -> 1977870826224
	1977870826128 [label=ReshapeAliasBackward0]
	1977870825984 -> 1977870826128
	1977870825984 [label=LeakyReluBackward0]
	1977870825888 -> 1977870825984
	1977870825888 [label=ConvolutionBackward0]
	1977870825648 -> 1977870825888
	1977870825648 [label=LeakyReluBackward0]
	1977870825456 -> 1977870825648
	1977870825456 [label=ConvolutionBackward0]
	1977870825360 -> 1977870825456
	1977870825360 [label=LeakyReluBackward0]
	1977870825072 -> 1977870825360
	1977870825072 [label=ConvolutionBackward0]
	1977870824928 -> 1977870825072
	1977870824928 [label=ConvolutionBackward0]
	1977870826848 -> 1977870824928
	1979393308848 [label="conv_layer0.weight
 (32, 4, 5)" fillcolor=lightblue]
	1979393308848 -> 1977870826848
	1977870826848 [label=AccumulateGrad]
	1977870826800 -> 1977870824928
	1979393308768 [label="conv_layer0.bias
 (32)" fillcolor=lightblue]
	1979393308768 -> 1977870826800
	1977870826800 [label=AccumulateGrad]
	1977870825024 -> 1977870825072
	1979393308688 [label="conv_layer1.weight
 (64, 32, 5)" fillcolor=lightblue]
	1979393308688 -> 1977870825024
	1977870825024 [label=AccumulateGrad]
	1977870825168 -> 1977870825072
	1979393308608 [label="conv_layer1.bias
 (64)" fillcolor=lightblue]
	1979393308608 -> 1977870825168
	1977870825168 [label=AccumulateGrad]
	1977870825408 -> 1977870825456
	1979393308528 [label="conv_layer3.weight
 (128, 64, 5)" fillcolor=lightblue]
	1979393308528 -> 1977870825408
	1977870825408 [label=AccumulateGrad]
	1977870825552 -> 1977870825456
	1979393308448 [label="conv_layer3.bias
 (128)" fillcolor=lightblue]
	1979393308448 -> 1977870825552
	1977870825552 [label=AccumulateGrad]
	1977870825840 -> 1977870825888
	1979393308368 [label="conv_layer6.weight
 (256, 128, 5)" fillcolor=lightblue]
	1979393308368 -> 1977870825840
	1977870825840 [label=AccumulateGrad]
	1977870826080 -> 1977870825888
	1979393308288 [label="conv_layer6.bias
 (256)" fillcolor=lightblue]
	1979393308288 -> 1977870826080
	1977870826080 [label=AccumulateGrad]
	1977870826176 -> 1977870826224
	1977870826176 [label=TBackward0]
	1977870825600 -> 1977870826176
	1979393308208 [label="dense_layer9.weight
 (256, 256)" fillcolor=lightblue]
	1979393308208 -> 1977870825600
	1977870825600 [label=AccumulateGrad]
	1977870826416 -> 1977870825792
	1977870826416 [label=TBackward0]
	1977870825936 -> 1977870826416
	1979393308128 [label="dense_layer12.weight
 (256, 256)" fillcolor=lightblue]
	1979393308128 -> 1977870825936
	1977870825936 [label=AccumulateGrad]
	1977870826704 -> 1977870826752
	1977870826704 [label=TBackward0]
	1977870826320 -> 1977870826704
	1979393308048 [label="dense_layer14.weight
 (1, 256)" fillcolor=lightblue]
	1979393308048 -> 1977870826320
	1977870826320 [label=AccumulateGrad]
	1977870825744 -> 1977870849664
}
