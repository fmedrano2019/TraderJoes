{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6691ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import math\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4843048e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2492, 50)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "data = pd.read_csv('fulldata.csv', index_col = 'Date')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11c1c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read over ARIMA predictions\n",
    "%store -r full_arima_predictions\n",
    "\n",
    "# Increment Indices\n",
    "arima_predictions_list = full_arima_predictions.tolist()\n",
    "arima_predictions_list.append(arima_predictions_list.pop(0))\n",
    "\n",
    "# Append ARIMA predictions to dataframe\n",
    "data['arima'] = arima_predictions_list\n",
    "\n",
    "# Append close to dataframe\n",
    "data['y'] = data['close_aapl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c245f4d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_aapl</th>\n",
       "      <th>high_aapl</th>\n",
       "      <th>low_aapl</th>\n",
       "      <th>close_aapl</th>\n",
       "      <th>volume_aapl</th>\n",
       "      <th>open_googl</th>\n",
       "      <th>high_googl</th>\n",
       "      <th>low_googl</th>\n",
       "      <th>close_googl</th>\n",
       "      <th>volume_googl</th>\n",
       "      <th>...</th>\n",
       "      <th>momentum</th>\n",
       "      <th>rsi_5</th>\n",
       "      <th>rsi_15</th>\n",
       "      <th>rsi_ratio</th>\n",
       "      <th>tr</th>\n",
       "      <th>atr</th>\n",
       "      <th>roc</th>\n",
       "      <th>vader_polarity</th>\n",
       "      <th>arima</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5/9/2013</th>\n",
       "      <td>16.421786</td>\n",
       "      <td>16.535714</td>\n",
       "      <td>16.270714</td>\n",
       "      <td>16.313214</td>\n",
       "      <td>398749904</td>\n",
       "      <td>21.792098</td>\n",
       "      <td>22.012812</td>\n",
       "      <td>21.726785</td>\n",
       "      <td>21.808114</td>\n",
       "      <td>87945080</td>\n",
       "      <td>...</td>\n",
       "      <td>15.313214</td>\n",
       "      <td>66.171526</td>\n",
       "      <td>64.804242</td>\n",
       "      <td>1.021099</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.419158</td>\n",
       "      <td>0.165081</td>\n",
       "      <td>0.131248</td>\n",
       "      <td>16.313212</td>\n",
       "      <td>16.313214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/10/2013</th>\n",
       "      <td>16.356071</td>\n",
       "      <td>16.418214</td>\n",
       "      <td>16.088572</td>\n",
       "      <td>16.177500</td>\n",
       "      <td>334849928</td>\n",
       "      <td>21.903956</td>\n",
       "      <td>22.034833</td>\n",
       "      <td>21.825130</td>\n",
       "      <td>22.027075</td>\n",
       "      <td>75955060</td>\n",
       "      <td>...</td>\n",
       "      <td>15.177500</td>\n",
       "      <td>57.572386</td>\n",
       "      <td>61.822287</td>\n",
       "      <td>0.931256</td>\n",
       "      <td>0.329643</td>\n",
       "      <td>0.412934</td>\n",
       "      <td>0.159885</td>\n",
       "      <td>0.146785</td>\n",
       "      <td>16.191360</td>\n",
       "      <td>16.177500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/13/2013</th>\n",
       "      <td>16.125357</td>\n",
       "      <td>16.353572</td>\n",
       "      <td>16.125000</td>\n",
       "      <td>16.240714</td>\n",
       "      <td>317109240</td>\n",
       "      <td>21.993543</td>\n",
       "      <td>22.083127</td>\n",
       "      <td>21.855684</td>\n",
       "      <td>21.959510</td>\n",
       "      <td>57893080</td>\n",
       "      <td>...</td>\n",
       "      <td>15.240714</td>\n",
       "      <td>60.556778</td>\n",
       "      <td>62.679325</td>\n",
       "      <td>0.966136</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.404487</td>\n",
       "      <td>0.140643</td>\n",
       "      <td>0.063889</td>\n",
       "      <td>16.231099</td>\n",
       "      <td>16.240714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/14/2013</th>\n",
       "      <td>16.208928</td>\n",
       "      <td>16.257143</td>\n",
       "      <td>15.791071</td>\n",
       "      <td>15.852143</td>\n",
       "      <td>447115760</td>\n",
       "      <td>21.958759</td>\n",
       "      <td>22.238780</td>\n",
       "      <td>21.949751</td>\n",
       "      <td>22.198992</td>\n",
       "      <td>63190600</td>\n",
       "      <td>...</td>\n",
       "      <td>14.852143</td>\n",
       "      <td>39.310535</td>\n",
       "      <td>54.606048</td>\n",
       "      <td>0.719893</td>\n",
       "      <td>0.466071</td>\n",
       "      <td>0.379742</td>\n",
       "      <td>0.092901</td>\n",
       "      <td>0.049072</td>\n",
       "      <td>15.893159</td>\n",
       "      <td>15.852143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/15/2013</th>\n",
       "      <td>15.684286</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.084286</td>\n",
       "      <td>15.316071</td>\n",
       "      <td>741612360</td>\n",
       "      <td>22.409198</td>\n",
       "      <td>22.931701</td>\n",
       "      <td>22.372159</td>\n",
       "      <td>22.919439</td>\n",
       "      <td>159658020</td>\n",
       "      <td>...</td>\n",
       "      <td>14.316071</td>\n",
       "      <td>24.492002</td>\n",
       "      <td>45.872465</td>\n",
       "      <td>0.533915</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.412962</td>\n",
       "      <td>0.057682</td>\n",
       "      <td>0.011088</td>\n",
       "      <td>15.359893</td>\n",
       "      <td>15.316071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/27/2023</th>\n",
       "      <td>159.940000</td>\n",
       "      <td>160.770000</td>\n",
       "      <td>157.870000</td>\n",
       "      <td>158.280000</td>\n",
       "      <td>52390266</td>\n",
       "      <td>104.615000</td>\n",
       "      <td>104.760000</td>\n",
       "      <td>101.927300</td>\n",
       "      <td>102.460000</td>\n",
       "      <td>31120864</td>\n",
       "      <td>...</td>\n",
       "      <td>157.280000</td>\n",
       "      <td>58.221301</td>\n",
       "      <td>60.577495</td>\n",
       "      <td>0.961104</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>3.498250</td>\n",
       "      <td>0.028928</td>\n",
       "      <td>0.154446</td>\n",
       "      <td>158.428987</td>\n",
       "      <td>158.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/28/2023</th>\n",
       "      <td>157.970000</td>\n",
       "      <td>158.490000</td>\n",
       "      <td>155.980000</td>\n",
       "      <td>157.650000</td>\n",
       "      <td>45992152</td>\n",
       "      <td>102.440000</td>\n",
       "      <td>102.450000</td>\n",
       "      <td>99.740000</td>\n",
       "      <td>101.030000</td>\n",
       "      <td>32057865</td>\n",
       "      <td>...</td>\n",
       "      <td>156.650000</td>\n",
       "      <td>53.185052</td>\n",
       "      <td>59.113390</td>\n",
       "      <td>0.899712</td>\n",
       "      <td>2.510000</td>\n",
       "      <td>3.543964</td>\n",
       "      <td>0.039908</td>\n",
       "      <td>0.171291</td>\n",
       "      <td>157.627915</td>\n",
       "      <td>157.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/29/2023</th>\n",
       "      <td>159.370000</td>\n",
       "      <td>161.050000</td>\n",
       "      <td>159.350000</td>\n",
       "      <td>160.770000</td>\n",
       "      <td>51305691</td>\n",
       "      <td>102.280000</td>\n",
       "      <td>102.490000</td>\n",
       "      <td>100.650000</td>\n",
       "      <td>101.390000</td>\n",
       "      <td>28779572</td>\n",
       "      <td>...</td>\n",
       "      <td>159.770000</td>\n",
       "      <td>69.511345</td>\n",
       "      <td>63.760854</td>\n",
       "      <td>1.090188</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.478964</td>\n",
       "      <td>0.051678</td>\n",
       "      <td>0.149073</td>\n",
       "      <td>160.714492</td>\n",
       "      <td>160.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/30/2023</th>\n",
       "      <td>161.530000</td>\n",
       "      <td>162.470000</td>\n",
       "      <td>161.271000</td>\n",
       "      <td>162.360000</td>\n",
       "      <td>49501689</td>\n",
       "      <td>100.910000</td>\n",
       "      <td>101.155000</td>\n",
       "      <td>99.780000</td>\n",
       "      <td>100.890000</td>\n",
       "      <td>33086183</td>\n",
       "      <td>...</td>\n",
       "      <td>161.360000</td>\n",
       "      <td>75.053359</td>\n",
       "      <td>65.878571</td>\n",
       "      <td>1.139268</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>3.362507</td>\n",
       "      <td>0.078159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>162.273604</td>\n",
       "      <td>162.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/31/2023</th>\n",
       "      <td>162.440000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>161.910000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>68749792</td>\n",
       "      <td>101.300000</td>\n",
       "      <td>103.890000</td>\n",
       "      <td>101.040000</td>\n",
       "      <td>103.730000</td>\n",
       "      <td>36863369</td>\n",
       "      <td>...</td>\n",
       "      <td>163.900000</td>\n",
       "      <td>81.696912</td>\n",
       "      <td>68.981102</td>\n",
       "      <td>1.184338</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>3.194650</td>\n",
       "      <td>0.110438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2492 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            open_aapl   high_aapl    low_aapl  close_aapl  volume_aapl  \\\n",
       "Date                                                                     \n",
       "5/9/2013    16.421786   16.535714   16.270714   16.313214    398749904   \n",
       "5/10/2013   16.356071   16.418214   16.088572   16.177500    334849928   \n",
       "5/13/2013   16.125357   16.353572   16.125000   16.240714    317109240   \n",
       "5/14/2013   16.208928   16.257143   15.791071   15.852143    447115760   \n",
       "5/15/2013   15.684286   15.750000   15.084286   15.316071    741612360   \n",
       "...               ...         ...         ...         ...          ...   \n",
       "3/27/2023  159.940000  160.770000  157.870000  158.280000     52390266   \n",
       "3/28/2023  157.970000  158.490000  155.980000  157.650000     45992152   \n",
       "3/29/2023  159.370000  161.050000  159.350000  160.770000     51305691   \n",
       "3/30/2023  161.530000  162.470000  161.271000  162.360000     49501689   \n",
       "3/31/2023  162.440000  165.000000  161.910000  164.900000     68749792   \n",
       "\n",
       "           open_googl  high_googl   low_googl  close_googl  volume_googl  ...  \\\n",
       "Date                                                                      ...   \n",
       "5/9/2013    21.792098   22.012812   21.726785    21.808114      87945080  ...   \n",
       "5/10/2013   21.903956   22.034833   21.825130    22.027075      75955060  ...   \n",
       "5/13/2013   21.993543   22.083127   21.855684    21.959510      57893080  ...   \n",
       "5/14/2013   21.958759   22.238780   21.949751    22.198992      63190600  ...   \n",
       "5/15/2013   22.409198   22.931701   22.372159    22.919439     159658020  ...   \n",
       "...               ...         ...         ...          ...           ...  ...   \n",
       "3/27/2023  104.615000  104.760000  101.927300   102.460000      31120864  ...   \n",
       "3/28/2023  102.440000  102.450000   99.740000   101.030000      32057865  ...   \n",
       "3/29/2023  102.280000  102.490000  100.650000   101.390000      28779572  ...   \n",
       "3/30/2023  100.910000  101.155000   99.780000   100.890000      33086183  ...   \n",
       "3/31/2023  101.300000  103.890000  101.040000   103.730000      36863369  ...   \n",
       "\n",
       "             momentum      rsi_5     rsi_15  rsi_ratio        tr       atr  \\\n",
       "Date                                                                         \n",
       "5/9/2013    15.313214  66.171526  64.804242   1.021099  0.295000  0.419158   \n",
       "5/10/2013   15.177500  57.572386  61.822287   0.931256  0.329643  0.412934   \n",
       "5/13/2013   15.240714  60.556778  62.679325   0.966136  0.228572  0.404487   \n",
       "5/14/2013   14.852143  39.310535  54.606048   0.719893  0.466071  0.379742   \n",
       "5/15/2013   14.316071  24.492002  45.872465   0.533915  0.767857  0.412962   \n",
       "...               ...        ...        ...        ...       ...       ...   \n",
       "3/27/2023  157.280000  58.221301  60.577495   0.961104  2.900000  3.498250   \n",
       "3/28/2023  156.650000  53.185052  59.113390   0.899712  2.510000  3.543964   \n",
       "3/29/2023  159.770000  69.511345  63.760854   1.090188  3.400000  3.478964   \n",
       "3/30/2023  161.360000  75.053359  65.878571   1.139268  1.700000  3.362507   \n",
       "3/31/2023  163.900000  81.696912  68.981102   1.184338  3.090000  3.194650   \n",
       "\n",
       "                roc  vader_polarity       arima           y  \n",
       "Date                                                         \n",
       "5/9/2013   0.165081        0.131248   16.313212   16.313214  \n",
       "5/10/2013  0.159885        0.146785   16.191360   16.177500  \n",
       "5/13/2013  0.140643        0.063889   16.231099   16.240714  \n",
       "5/14/2013  0.092901        0.049072   15.893159   15.852143  \n",
       "5/15/2013  0.057682        0.011088   15.359893   15.316071  \n",
       "...             ...             ...         ...         ...  \n",
       "3/27/2023  0.028928        0.154446  158.428987  158.280000  \n",
       "3/28/2023  0.039908        0.171291  157.627915  157.650000  \n",
       "3/29/2023  0.051678        0.149073  160.714492  160.770000  \n",
       "3/30/2023  0.078159        0.000000  162.273604  162.360000  \n",
       "3/31/2023  0.110438        0.000000    0.000000  164.900000  \n",
       "\n",
       "[2492 rows x 52 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data preview\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "221080f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2492, 52)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5af3a696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1994"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data to numpy array\n",
    "dataset = data.values\n",
    "\n",
    "# Get training set size 80:20 split\n",
    "training_data_len = math.ceil(len(dataset) * 0.8)\n",
    "training_data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6742431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler for data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7b9ff87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1994, 51)\n",
      "y_train shape: (1994,)\n",
      "\n",
      "x_test shape: (498, 51)\n",
      "y_test shape: (498,)\n"
     ]
    }
   ],
   "source": [
    "# Create training dataset\n",
    "train_data = dataset[0:training_data_len,:]\n",
    "\n",
    "# Split to x_train and y_train\n",
    "x_train = train_data[:,:51]\n",
    "y_train = train_data[:,51]\n",
    "\n",
    "# Create test dataset\n",
    "test_data = dataset[training_data_len:,:]\n",
    "\n",
    "# Split to x_test and y_test\n",
    "x_test = test_data[:,:51]\n",
    "y_test = test_data[:,51]\n",
    "\n",
    "# Show shapes of sets\n",
    "print('x_train shape: ' + str(x_train.shape))\n",
    "print('y_train shape: ' + str(y_train.shape))\n",
    "print()\n",
    "print('x_test shape: ' + str(x_test.shape))\n",
    "print('y_test shape: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66a8e2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01885966, 0.01712881, 0.01868894, ..., 0.78375968, 0.4121214 ,\n",
       "        0.01733483],\n",
       "       [0.01835269, 0.01623046, 0.01726017, ..., 0.77392832, 0.4330199 ,\n",
       "        0.01639152],\n",
       "       [0.01657281, 0.01573623, 0.01754592, ..., 0.73751712, 0.32151841,\n",
       "        0.01669916],\n",
       "       ...,\n",
       "       [0.86290998, 0.86872551, 0.87268769, ..., 0.50650193, 0.50449132,\n",
       "        0.87993629],\n",
       "       [0.88697981, 0.88761008, 0.89920129, ..., 0.55632543, 0.40436208,\n",
       "        0.8986756 ],\n",
       "       [0.8935373 , 0.90787084, 0.90665333, ..., 0.66708059, 0.60343157,\n",
       "        0.91915718]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert training and testing sets to numpy arrays\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Scale data\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "y_train = scaler.fit_transform(y_train.reshape(-1,1))\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "y_test = scaler.fit_transform(y_test.reshape(-1,1))\n",
    "\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ede46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01885966 0.01712881 0.01868894 ... 0.78375968 0.4121214  0.01733483]\n",
      " [0.01835269 0.01623046 0.01726017 ... 0.77392832 0.4330199  0.01639152]\n",
      " [0.01657281 0.01573623 0.01754592 ... 0.73751712 0.32151841 0.01669916]\n",
      " ...\n",
      " [0.86290998 0.86872551 0.87268769 ... 0.50650193 0.50449132 0.87993629]\n",
      " [0.88697981 0.88761008 0.89920129 ... 0.55632543 0.40436208 0.8986756 ]\n",
      " [0.8935373  0.90787084 0.90665333 ... 0.66708059 0.60343157 0.91915718]]\n",
      "[[0.15739028 0.14082333 0.14735361 ... 0.73666547 0.28879025 0.72379143]\n",
      " [0.15604506 0.17186964 0.17021277 ... 0.72425698 0.47709323 0.73813039]\n",
      " [0.19808307 0.17770154 0.16537718 ... 0.68942875 0.50414104 0.72892185]\n",
      " ...\n",
      " [0.60887843 0.6245283  0.65236504 ... 0.61482211 0.4685386  0.88487621]\n",
      " [0.64519926 0.64888508 0.68614384 ... 0.69149945 0.12936266 0.8934605 ]\n",
      " [0.66050109 0.6922813  0.69737999 ... 0.7849625  0.12936266 0.        ]]\n",
      "[[0.01742606]\n",
      " [0.0163748 ]\n",
      " [0.01686447]\n",
      " ...\n",
      " [0.88179379]\n",
      " [0.90084931]\n",
      " [0.92126041]]\n",
      "[[0.14297772]\n",
      " [0.19682647]\n",
      " [0.1563133 ]\n",
      " [0.1980081 ]\n",
      " [0.19226874]\n",
      " [0.20374747]\n",
      " [0.17454423]\n",
      " [0.18112762]\n",
      " [0.15479406]\n",
      " [0.19496962]\n",
      " [0.20172181]\n",
      " [0.19615125]\n",
      " [0.18247806]\n",
      " [0.18079001]\n",
      " [0.14669142]\n",
      " [0.16492235]\n",
      " [0.08575287]\n",
      " [0.08997299]\n",
      " [0.11765699]\n",
      " [0.12559082]\n",
      " [0.06887238]\n",
      " [0.05300473]\n",
      " [0.        ]\n",
      " [0.03713707]\n",
      " [0.07900068]\n",
      " [0.0590817 ]\n",
      " [0.03511141]\n",
      " [0.03241053]\n",
      " [0.07663741]\n",
      " [0.04490209]\n",
      " [0.07309251]\n",
      " [0.06971641]\n",
      " [0.06887238]\n",
      " [0.04237002]\n",
      " [0.03106009]\n",
      " [0.02548953]\n",
      " [0.03865631]\n",
      " [0.01299797]\n",
      " [0.05266712]\n",
      " [0.05283592]\n",
      " [0.06701553]\n",
      " [0.07359892]\n",
      " [0.05638082]\n",
      " [0.07731263]\n",
      " [0.13014855]\n",
      " [0.11596894]\n",
      " [0.12457799]\n",
      " [0.15226199]\n",
      " [0.12981094]\n",
      " [0.16087103]\n",
      " [0.18923025]\n",
      " [0.18450371]\n",
      " [0.17960837]\n",
      " [0.17454423]\n",
      " [0.20273464]\n",
      " [0.22889939]\n",
      " [0.2395341 ]\n",
      " [0.24476705]\n",
      " [0.29017556]\n",
      " [0.32494936]\n",
      " [0.3679946 ]\n",
      " [0.34554355]\n",
      " [0.37711006]\n",
      " [0.36681296]\n",
      " [0.38605672]\n",
      " [0.44530722]\n",
      " [0.4339973 ]\n",
      " [0.39871708]\n",
      " [0.33220797]\n",
      " [0.39466577]\n",
      " [0.3820054 ]\n",
      " [0.40563808]\n",
      " [0.43534774]\n",
      " [0.44260635]\n",
      " [0.40513167]\n",
      " [0.3749156 ]\n",
      " [0.38605672]\n",
      " [0.38977043]\n",
      " [0.38403106]\n",
      " [0.41509115]\n",
      " [0.40817016]\n",
      " [0.41002701]\n",
      " [0.39449696]\n",
      " [0.39365294]\n",
      " [0.3853815 ]\n",
      " [0.38977043]\n",
      " [0.4409183 ]\n",
      " [0.4444632 ]\n",
      " [0.47856178]\n",
      " [0.46286293]\n",
      " [0.39821067]\n",
      " [0.40395003]\n",
      " [0.42910196]\n",
      " [0.4547603 ]\n",
      " [0.45324105]\n",
      " [0.43197164]\n",
      " [0.41812964]\n",
      " [0.43602296]\n",
      " [0.51232275]\n",
      " [0.49054693]\n",
      " [0.50202566]\n",
      " [0.52126941]\n",
      " [0.53224173]\n",
      " [0.57258609]\n",
      " [0.54591492]\n",
      " [0.52835922]\n",
      " [0.44226874]\n",
      " [0.45205942]\n",
      " [0.42792032]\n",
      " [0.44328157]\n",
      " [0.43923025]\n",
      " [0.39314652]\n",
      " [0.34047941]\n",
      " [0.34875084]\n",
      " [0.38960162]\n",
      " [0.4061445 ]\n",
      " [0.40766374]\n",
      " [0.38149899]\n",
      " [0.32309251]\n",
      " [0.33862255]\n",
      " [0.31617151]\n",
      " [0.33558406]\n",
      " [0.27633356]\n",
      " [0.30958812]\n",
      " [0.32461175]\n",
      " [0.34638758]\n",
      " [0.33980419]\n",
      " [0.33828494]\n",
      " [0.31634031]\n",
      " [0.30621202]\n",
      " [0.3543214 ]\n",
      " [0.37255233]\n",
      " [0.40141796]\n",
      " [0.43872384]\n",
      " [0.44716408]\n",
      " [0.45087779]\n",
      " [0.4375422 ]\n",
      " [0.43669818]\n",
      " [0.44817691]\n",
      " [0.44024308]\n",
      " [0.50303849]\n",
      " [0.45627954]\n",
      " [0.44209993]\n",
      " [0.45999325]\n",
      " [0.48480756]\n",
      " [0.4758609 ]\n",
      " [0.48126266]\n",
      " [0.46708305]\n",
      " [0.47332883]\n",
      " [0.42454423]\n",
      " [0.4237002 ]\n",
      " [0.45948683]\n",
      " [0.45965564]\n",
      " [0.47653612]\n",
      " [0.51856853]\n",
      " [0.59250506]\n",
      " [0.63774477]\n",
      " [0.6456786 ]\n",
      " [0.65226199]\n",
      " [0.66120864]\n",
      " [0.57461175]\n",
      " [0.63251182]\n",
      " [0.71792708]\n",
      " [0.70898042]\n",
      " [0.69193113]\n",
      " [0.65952059]\n",
      " [0.71826469]\n",
      " [0.81718433]\n",
      " [0.88301823]\n",
      " [0.87424038]\n",
      " [0.95678596]\n",
      " [0.89415935]\n",
      " [0.87035787]\n",
      " [0.95425388]\n",
      " [0.83541526]\n",
      " [0.81650912]\n",
      " [0.79304524]\n",
      " [0.84773801]\n",
      " [0.8924713 ]\n",
      " [0.90327481]\n",
      " [0.97164078]\n",
      " [0.95408508]\n",
      " [0.95560432]\n",
      " [0.93568535]\n",
      " [0.92505064]\n",
      " [1.        ]\n",
      " [0.96100608]\n",
      " [0.88031735]\n",
      " [0.83102633]\n",
      " [0.83389602]\n",
      " [0.83423363]\n",
      " [0.88301823]\n",
      " [0.89061445]\n",
      " [0.83423363]\n",
      " [0.84908845]\n",
      " [0.79388926]\n",
      " [0.73362593]\n",
      " [0.70459149]\n",
      " [0.66914247]\n",
      " [0.65580689]\n",
      " [0.62474679]\n",
      " [0.62322755]\n",
      " [0.61529372]\n",
      " [0.80283592]\n",
      " [0.87795409]\n",
      " [0.8750844 ]\n",
      " [0.8958474 ]\n",
      " [0.84621877]\n",
      " [0.83760972]\n",
      " [0.82528697]\n",
      " [0.87879811]\n",
      " [0.90327481]\n",
      " [0.83305199]\n",
      " [0.7743079 ]\n",
      " [0.77835922]\n",
      " [0.84436192]\n",
      " [0.8403106 ]\n",
      " [0.77835922]\n",
      " [0.75168805]\n",
      " [0.7013842 ]\n",
      " [0.62964213]\n",
      " [0.67471303]\n",
      " [0.71033086]\n",
      " [0.71488859]\n",
      " [0.68247806]\n",
      " [0.73919649]\n",
      " [0.73362593]\n",
      " [0.68197164]\n",
      " [0.61664416]\n",
      " [0.58524646]\n",
      " [0.67825793]\n",
      " [0.60347738]\n",
      " [0.53950034]\n",
      " [0.47012154]\n",
      " [0.54557731]\n",
      " [0.6215395 ]\n",
      " [0.6389264 ]\n",
      " [0.69564483]\n",
      " [0.71927752]\n",
      " [0.77734639]\n",
      " [0.80081026]\n",
      " [0.86596894]\n",
      " [0.87694126]\n",
      " [0.89179608]\n",
      " [0.94851452]\n",
      " [0.92842674]\n",
      " [0.8750844 ]\n",
      " [0.87002026]\n",
      " [0.93973666]\n",
      " [0.88268062]\n",
      " [0.82815665]\n",
      " [0.8333896 ]\n",
      " [0.7987846 ]\n",
      " [0.7255233 ]\n",
      " [0.75776502]\n",
      " [0.80401756]\n",
      " [0.71775827]\n",
      " [0.71404456]\n",
      " [0.7533761 ]\n",
      " [0.75050641]\n",
      " [0.73683322]\n",
      " [0.65867657]\n",
      " [0.6770763 ]\n",
      " [0.57444294]\n",
      " [0.57056043]\n",
      " [0.68990547]\n",
      " [0.58879136]\n",
      " [0.59402431]\n",
      " [0.61968265]\n",
      " [0.73008103]\n",
      " [0.57393653]\n",
      " [0.58254558]\n",
      " [0.49442944]\n",
      " [0.53578663]\n",
      " [0.40057394]\n",
      " [0.33406482]\n",
      " [0.41087103]\n",
      " [0.38436867]\n",
      " [0.44682647]\n",
      " [0.30469278]\n",
      " [0.24611749]\n",
      " [0.2501688 ]\n",
      " [0.34334909]\n",
      " [0.29692775]\n",
      " [0.29962863]\n",
      " [0.35465901]\n",
      " [0.45357866]\n",
      " [0.44007427]\n",
      " [0.43787981]\n",
      " [0.48008103]\n",
      " [0.38166779]\n",
      " [0.39449696]\n",
      " [0.43787981]\n",
      " [0.42521945]\n",
      " [0.33541526]\n",
      " [0.24240378]\n",
      " [0.15378123]\n",
      " [0.16863606]\n",
      " [0.21370695]\n",
      " [0.12305874]\n",
      " [0.14837947]\n",
      " [0.22113437]\n",
      " [0.21235652]\n",
      " [0.26164754]\n",
      " [0.31887238]\n",
      " [0.31887238]\n",
      " [0.24763673]\n",
      " [0.2778528 ]\n",
      " [0.23548278]\n",
      " [0.27278866]\n",
      " [0.31718433]\n",
      " [0.3401418 ]\n",
      " [0.39804186]\n",
      " [0.4096894 ]\n",
      " [0.37305874]\n",
      " [0.38977043]\n",
      " [0.38352465]\n",
      " [0.43382849]\n",
      " [0.46252532]\n",
      " [0.41019581]\n",
      " [0.47653612]\n",
      " [0.51097232]\n",
      " [0.54996624]\n",
      " [0.52869683]\n",
      " [0.50945307]\n",
      " [0.48666442]\n",
      " [0.57427414]\n",
      " [0.58372721]\n",
      " [0.67083052]\n",
      " [0.65395003]\n",
      " [0.6286293 ]\n",
      " [0.73193788]\n",
      " [0.72653612]\n",
      " [0.7187711 ]\n",
      " [0.71066847]\n",
      " [0.71151249]\n",
      " [0.78443619]\n",
      " [0.77177583]\n",
      " [0.83271438]\n",
      " [0.85111411]\n",
      " [0.84841323]\n",
      " [0.87407157]\n",
      " [0.86731938]\n",
      " [0.8229237 ]\n",
      " [0.75624578]\n",
      " [0.75050641]\n",
      " [0.75557056]\n",
      " [0.79777178]\n",
      " [0.68956786]\n",
      " [0.65175557]\n",
      " [0.61006077]\n",
      " [0.58153275]\n",
      " [0.59402431]\n",
      " [0.55773126]\n",
      " [0.53612424]\n",
      " [0.56026334]\n",
      " [0.53494261]\n",
      " [0.58406482]\n",
      " [0.68636057]\n",
      " [0.5244767 ]\n",
      " [0.54929102]\n",
      " [0.49966239]\n",
      " [0.47147198]\n",
      " [0.53528022]\n",
      " [0.57613099]\n",
      " [0.52245105]\n",
      " [0.50590817]\n",
      " [0.46691425]\n",
      " [0.47265361]\n",
      " [0.48936529]\n",
      " [0.45695476]\n",
      " [0.33271438]\n",
      " [0.2604659 ]\n",
      " [0.33220797]\n",
      " [0.39382174]\n",
      " [0.39888589]\n",
      " [0.38251182]\n",
      " [0.29237002]\n",
      " [0.29794058]\n",
      " [0.27363268]\n",
      " [0.26282917]\n",
      " [0.34132343]\n",
      " [0.26350439]\n",
      " [0.33153275]\n",
      " [0.3541526 ]\n",
      " [0.35600945]\n",
      " [0.34807562]\n",
      " [0.41357191]\n",
      " [0.45037137]\n",
      " [0.49915598]\n",
      " [0.44868332]\n",
      " [0.37187711]\n",
      " [0.55654963]\n",
      " [0.51603646]\n",
      " [0.47062795]\n",
      " [0.37575962]\n",
      " [0.27194463]\n",
      " [0.26350439]\n",
      " [0.27261985]\n",
      " [0.28241053]\n",
      " [0.20425388]\n",
      " [0.40681972]\n",
      " [0.45459149]\n",
      " [0.4306212 ]\n",
      " [0.46033086]\n",
      " [0.43923025]\n",
      " [0.47180959]\n",
      " [0.48143147]\n",
      " [0.42606347]\n",
      " [0.46269413]\n",
      " [0.47771776]\n",
      " [0.42775152]\n",
      " [0.36208643]\n",
      " [0.31060095]\n",
      " [0.42640108]\n",
      " [0.43112762]\n",
      " [0.42268737]\n",
      " [0.4027684 ]\n",
      " [0.33997299]\n",
      " [0.30671843]\n",
      " [0.33558406]\n",
      " [0.32731263]\n",
      " [0.36664416]\n",
      " [0.38318704]\n",
      " [0.34503714]\n",
      " [0.23176907]\n",
      " [0.19817691]\n",
      " [0.16205267]\n",
      " [0.16087103]\n",
      " [0.21404456]\n",
      " [0.1596894 ]\n",
      " [0.15344362]\n",
      " [0.12255233]\n",
      " [0.05519919]\n",
      " [0.11546253]\n",
      " [0.12086428]\n",
      " [0.03882512]\n",
      " [0.06060095]\n",
      " [0.03798109]\n",
      " [0.11563133]\n",
      " [0.12457799]\n",
      " [0.13436867]\n",
      " [0.18095881]\n",
      " [0.17960837]\n",
      " [0.20239703]\n",
      " [0.222316  ]\n",
      " [0.20999325]\n",
      " [0.21100608]\n",
      " [0.25489534]\n",
      " [0.30958812]\n",
      " [0.33355841]\n",
      " [0.32224848]\n",
      " [0.3576975 ]\n",
      " [0.39095206]\n",
      " [0.34149223]\n",
      " [0.36326806]\n",
      " [0.38251182]\n",
      " [0.47349764]\n",
      " [0.53561783]\n",
      " [0.48885888]\n",
      " [0.5381499 ]\n",
      " [0.49206617]\n",
      " [0.47434166]\n",
      " [0.47670493]\n",
      " [0.52464551]\n",
      " [0.51367319]\n",
      " [0.54962863]\n",
      " [0.52228224]\n",
      " [0.50270088]\n",
      " [0.4339973 ]\n",
      " [0.44125591]\n",
      " [0.44952735]\n",
      " [0.40411884]\n",
      " [0.42454423]\n",
      " [0.41593518]\n",
      " [0.38048616]\n",
      " [0.39061445]\n",
      " [0.47704254]\n",
      " [0.5243079 ]\n",
      " [0.48666442]\n",
      " [0.50810263]\n",
      " [0.46961512]\n",
      " [0.43433491]\n",
      " [0.46758947]\n",
      " [0.5033761 ]\n",
      " [0.51012829]\n",
      " [0.55840648]\n",
      " [0.54405807]\n",
      " [0.58457124]\n",
      " [0.61630655]\n",
      " [0.59182984]\n",
      " [0.61039838]\n",
      " [0.63268062]\n",
      " [0.59942606]\n",
      " [0.58879136]\n",
      " [0.64145847]\n",
      " [0.66829845]\n",
      " [0.71117488]]\n"
     ]
    }
   ],
   "source": [
    "# Train Split Preview\n",
    "print(x_train)\n",
    "print(x_test)\n",
    "\n",
    "# Test Split Preview\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73facdac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "125/125 [==============================] - 2s 5ms/step - loss: 0.1502 - mae: 0.1502 - val_loss: 0.2040 - val_mae: 0.2040\n",
      "Epoch 2/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0654 - mae: 0.0654 - val_loss: 0.1817 - val_mae: 0.1817\n",
      "Epoch 3/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0584 - mae: 0.0584 - val_loss: 0.1741 - val_mae: 0.1741\n",
      "Epoch 4/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0556 - mae: 0.0556 - val_loss: 0.1603 - val_mae: 0.1603\n",
      "Epoch 5/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0494 - mae: 0.0494 - val_loss: 0.1473 - val_mae: 0.1473\n",
      "Epoch 6/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0420 - mae: 0.0420 - val_loss: 0.1402 - val_mae: 0.1402\n",
      "Epoch 7/250\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0392 - mae: 0.0392 - val_loss: 0.1360 - val_mae: 0.1360\n",
      "Epoch 8/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0370 - mae: 0.0370 - val_loss: 0.1308 - val_mae: 0.1308\n",
      "Epoch 9/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0350 - mae: 0.0350 - val_loss: 0.1267 - val_mae: 0.1267\n",
      "Epoch 10/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0325 - mae: 0.0325 - val_loss: 0.1246 - val_mae: 0.1246\n",
      "Epoch 11/250\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0319 - mae: 0.0319 - val_loss: 0.1237 - val_mae: 0.1237\n",
      "Epoch 12/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.0310 - val_loss: 0.1225 - val_mae: 0.1225\n",
      "Epoch 13/250\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0300 - mae: 0.0300 - val_loss: 0.1217 - val_mae: 0.1217\n",
      "Epoch 14/250\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0296 - mae: 0.0296 - val_loss: 0.1202 - val_mae: 0.1202\n",
      "Epoch 15/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.0290 - val_loss: 0.1194 - val_mae: 0.1194\n",
      "Epoch 16/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.0288 - val_loss: 0.1209 - val_mae: 0.1209\n",
      "Epoch 17/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.0284 - val_loss: 0.1173 - val_mae: 0.1173\n",
      "Epoch 18/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.0282 - val_loss: 0.1179 - val_mae: 0.1179\n",
      "Epoch 19/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.0270 - val_loss: 0.1184 - val_mae: 0.1184\n",
      "Epoch 20/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.0270 - val_loss: 0.1170 - val_mae: 0.1170\n",
      "Epoch 21/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.0267 - val_loss: 0.1179 - val_mae: 0.1179\n",
      "Epoch 22/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.0269 - val_loss: 0.1160 - val_mae: 0.1160\n",
      "Epoch 23/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.0265 - val_loss: 0.1179 - val_mae: 0.1179\n",
      "Epoch 24/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.0262 - val_loss: 0.1196 - val_mae: 0.1196\n",
      "Epoch 25/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0255 - mae: 0.0255 - val_loss: 0.1164 - val_mae: 0.1164\n",
      "Epoch 26/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0251 - mae: 0.0251 - val_loss: 0.1163 - val_mae: 0.1163\n",
      "Epoch 27/250\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0250 - mae: 0.0250 - val_loss: 0.1166 - val_mae: 0.1166\n",
      "Epoch 28/250\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0246 - mae: 0.0246 - val_loss: 0.1187 - val_mae: 0.1187\n",
      "Epoch 29/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0244 - mae: 0.0244 - val_loss: 0.1170 - val_mae: 0.1170\n",
      "Epoch 30/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0245 - mae: 0.0245 - val_loss: 0.1146 - val_mae: 0.1146\n",
      "Epoch 31/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0236 - mae: 0.0236 - val_loss: 0.1165 - val_mae: 0.1165\n",
      "Epoch 32/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0237 - mae: 0.0237 - val_loss: 0.1175 - val_mae: 0.1175\n",
      "Epoch 33/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0231 - mae: 0.0231 - val_loss: 0.1159 - val_mae: 0.1159\n",
      "Epoch 34/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0228 - mae: 0.0228 - val_loss: 0.1154 - val_mae: 0.1154\n",
      "Epoch 35/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0225 - mae: 0.0225 - val_loss: 0.1161 - val_mae: 0.1161\n",
      "Epoch 36/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0227 - mae: 0.0227 - val_loss: 0.1160 - val_mae: 0.1160\n",
      "Epoch 37/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0224 - mae: 0.0224 - val_loss: 0.1164 - val_mae: 0.1164\n",
      "Epoch 38/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0219 - mae: 0.0219 - val_loss: 0.1152 - val_mae: 0.1152\n",
      "Epoch 39/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0213 - mae: 0.0213 - val_loss: 0.1133 - val_mae: 0.1133\n",
      "Epoch 40/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0214 - mae: 0.0214 - val_loss: 0.1123 - val_mae: 0.1123\n",
      "Epoch 41/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.1133 - val_mae: 0.1133\n",
      "Epoch 42/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0209 - mae: 0.0209 - val_loss: 0.1134 - val_mae: 0.1134\n",
      "Epoch 43/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0211 - mae: 0.0211 - val_loss: 0.1137 - val_mae: 0.1137\n",
      "Epoch 44/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0206 - mae: 0.0206 - val_loss: 0.1152 - val_mae: 0.1152\n",
      "Epoch 45/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0210 - mae: 0.0210 - val_loss: 0.1130 - val_mae: 0.1130\n",
      "Epoch 46/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0206 - mae: 0.0206 - val_loss: 0.1121 - val_mae: 0.1121\n",
      "Epoch 47/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.1121 - val_mae: 0.1121\n",
      "Epoch 48/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0199 - mae: 0.0199 - val_loss: 0.1137 - val_mae: 0.1137\n",
      "Epoch 49/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.1115 - val_mae: 0.1115\n",
      "Epoch 50/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.1130 - val_mae: 0.1130\n",
      "Epoch 51/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.1111 - val_mae: 0.1111\n",
      "Epoch 52/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.1123 - val_mae: 0.1123\n",
      "Epoch 53/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.1113 - val_mae: 0.1113\n",
      "Epoch 54/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.1119 - val_mae: 0.1119\n",
      "Epoch 55/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.1103 - val_mae: 0.1103\n",
      "Epoch 56/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.1102 - val_mae: 0.1102\n",
      "Epoch 57/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.1096 - val_mae: 0.1096\n",
      "Epoch 58/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.1102 - val_mae: 0.1102\n",
      "Epoch 59/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.1106 - val_mae: 0.1106\n",
      "Epoch 60/250\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.1094 - val_mae: 0.1094\n",
      "Epoch 61/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.1101 - val_mae: 0.1101\n",
      "Epoch 62/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.1096 - val_mae: 0.1096\n",
      "Epoch 63/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.1101 - val_mae: 0.1101\n",
      "Epoch 64/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.1077 - val_mae: 0.1077\n",
      "Epoch 65/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.1078 - val_mae: 0.1078\n",
      "Epoch 66/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.1095 - val_mae: 0.1095\n",
      "Epoch 67/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.1083 - val_mae: 0.1083\n",
      "Epoch 68/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.1076 - val_mae: 0.1076\n",
      "Epoch 69/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.1072 - val_mae: 0.1072\n",
      "Epoch 70/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.1080 - val_mae: 0.1080\n",
      "Epoch 71/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.1072 - val_mae: 0.1072\n",
      "Epoch 72/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.1062 - val_mae: 0.1062\n",
      "Epoch 73/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.1085 - val_mae: 0.1085\n",
      "Epoch 74/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.1060 - val_mae: 0.1060\n",
      "Epoch 75/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.1053 - val_mae: 0.1053\n",
      "Epoch 76/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.1065 - val_mae: 0.1065\n",
      "Epoch 77/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.1061 - val_mae: 0.1061\n",
      "Epoch 78/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.1063 - val_mae: 0.1063\n",
      "Epoch 79/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.1069 - val_mae: 0.1069\n",
      "Epoch 80/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.1062 - val_mae: 0.1062\n",
      "Epoch 81/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.1059 - val_mae: 0.1059\n",
      "Epoch 82/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.1063 - val_mae: 0.1063\n",
      "Epoch 83/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.1065 - val_mae: 0.1065\n",
      "Epoch 84/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.1058 - val_mae: 0.1058\n",
      "Epoch 85/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.1064 - val_mae: 0.1064\n",
      "Epoch 86/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.1067 - val_mae: 0.1067\n",
      "Epoch 87/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.1045 - val_mae: 0.1045\n",
      "Epoch 88/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.1026 - val_mae: 0.1026\n",
      "Epoch 89/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.1038 - val_mae: 0.1038\n",
      "Epoch 90/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.1037 - val_mae: 0.1037\n",
      "Epoch 91/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.1037 - val_mae: 0.1037\n",
      "Epoch 92/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.1032 - val_mae: 0.1032\n",
      "Epoch 93/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.1038 - val_mae: 0.1038\n",
      "Epoch 94/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.1043 - val_mae: 0.1043\n",
      "Epoch 95/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.1030 - val_mae: 0.1030\n",
      "Epoch 96/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.1036 - val_mae: 0.1036\n",
      "Epoch 97/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.1045 - val_mae: 0.1045\n",
      "Epoch 98/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.1039 - val_mae: 0.1039\n",
      "Epoch 99/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.1034 - val_mae: 0.1034\n",
      "Epoch 100/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.1038 - val_mae: 0.1038\n",
      "Epoch 101/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.1036 - val_mae: 0.1036\n",
      "Epoch 102/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.1032 - val_mae: 0.1032\n",
      "Epoch 103/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.1018 - val_mae: 0.1018\n",
      "Epoch 104/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.1035 - val_mae: 0.1035\n",
      "Epoch 105/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.1020 - val_mae: 0.1020\n",
      "Epoch 106/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.1008 - val_mae: 0.1008\n",
      "Epoch 107/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.1032 - val_mae: 0.1032\n",
      "Epoch 108/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.1018 - val_mae: 0.1018\n",
      "Epoch 109/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.1026 - val_mae: 0.1026\n",
      "Epoch 110/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.1021 - val_mae: 0.1021\n",
      "Epoch 111/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.1038 - val_mae: 0.1038\n",
      "Epoch 112/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.1027 - val_mae: 0.1027\n",
      "Epoch 113/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.1021 - val_mae: 0.1021\n",
      "Epoch 114/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.1002 - val_mae: 0.1002\n",
      "Epoch 115/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.1025 - val_mae: 0.1025\n",
      "Epoch 116/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.1006 - val_mae: 0.1006\n",
      "Epoch 117/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.1031 - val_mae: 0.1031\n",
      "Epoch 118/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.1019 - val_mae: 0.1019\n",
      "Epoch 119/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.1024 - val_mae: 0.1024\n",
      "Epoch 120/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.1010 - val_mae: 0.1010\n",
      "Epoch 121/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.1013 - val_mae: 0.1013\n",
      "Epoch 122/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.1009 - val_mae: 0.1009\n",
      "Epoch 123/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.1002 - val_mae: 0.1002\n",
      "Epoch 124/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.1009 - val_mae: 0.1009\n",
      "Epoch 125/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.1002 - val_mae: 0.1002\n",
      "Epoch 126/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.1005 - val_mae: 0.1005\n",
      "Epoch 127/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.1008 - val_mae: 0.1008\n",
      "Epoch 128/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.1011 - val_mae: 0.1011\n",
      "Epoch 129/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.1008 - val_mae: 0.1008\n",
      "Epoch 130/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.1007 - val_mae: 0.1007\n",
      "Epoch 131/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.1013 - val_mae: 0.1013\n",
      "Epoch 132/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.1012 - val_mae: 0.1012\n",
      "Epoch 133/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.1011 - val_mae: 0.1011\n",
      "Epoch 134/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.1002 - val_mae: 0.1002\n",
      "Epoch 135/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.1021 - val_mae: 0.1021\n",
      "Epoch 136/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.1008 - val_mae: 0.1008\n",
      "Epoch 137/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0999 - val_mae: 0.0999\n",
      "Epoch 138/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.1000 - val_mae: 0.1000\n",
      "Epoch 139/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.1013 - val_mae: 0.1013\n",
      "Epoch 140/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.1010 - val_mae: 0.1010\n",
      "Epoch 141/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.1009 - val_mae: 0.1009\n",
      "Epoch 142/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.1003 - val_mae: 0.1003\n",
      "Epoch 143/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.1003 - val_mae: 0.1003\n",
      "Epoch 144/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0995 - val_mae: 0.0995\n",
      "Epoch 145/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.1006 - val_mae: 0.1006\n",
      "Epoch 146/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.1010 - val_mae: 0.1010\n",
      "Epoch 147/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.1013 - val_mae: 0.1013\n",
      "Epoch 148/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.1015 - val_mae: 0.1015\n",
      "Epoch 149/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.1008 - val_mae: 0.1008\n",
      "Epoch 150/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.1027 - val_mae: 0.1027\n",
      "Epoch 151/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.1001 - val_mae: 0.1001\n",
      "Epoch 152/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0998 - val_mae: 0.0998\n",
      "Epoch 153/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.1005 - val_mae: 0.1005\n",
      "Epoch 154/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0987 - val_mae: 0.0987\n",
      "Epoch 155/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0985 - val_mae: 0.0985\n",
      "Epoch 156/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.1006 - val_mae: 0.1006\n",
      "Epoch 157/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0991 - val_mae: 0.0991\n",
      "Epoch 158/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.1004 - val_mae: 0.1004\n",
      "Epoch 159/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0993 - val_mae: 0.0993\n",
      "Epoch 160/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.1006 - val_mae: 0.1006\n",
      "Epoch 161/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0974 - val_mae: 0.0974\n",
      "Epoch 162/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0986 - val_mae: 0.0986\n",
      "Epoch 163/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0992 - val_mae: 0.0992\n",
      "Epoch 164/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0992 - val_mae: 0.0992\n",
      "Epoch 165/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.1002 - val_mae: 0.1002\n",
      "Epoch 166/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0995 - val_mae: 0.0995\n",
      "Epoch 167/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.1009 - val_mae: 0.1009\n",
      "Epoch 168/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0998 - val_mae: 0.0998\n",
      "Epoch 169/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0995 - val_mae: 0.0995\n",
      "Epoch 170/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0990 - val_mae: 0.0990\n",
      "Epoch 171/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0982 - val_mae: 0.0982\n",
      "Epoch 172/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0997 - val_mae: 0.0997\n",
      "Epoch 173/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.1009 - val_mae: 0.1009\n",
      "Epoch 174/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0999 - val_mae: 0.0999\n",
      "Epoch 175/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0986 - val_mae: 0.0986\n",
      "Epoch 176/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0987 - val_mae: 0.0987\n",
      "Epoch 177/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0989 - val_mae: 0.0989\n",
      "Epoch 178/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0986 - val_mae: 0.0986\n",
      "Epoch 179/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0991 - val_mae: 0.0991\n",
      "Epoch 180/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0976 - val_mae: 0.0976\n",
      "Epoch 181/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0996 - val_mae: 0.0996\n",
      "Epoch 182/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.1002 - val_mae: 0.1002\n",
      "Epoch 183/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0991 - val_mae: 0.0991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0982 - val_mae: 0.0982\n",
      "Epoch 185/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0982 - val_mae: 0.0982\n",
      "Epoch 186/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0990 - val_mae: 0.0990\n",
      "Epoch 187/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0990 - val_mae: 0.0990\n",
      "Epoch 188/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0976 - val_mae: 0.0976\n",
      "Epoch 189/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0986 - val_mae: 0.0986\n",
      "Epoch 190/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0990 - val_mae: 0.0990\n",
      "Epoch 191/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0981 - val_mae: 0.0981\n",
      "Epoch 192/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0979 - val_mae: 0.0979\n",
      "Epoch 193/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0980 - val_mae: 0.0980\n",
      "Epoch 194/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0983 - val_mae: 0.0983\n",
      "Epoch 195/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0981 - val_mae: 0.0981\n",
      "Epoch 196/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0977 - val_mae: 0.0977\n",
      "Epoch 197/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0967 - val_mae: 0.0967\n",
      "Epoch 198/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0965 - val_mae: 0.0965\n",
      "Epoch 199/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0985 - val_mae: 0.0985\n",
      "Epoch 200/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0974 - val_mae: 0.0974\n",
      "Epoch 201/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0969 - val_mae: 0.0969\n",
      "Epoch 202/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0986 - val_mae: 0.0986\n",
      "Epoch 203/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0980 - val_mae: 0.0980\n",
      "Epoch 204/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0982 - val_mae: 0.0982\n",
      "Epoch 205/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0983 - val_mae: 0.0983\n",
      "Epoch 206/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0955 - val_mae: 0.0955\n",
      "Epoch 207/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0972 - val_mae: 0.0972\n",
      "Epoch 208/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0978 - val_mae: 0.0978\n",
      "Epoch 209/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0972 - val_mae: 0.0972\n",
      "Epoch 210/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0958 - val_mae: 0.0958\n",
      "Epoch 211/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0959 - val_mae: 0.0959\n",
      "Epoch 212/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0951 - val_mae: 0.0951\n",
      "Epoch 213/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0961 - val_mae: 0.0961\n",
      "Epoch 214/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0953 - val_mae: 0.0953\n",
      "Epoch 215/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0963 - val_mae: 0.0963\n",
      "Epoch 216/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0959 - val_mae: 0.0959\n",
      "Epoch 217/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0960 - val_mae: 0.0960\n",
      "Epoch 218/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0959 - val_mae: 0.0959\n",
      "Epoch 219/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0964 - val_mae: 0.0964\n",
      "Epoch 220/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0947 - val_mae: 0.0947\n",
      "Epoch 221/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0965 - val_mae: 0.0965\n",
      "Epoch 222/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0964 - val_mae: 0.0964\n",
      "Epoch 223/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0969 - val_mae: 0.0969\n",
      "Epoch 224/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0961 - val_mae: 0.0961\n",
      "Epoch 225/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0958 - val_mae: 0.0958\n",
      "Epoch 226/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0954 - val_mae: 0.0954\n",
      "Epoch 227/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0955 - val_mae: 0.0955\n",
      "Epoch 228/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0961 - val_mae: 0.0961\n",
      "Epoch 229/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0948 - val_mae: 0.0948\n",
      "Epoch 230/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0958 - val_mae: 0.0958\n",
      "Epoch 231/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0946 - val_mae: 0.0946\n",
      "Epoch 232/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0964 - val_mae: 0.0964\n",
      "Epoch 233/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0951 - val_mae: 0.0951\n",
      "Epoch 234/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0952 - val_mae: 0.0952\n",
      "Epoch 235/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0954 - val_mae: 0.0954\n",
      "Epoch 236/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0954 - val_mae: 0.0954\n",
      "Epoch 237/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0960 - val_mae: 0.0960\n",
      "Epoch 238/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0957 - val_mae: 0.0957\n",
      "Epoch 239/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0956 - val_mae: 0.0956\n",
      "Epoch 240/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0946 - val_mae: 0.0946\n",
      "Epoch 241/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0953 - val_mae: 0.0953\n",
      "Epoch 242/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0948 - val_mae: 0.0948\n",
      "Epoch 243/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0953 - val_mae: 0.0953\n",
      "Epoch 244/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0953 - val_mae: 0.0953\n",
      "Epoch 245/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0938 - val_mae: 0.0938\n",
      "Epoch 246/250\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0955 - val_mae: 0.0955\n",
      "Epoch 247/250\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0952 - val_mae: 0.0952\n",
      "Epoch 248/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0945 - val_mae: 0.0945\n",
      "Epoch 249/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0943 - val_mae: 0.0943\n",
      "Epoch 250/250\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0957 - val_mae: 0.0957\n"
     ]
    }
   ],
   "source": [
    "# Build autoencoder\n",
    "# Code modified from: https://www.analyticsvidhya.com/blog/2021/06/dimensionality-reduction-using-autoencoders-in-python/\n",
    "class AutoEncoders(Model):\n",
    "\n",
    "    # Initializer\n",
    "    def __init__(self, output_units):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Build Encoder down to 10 features\n",
    "        self.encoder = Sequential(\n",
    "            [\n",
    "                Dense(51, activation=\"relu\"),\n",
    "                Dense(37, activation=\"relu\"),\n",
    "                Dense(25, activation=\"relu\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Build Decoder\n",
    "        self.decoder = Sequential(\n",
    "            [\n",
    "                Dense(37, activation=\"relu\"),\n",
    "                Dense(51, activation=\"relu\"),\n",
    "                Dense(output_units, activation=\"sigmoid\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Call Overwrite\n",
    "    def call(self, inputs):\n",
    "        # Encode\n",
    "        encoded = self.encoder(inputs)\n",
    "        \n",
    "        # Decode\n",
    "        decoded = self.decoder(encoded)\n",
    "        \n",
    "        # Return\n",
    "        return decoded\n",
    "    \n",
    "# Autoencoder Usage\n",
    "    # Instantiate Autoencoder\n",
    "auto_encoder = AutoEncoders(51)\n",
    "    \n",
    "    # Prep for training\n",
    "auto_encoder.compile( loss='mae', metrics=['mae'], optimizer='adam')\n",
    "\n",
    "    # Train\n",
    "history = auto_encoder.fit(\n",
    "    x_train, \n",
    "    x_train, \n",
    "    epochs=250, \n",
    "    batch_size=16, \n",
    "    validation_data=(x_test, x_test)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1af6350",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc0efddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAHFCAYAAADmGm0KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABuvklEQVR4nO3deXhU1eHG8e/MZF8hC1kgJGFfRRZlE1cM4r5V3EBal1JrK1KqIrYiLrTUBa2CdSvSXxWsolKhQlBAEBBBoggRkC0sCSEBspJtcn9/HDIwJkAISWZC3s/z3Cczd87ce+4lNW/POfccm2VZFiIiIiLixu7pCoiIiIh4I4UkERERkRooJImIiIjUQCFJREREpAYKSSIiIiI1UEgSERERqYFCkoiIiEgNFJJEREREaqCQJCIiIlIDhSQRaRZ27tyJzWZj5syZp/3dpUuXYrPZWLp0ab2UE5GmQSFJREREpAYKSSIiIiI1UEgSkUYxadIkbDYb33//Pb/4xS8IDw8nIiKCcePGUVFRwebNm7niiisIDQ0lKSmJqVOnVjtGRkYGd955J61atcLf35+uXbvy/PPPU1lZ6VZu37593HLLLYSGhhIeHs6IESPIysqqsV5r167l2muvJSIigoCAAHr37s37779fr9c+b948Bg4cSFBQEKGhoVx++eWsWrXKrcyBAwe47777SEhIwN/fn+joaAYPHszixYtdZdavX8/VV1/tuv74+Hiuuuoq9uzZU6/1FRHDx9MVEJHm5ZZbbuHOO+/k17/+NampqUydOpXy8nIWL17M/fffz/jx43n33Xd55JFH6NChAzfeeCNgQsSgQYMoKyvjqaeeIikpiU8//ZTx48ezbds2pk+fDsCRI0cYOnQo+/btY8qUKXTq1In58+czYsSIanVZsmQJV1xxBf379+e1114jPDyc2bNnM2LECIqLixk9evQZX++7777LHXfcQUpKCu+99x6lpaVMnTqViy++mM8//5wLLrgAgJEjR/Ltt9/yzDPP0KlTJw4fPsy3335Lbm4uAEVFRVx++eUkJyfz6quvEhMTQ1ZWFkuWLKGgoOCM6ykiNbBERBrBE088YQHW888/77b/3HPPtQBr7ty5rn3l5eVWdHS0deONN7r2PfrooxZgff31127f/81vfmPZbDZr8+bNlmVZ1owZMyzA+uSTT9zK3XvvvRZg/fOf/3Tt69Kli9W7d2+rvLzcrezVV19txcXFWU6n07Isy1qyZIkFWEuWLDnpNf68nNPptOLj462ePXu6jmVZllVQUGC1atXKGjRokGtfSEiINXbs2BMee+3atRZgffzxxyetg4jUH3W3iUijuvrqq93ed+3aFZvNxvDhw137fHx86NChA7t27XLt++KLL+jWrRvnn3++2/dHjx6NZVl88cUXgGkdCg0N5dprr3Urd/vtt7u9/+mnn/jxxx+54447AKioqHBtV155JZmZmWzevPmMrnXz5s3s27ePkSNHYrcf+89tSEgIN910E6tXr6a4uBiA888/n5kzZ/L000+zevVqysvL3Y7VoUMHWrZsySOPPMJrr73Gpk2bzqhuInJqCkki0qgiIiLc3vv5+REUFERAQEC1/SUlJa73ubm5xMXFVTtefHy86/OqnzExMdXKxcbGur3fv38/AOPHj8fX19dtu//++wHIyck53ctzU1WnE9W7srKSQ4cOATBnzhzuuusu3nzzTQYOHEhERASjRo1yjaUKDw9n2bJlnHvuuTz22GN0796d+Ph4nnjiiWqBSkTqh8YkiUiTEBkZSWZmZrX9+/btAyAqKspVbs2aNdXK/XzgdlX5CRMmuMY9/Vznzp3PuM7ACettt9tp2bKlqz7Tpk1j2rRpZGRkMG/ePB599FGys7P57LPPAOjZsyezZ8/Gsiy+//57Zs6cyeTJkwkMDOTRRx89o7qKSHVqSRKRJuGyyy5j06ZNfPvtt277Z82ahc1m45JLLgHgkksuoaCggHnz5rmVe/fdd93ed+7cmY4dO/Ldd9/Rr1+/GrfQ0NAzqnPnzp1p3bo17777LpZlufYXFRXx4Ycfup54+7m2bdvywAMPcPnll1e7XgCbzUavXr148cUXadGiRY1lROTMqSVJRJqEhx56iFmzZnHVVVcxefJkEhMTmT9/PtOnT+c3v/kNnTp1AmDUqFG8+OKLjBo1imeeeYaOHTuyYMECFi5cWO2Y//jHPxg+fDjDhg1j9OjRtG7dmoMHD5Kens63337Lf/7znzOqs91uZ+rUqdxxxx1cffXV/PrXv6a0tJS//e1vHD58mL/85S8A5OXlcckll3D77bfTpUsXQkND+eabb/jss89crVyffvop06dP5/rrr6ddu3ZYlsXcuXM5fPgwl19++RnVU0RqppAkIk1CdHQ0K1euZMKECUyYMIH8/HzatWvH1KlTGTdunKtcUFAQX3zxBQ8++CCPPvooNpuNlJQUZs+ezaBBg9yOeckll7BmzRqeeeYZxo4dy6FDh4iMjKRbt27ccsst9VLv22+/neDgYKZMmcKIESNwOBwMGDCAJUuWuOoTEBBA//79+de//sXOnTspLy+nbdu2PPLIIzz88MMAdOzYkRYtWjB16lT27duHn58fnTt3ZubMmdx11131UlcRcWezjm8DFhERERFAY5JEREREaqSQJCIiIlIDhSQRERGRGigkiYiIiNRAIUlERESkBgpJIiIiIjXQPEl1VFlZyb59+wgNDcVms3m6OiIiIlILlmVRUFBAfHy828LTNVFIqqN9+/aRkJDg6WqIiIhIHezevZs2bdqctIxCUh1Vrem0e/duwsLCPFwbERERqY38/HwSEhJqtTajQlIdVXWxhYWFKSSJiIg0MbUZKqOB2yIiIiI1UEgSERERqYFCkoiIiEgNNCapgTmdTsrLyz1djSbJ19cXh8Ph6WqIiEgzpZDUQCzLIisri8OHD3u6Kk1aixYtiI2N1VxUIiLS6BSSGkhVQGrVqhVBQUH6I3+aLMuiuLiY7OxsAOLi4jxcIxERaW4UkhqA0+l0BaTIyEhPV6fJCgwMBCA7O5tWrVqp601ERBqVBm43gKoxSEFBQR6uSdNXdQ81rktERBqbQlIDUhfbmdM9FBERT1FIEhEREamBQpI0mKSkJKZNm+bpaoiIiNSJBm6Lm4svvphzzz23XsLNN998Q3Bw8JlXSkRExAMUkrxNZSVUVpjXPn6erUsNLMvC6XTi43PqX53o6OhGqJGIiEjDUHebtyk5BNkbIS+j0U89evRoli1bxksvvYTNZsNmszFz5kxsNhsLFy6kX79++Pv7s3z5crZt28Z1111HTEwMISEhnHfeeSxevNjteD/vbrPZbLz55pvccMMNBAUF0bFjR+bNm9fIVykiIlI7CkmNxLIsissqTr2VQ3F5JcWltShbi82yrFrX8aWXXmLgwIHce++9ZGZmkpmZSUJCAgAPP/wwU6ZMIT09nXPOOYfCwkKuvPJKFi9ezPr16xk2bBjXXHMNGRknD3dPPvkkt9xyC99//z1XXnkld9xxBwcPHjyjeysiItIQ1N3WSI6UO+n254Wn+a1tZ3zeTZOHEeRXu3/m8PBw/Pz8CAoKIjY2FoAff/wRgMmTJ3P55Ze7ykZGRtKrVy/X+6effpqPPvqIefPm8cADD5zwHKNHj+a2224D4Nlnn+Xvf/87a9as4YorrjjtaxMREWlIakmSWunXr5/b+6KiIh5++GG6detGixYtCAkJ4ccffzxlS9I555zjeh0cHExoaKhr6RERERFv4vGWpOnTp/O3v/2NzMxMunfvzrRp0xgyZEiNZefOncuMGTNIS0ujtLSU7t27M2nSJIYNG+ZW7sMPP+RPf/oT27Zto3379jzzzDPccMMNdT5vfQj0dbBp8rBTFywvgZzNYPeBmO71ct768POn1P74xz+ycOFCnnvuOTp06EBgYCA333wzZWVlJz2Or6+v23ubzUZlZWW91FFERKQ+ebQlac6cOYwdO5aJEyeyfv16hgwZwvDhw0/YGvHll19y+eWXs2DBAtatW8cll1zCNddcw/r1611lVq1axYgRIxg5ciTfffcdI0eO5JZbbuHrr7+u83nrg81mI8jP59Sbvy9BvnaCfKhd+VNspztjtZ+fH06n85Tlli9fzujRo7nhhhvo2bMnsbGx7Ny5s453R0RExPt4NCS98MIL3H333dxzzz107dqVadOmkZCQwIwZM2osP23aNB5++GHOO+88OnbsyLPPPkvHjh3573//61bm8ssvZ8KECXTp0oUJEyZw2WWXuT1ldbrnbVS2o/8kViWcxqDr+pKUlMTXX3/Nzp07ycnJOWErT4cOHZg7dy5paWl899133H777WoREhGRs4rHQlJZWRnr1q0jJSXFbX9KSgorV66s1TEqKyspKCggIiLCtW/VqlXVjjls2DDXMet63tLSUvLz8922BmE77p/EavzQMX78eBwOB926dSM6OvqErWsvvvgiLVu2ZNCgQVxzzTUMGzaMPn36NHJtRUREGo7HxiTl5OTgdDqJiYlx2x8TE0NWVlatjvH8889TVFTELbfc4tqXlZV10mPW9bxTpkzhySefrFW9zki1kFQ/Y4pqq1OnTqxatcpt3+jRo6uVS0pK4osvvnDb99vf/tbt/c+732qajuDw4cN1qqeIiEhD8/jTbT8fM2NZVq3G0bz33ntMmjSJOXPm0KpVq9M+5umed8KECeTl5bm23bt3n7KOdWKzHdflduqxQSIiItIwPNaSFBUVhcPhqNZ6k52dXa2V5+fmzJnD3XffzX/+8x+GDh3q9llsbOxJj1nX8/r7++Pv73/K66oXNodpRdIYHxEREY/xWEuSn58fffv2JTU11W1/amoqgwYNOuH33nvvPUaPHs27777LVVddVe3zgQMHVjvmokWLXMes63kb1fGDt0VERMQjPDpP0rhx4xg5ciT9+vVj4MCBvP7662RkZDBmzBjAdHHt3buXWbNmASYgjRo1ipdeeokBAwa4WoMCAwMJDw8H4MEHH+TCCy/kr3/9K9dddx2ffPIJixcvZsWKFbU+r8cpJImIiHicR0PSiBEjyM3NZfLkyWRmZtKjRw8WLFhAYmIiAJmZmW5PV/3jH/+goqKC3/72t26DhO+66y5mzpwJwKBBg5g9ezaPP/44f/rTn2jfvj1z5syhf//+tT6vx9kVkkRERDzNZp3OCqjikp+fT3h4OHl5eYSFhbl9VlJSwo4dO0hOTiYgIOD0D577E5QWQIu2EBRZTzVums74XoqIiBznZH+/f87jT7dJDWxHH/tXS5KIiIjHKCR5o6oxSXq6TURExGMUkryRXfMkiYiIeJpCkjdSd5uIiIjHKSR5Iw9OAXDxxRczduzYejve6NGjuf766+vteCIiIo1FIckbaUySiIiIxykkeSMPrd02evRoli1bxksvvYTNZsNms7Fz5042bdrElVdeSUhICDExMYwcOZKcnBzX9z744AN69uxJYGAgkZGRDB06lKKiIiZNmsQ777zDJ5984jre0qVLG/WaRERE6sqjk0k2K5YF5cW1K1tRCuVHzNiksqIzO69vkFk0txZeeukltmzZQo8ePZg8eTIATqeTiy66iHvvvZcXXniBI0eO8Mgjj3DLLbfwxRdfkJmZyW233cbUqVO54YYbKCgoYPny5ViWxfjx40lPTyc/P59//vOfAERERJzZ9YiIiDQShaTGUl4Mz8Y3/nkf2wd+wbUqGh4ejp+fH0FBQcTGxgLw5z//mT59+vDss8+6yr399tskJCSwZcsWCgsLqaio4MYbb3TNWN6zZ09X2cDAQEpLS13HExERaSoUkuSk1q1bx5IlSwgJCan22bZt20hJSeGyyy6jZ8+eDBs2jJSUFG6++WZatmzpgdqKiIjUH4WkxuIbZFp1aqPsCORuAbsvxHQ78/OegcrKSq655hr++te/VvssLi4Oh8NBamoqK1euZNGiRfz9739n4sSJfP311yQnJ5/RuUVERDxJIamx2Gy17vbC5gDfQPOztt+pJ35+fjidxwaM9+nThw8//JCkpCR8fGr+dbHZbAwePJjBgwfz5z//mcTERD766CPGjRtX7XgiIiJNhZ5u80Z2z82TlJSUxNdff83OnTvJycnht7/9LQcPHuS2225jzZo1bN++nUWLFvGrX/0Kp9PJ119/zbPPPsvatWvJyMhg7ty5HDhwgK5du7qO9/3337N582ZycnIoLy9v9GsSERGpC4Ukb1Q1BQBWowel8ePH43A46NatG9HR0ZSVlfHVV1/hdDoZNmwYPXr04MEHHyQ8PBy73U5YWBhffvklV155JZ06deLxxx/n+eefZ/jw4QDce++9dO7cmX79+hEdHc1XX33VqNcjIiJSVzbLsixPV6Ipys/PJzw8nLy8PMLCwtw+KykpYceOHSQnJxMQEHD6B7csyEwzr2N6gqP59oqe8b0UERE5zsn+fv+cWpK8kc0GHJ3bSOu3iYiIeIRCkrfy0KzbIiIiYigkeSu7w/xUS5KIiIhHKCR5K5vnnnATERERhaQGdUZj4qtCUmXzDkl6rkBERDxFIakB+Pr6AlBcXMsFbWuiMUnAsXtYdU9FREQaS/N9trwBORwOWrRoQXZ2NgBBQUHYbLbTO0g5UGFBSSnYS+q/kl7OsiyKi4vJzs6mRYsWOBwOT1dJRESaGYWkBlK16n1VUDptxblQVgSBFeB/uP4q1sS0aNHCdS9FREQak0JSA7HZbMTFxdGqVau6LcWx5D3YOBfOHwPn31P/FWwCfH191YIkIiIeo5DUwBwOR93+0NudULgbSrJAM02LiIg0Og3c9lahceZn3l7P1kNERKSZUkjyVi2TzM9DOzxaDRERkeZKIclbRSSbn4d2erQaIiIizZVCkreqakk6cgiOHPZkTURERJolhSRv5RcMwa3Ma3W5iYiINDqFJG+mLjcRERGPUUjyZi2PhqSDakkSERFpbB4PSdOnTyc5OZmAgAD69u3L8uXLT1g2MzOT22+/nc6dO2O32xk7dmy1MhdffDE2m63adtVVV7nKTJo0qdrnXjmrs55wExER8RiPhqQ5c+YwduxYJk6cyPr16xkyZAjDhw8nIyOjxvKlpaVER0czceJEevXqVWOZuXPnkpmZ6dp++OEHHA4Hv/jFL9zKde/e3a3chg0b6v36zpi620RERDzGozNuv/DCC9x9993cc49ZdmPatGksXLiQGTNmMGXKlGrlk5KSeOmllwB4++23azxmRESE2/vZs2cTFBRULST5+Ph4Z+vR8VzdbTs9Wg0REZHmyGMtSWVlZaxbt46UlBS3/SkpKaxcubLezvPWW29x6623Ehwc7LZ/69atxMfHk5yczK233sr27dvr7Zz1pqq7LX8PVJR5tCoiIiLNjcdCUk5ODk6nk5iYGLf9MTExZGVl1cs51qxZww8//OBqqarSv39/Zs2axcKFC3njjTfIyspi0KBB5ObmnvBYpaWl5Ofnu20NLqQV+AaDVQl5uxv+fCIiIuLi8YHbNpvN7b1lWdX21dVbb71Fjx49OP/88932Dx8+nJtuuomePXsydOhQ5s+fD8A777xzwmNNmTKF8PBw15aQkFAvdTwpm+1Ya5KecBMREWlUHgtJUVFROByOaq1G2dnZ1VqX6qK4uJjZs2dXa0WqSXBwMD179mTr1q0nLDNhwgTy8vJc2+7djdSyE97G/Mzf0zjnExEREcCDIcnPz4++ffuSmprqtj81NZVBgwad8fHff/99SktLufPOO09ZtrS0lPT0dOLi4k5Yxt/fn7CwMLetUQRHmZ/FBxvnfCIiIgJ4+Om2cePGMXLkSPr168fAgQN5/fXXycjIYMyYMYBpvdm7dy+zZs1yfSctLQ2AwsJCDhw4QFpaGn5+fnTr1s3t2G+99RbXX389kZGR1c47fvx4rrnmGtq2bUt2djZPP/00+fn53HXXXQ13sXUVdPRpvSMKSSIiIo3JoyFpxIgR5ObmMnnyZDIzM+nRowcLFiwgMTERMJNH/nzOpN69e7ter1u3jnfffZfExER27tzp2r9lyxZWrFjBokWLajzvnj17uO2228jJySE6OpoBAwawevVq13m9StDRkKeWJBERkUZlsyzL8nQlmqL8/HzCw8PJy8tr2K63b2fBvN9Bpyvg9jkNdx4REZFm4HT+fnv86TY5BVdL0omnJxAREZH6p5Dk7QKPjklSSBIREWlUCkneTi1JIiIiHqGQ5O2qQlJJHjjLPVsXERGRZkQhydsFtgCOzkB+5JAnayIiItKsKCR5O7sDAlua1+pyExERaTQKSU2B5koSERFpdApJTYEGb4uIiDQ6haSmQCFJRESk0SkkNQVBGpMkIiLS2BSSmgKNSRIREWl0CklNgbrbREREGp1CUlOgkCQiItLoFJKaAoUkERGRRqeQ1BRUhaQjGpMkIiLSWBSSmgIN3BYREWl0CklNQVCE+VmaDxVlnq2LiIhIM6GQ1BT4h4Pt6D+VutxEREQahUJSU2C3Q+DR1iQN3hYREWkUCklNhZ5wExERaVQKSU2FQpKIiEijUkhqKoLU3SYiItKYFJKaCldL0iHP1kNERKSZUEhqKtTdJiIi0qgUkpoKhSQREZFGpZDUVGhMkoiISKNSSGoq1JIkIiLSqBSSmgqt3yYiItKoFJKaCnW3iYiINCqFpKaiqiWpvAjKj3i2LiIiIs2AQlJT4R8Gdh/zWl1uIiIiDU4hqamw2Y61Jh1RSBIREWloCklNiZ5wExERaTQeD0nTp08nOTmZgIAA+vbty/Lly09YNjMzk9tvv53OnTtjt9sZO3ZstTIzZ87EZrNV20pKSup8Xq+hkCQiItJoPBqS5syZw9ixY5k4cSLr169nyJAhDB8+nIyMjBrLl5aWEh0dzcSJE+nVq9cJjxsWFkZmZqbbFhAQUOfzeo3AluanxiSJiIg0OI+GpBdeeIG7776be+65h65duzJt2jQSEhKYMWNGjeWTkpJ46aWXGDVqFOHh4Sc8rs1mIzY21m07k/M2pqy8ElI37WftzhqCkFqSREREGo3HQlJZWRnr1q0jJSXFbX9KSgorV648o2MXFhaSmJhImzZtuPrqq1m/fv0Zn7e0tJT8/Hy3rSF8vSOXe2et5cXFW6p/qJAkIiLSaDwWknJycnA6ncTExLjtj4mJISsrq87H7dKlCzNnzmTevHm89957BAQEMHjwYLZu3XpG550yZQrh4eGuLSEhoc51PBmH3QZAhdOq/qFCkoiISKPx+MBtm83m9t6yrGr7TseAAQO488476dWrF0OGDOH999+nU6dO/P3vfz+j806YMIG8vDzXtnv37jrX8WQcR+tQaSkkiYiIeJKPp04cFRWFw+Go1nqTnZ1drZXnTNjtds477zxXS1Jdz+vv74+/v3+91etE7EdbkpyVJwtJGrgtIiLS0DzWkuTn50ffvn1JTU1125+amsqgQYPq7TyWZZGWlkZcXFyjnreuqlqSauptO7Z+m0KSiIhIQ/NYSxLAuHHjGDlyJP369WPgwIG8/vrrZGRkMGbMGMB0ce3du5dZs2a5vpOWlgaYwdkHDhwgLS0NPz8/unXrBsCTTz7JgAED6NixI/n5+bz88sukpaXx6quv1vq8nlQ1JqnypC1JOWBZZhZuERERaRAeDUkjRowgNzeXyZMnk5mZSY8ePViwYAGJiYmAmTzy53MX9e7d2/V63bp1vPvuuyQmJrJz504ADh8+zH333UdWVhbh4eH07t2bL7/8kvPPP7/W5/Wkk3a3hcaBzQ4VJVC4H0Jjq5cRERGRemGzrJpGCMup5OfnEx4eTl5eHmFhYfV23BVbc7jzra/pEhvKZ2MvrF5g2jlweBeMXgBJg+vtvCIiIs3B6fz99vjTbeLONQVATS1JAJEdzM+D2xqpRiIiIs2TQpKXOemYJIDI9uZnrkKSiIhIQ1JI8jKOo/8izhP1gkYcDUlqSRIREWlQCklexm47ycBtOK4laXsj1UhERKR5UkjyMqfsbotoZ34e3A6VlY1UKxERkeZHIcnLuFqSTtTd1iIR7D5QcQQK9jVizURERJoXhSQv43DNk3SiAj4mKIEGb4uIiDQghSQv4+MKSSfpSovU4G0REZGGppDkZU4643aVCE0DICIi0tAUkrxM1QK3J8tIx1qS9ISbiIhIQ1FI8jKO2rQkRXUyP7M2NEKNREREmieFJC/j6m472ZJ6bfqZJ9zydsOhXY1UMxERkeZFIcnLuLrbTtaS5BcM8b3N611fNUKtREREmh+FJC9jP9WyJFUSB5ufOxWSREREGoJCkpepakmyrFO0JiVdYH7uWtEItRIREWl+FJK8jI/92D/JSVuTEvqDzQ6HdkLe3oavmIiISDOjkORljstIJ3/CLSAM4nqZ1xqXJCIiUu8UkrxM1RQAAJW1HZe0a2UD1khERKR5UkjyMlUL3MIpWpIA2pxnfu5b34A1EhERaZ4UkryMW0vSSZZvAyD+XPNz/0aoKG2wOomIiDRHCklexnF8S9KputtaJEJAC6gsh+xNDVsxERGRZkYhycvY7afR3WazHZtUcl9aw1VKRESkGVJI8kI+tVm/rUpVl5vGJYmIiNQrhSQvVKv126pUtSRlpjVchURERJohhSQvVKv126rEnWt+7t+kwdsiIiL1SCHJCzlOp7utRVsIjDCDt/dvbOCaiYiINB8KSV6oaux2rbrbbLZj45L2rmuwOomIiDQ3CkleqKolqVbdbQAJA8xPLU8iIiJSbxSSvJDjdAZuAyQPMT93roDafkdEREROSiHJC1UtTVKrMUkArfuCTyAUHYADPzZgzURERJoPhSQvdFrzJAH4+EPb/ub1juUNVCsREZHmRSHJC9lPNyQBJFV1uX3ZADUSERFpfjwekqZPn05ycjIBAQH07duX5ctP3BKSmZnJ7bffTufOnbHb7YwdO7ZamTfeeIMhQ4bQsmVLWrZsydChQ1mzZo1bmUmTJmGz2dy22NjY+r60OnMN3D6d8UXJF5qfO1fUYmVcERERORWPhqQ5c+YwduxYJk6cyPr16xkyZAjDhw8nIyOjxvKlpaVER0czceJEevXqVWOZpUuXctttt7FkyRJWrVpF27ZtSUlJYe/evW7lunfvTmZmpmvbsGFDvV9fXTlcY5JO40vxvcE3GI4cgr1rG6ZiIiIizYhHQ9ILL7zA3XffzT333EPXrl2ZNm0aCQkJzJgxo8bySUlJvPTSS4waNYrw8PAay/z73//m/vvv59xzz6VLly688cYbVFZW8vnnn7uV8/HxITY21rVFR0fX+/XVVZ262xy+0O1a83r58w1QKxERkebFYyGprKyMdevWkZKS4rY/JSWFlStX1tt5iouLKS8vJyIiwm3/1q1biY+PJzk5mVtvvZXt27fX2znPlGtZktN9nH/IeLDZYctnmlhSRETkDHksJOXk5OB0OomJiXHbHxMTQ1ZWVr2d59FHH6V169YMHTrUta9///7MmjWLhQsX8sYbb5CVlcWgQYPIzc094XFKS0vJz8932xpKnVqSAKI6wDkjzOsvntGcSSIiImfA4wO3bUdbTapYllVtX11NnTqV9957j7lz5xIQEODaP3z4cG666SZ69uzJ0KFDmT9/PgDvvPPOCY81ZcoUwsPDXVtCQkK91LEmpz0FwPEu/CPYHLDtc/j4fnBW1HPtREREmgePhaSoqCgcDke1VqPs7OxqrUt18dxzz/Hss8+yaNEizjnnnJOWDQ4OpmfPnmzduvWEZSZMmEBeXp5r27179xnX8UTq3JIEENkernvVBKXv3oUPRkOls34rKCIi0gx4LCT5+fnRt29fUlNT3fanpqYyaNCgMzr23/72N5566ik+++wz+vXrd8rypaWlpKenExcXd8Iy/v7+hIWFuW0NxXE6C9zW5Nzb4NZ/g8Mf0v8Lnz2qrjcREZHT5NHutnHjxvHmm2/y9ttvk56ezkMPPURGRgZjxowBTOvNqFGj3L6TlpZGWloahYWFHDhwgLS0NDZt2uT6fOrUqTz++OO8/fbbJCUlkZWVRVZWFoWFha4y48ePZ9myZezYsYOvv/6am2++mfz8fO66667GufBTOO0FbmvSeTjc+A/zes3r8PmTalESERE5DT6ePPmIESPIzc1l8uTJZGZm0qNHDxYsWEBiYiJgJo/8+ZxJvXv3dr1et24d7777LomJiezcuRMwk1OWlZVx8803u33viSeeYNKkSQDs2bOH2267jZycHKKjoxkwYACrV692ndfTXGu3nWnrT/cbIG8vLJoIK140T7z94h0Iijj1d0VERJo5m2WpH6Yu8vPzCQ8PJy8vr9673m5/YzUrt+Xy0q3nct25rc/8gN//B/77IJQXQacr4LbZUDU4vqwYfALA7vEx/CIiIg3udP5+6y+jF6rTsiQnc84v4JcLzBilLZ/B2rfM/uwf4cVu8K/r6uc8IiIiZxGFJC9kr8uyJKcSfy4MnWReL3wcNn8GH91nljHZ8SUcrnkpGBERkeZKIckLHZsnqZ4Xqu0/BjqmQMUReG8EZH537LOtqSf+Xk1+nA//vgXyM+u3jiIiIl5CIckLHZsnqd4PDCP+D/oc98Rg26PTLZxOSMrbA3Pvg60L4evXai5zcDvUd8gTERFpRApJXshRX0+31cTHH679O9z6LvxiJlw51ezfsQzKS6D8CKx+zQz0LqphmRbLgvnjoezolAqbPq4+B9O3s+Dl3vDp2Pqvv4iISCPx6BQAUrN6mSfpVLpcZX5aFoTGQUEmLBgPWxdB4X7z2aGdcM1L8L9HoEUiDP+rmZxyy//A7gt2hymT+Z0Z8wTmabkvnjavv30HetwI7S52P3dJPvgGgsO34a5PRETkDKklyQud0bIkp8tmg46Xm9fr/2UCUngC+AbB9qXwyvnmibg1/4DNC2DxJFN28INmfBOY1qQqa986FrIA/jvWtE5V+XE+PNcR3r4CKsoa7rpERETOkEKSF6palqTepgA4lV63gc1uwtHV0+B338I1L5vPnKUmMAF8eA8c3AZBUXDBWOh+vdn/w1zI+BrW/9tMWgkwbAqExsOhHfD10Zm/0z+F90dBRQnsXQsrXjhxnbJ/hMIDDXCxIiIitaPuNi/UqC1JAImDYPxWCAg/1gV2zi+g5LDpThvwG5gx2LwHuPCP4B8KHYeZiSgP74K3U44dL7IjnH8fBITBJ7+Fb96EbtfBh3dDZQXE94Z96+HL50xrVNy5kPZv03IVHGVmBt/zjQlj96RCRLvGuQ8iIiLHUUjyQlVTAFQ0VkgCE05+7vx7j70e8gdI/RO0aAv9fmn2+YeYcUrf/guKsiEo0oSefr8Chw/0uBlS/wx5u+FfN5gWpMTBMGqeaVHaPB/evAxaJpmn4X6uOAf+72a4OxWCI099DXl7zfgqzR4uIiL1QCHJCzXKwO3TNeB+E4raDjJPyFXpO9psNfENMJ8tf950u2GDYc+aAHXty/BxhZlG4OB28AsxrU+WEwJbQoeh8N7tpnvv49/AHe+fvH6rpsPCCaaV69LH6+eaRUSkWVNI8kL1tsBtfXL4mBai09XvblgxzYSfXrceewouOMoEn6wfYPsS6H4jhP9snbo73ofXLjBBaucKSLqg5nNkp8PiJ8zrVdNNoNMiviIicobUL+GFvLIlqa7CW5uuuvjecNkT1T+P7QGDflc9IAG06gp97jKvU59wn4/JsqC0EHZ+ZSa2dB59Uq68CL55y/04FWWwbCpsXVw/1yQiIs2CQpIX8sqWpDNx6US4bymExZ3+dy96xDxdt3ctfDcbKkrhozHwTCxMaQ0zr4Ss7yGgBaQcnZ/p69fcpx1Y+TIseQb+MxpK8kxoylhdfRJMERGR49QpJL3zzjvMnz/f9f7hhx+mRYsWDBo0iF27dtVb5ZorR0MtS9IUhcaYliYwT8q9fQV8954ZBA4Q3Aq63wAj50L/35iB5cU58PH9JlAd3AFf/s2ULSuAdTPNU3ZvDzNjpQAqneCsaPRLExER71ankPTss88SGBgIwKpVq3jllVeYOnUqUVFRPPTQQ/VawebI1d2mlg7jwofhnFvNuKZ935ppB26bAxP2wvgtZnmV1n3NuKkr/gp2H9g4F16/GP59swlUgUfHKC15FtLnmdcrXjTzMb12AUzraWYOd1aYLrzSQk9drYiIeIk6DdzevXs3HTp0AODjjz/m5ptv5r777mPw4MFcfPHF9Vm/Zqmqu63CqZAEmPBz/Qwz2Dv9v3DNNGh/ac1lu1wJd/wH5oyC7E1Hv+8Hd/0X/u8mKMwy+3yDzPpzr18MFUe75mZeY1qucrZAm/Phl/8z5xYRkWapTi1JISEh5OaaxU8XLVrE0KFDAQgICODIkSMn+6rUgo9akqqz22HYMzD2+xMHpCrtL4X7V8K1r5jFfO9ONQPEB95vPm/dD0b8n3ldcQT8w01LVGmeCUgAe9aYsUwnkrcXnOVnfl0iIuK16vR/ky+//HLuueceevfuzZYtW7jqKrNY6saNG0lKSqrP+jVLjT7j9tmoRVvoM9J938AHzMSVyRdBYAszC/jWVLjlHUg43yzMGxhhZh7/3x9N11xBJkR1gnNvB59A+H42rHnDdPslDoaRH5lB4plp5r3DF/ZvAr8gcy4REWmy6hSSXn31VR5//HF2797Nhx9+SGSkmQ153bp13HbbbfVawebIcbY93eYt7A4TjKrcPNO0JPkFm/dXTDE/LcsskbJ5Pqx53ez76iXT3bdv/bHv7/oKZt8B+38wYaplsglG25eYp+0eTDMTY1Ydszi35pnNRUTEK9UpJLVo0YJXXnml2v4nn3zyjCsk4DjaCXpWzJPkzez2YwHpeDYb3Pw2bHgfcreZBXzzMszyKn6hMOQhE4g+vAd+Sq36kplV/NAO87bksFmuZfDvzfv/PQJr/mFmA7/wj41xdSIicobqFJI+++wzQkJCuOACMwPyq6++yhtvvEG3bt149dVXadmyZb1WsrlRd5sX8A2APqPM64segVWvQGE2XDgeQmPN/tJ8+Owx6HkzXPon0xWXt8e0Ii37i+mWG/hbyFhlAhKYLr2Q2OpdgTXZtQqOHDKD0UVEpNHVaeD2H//4R/Lz8wHYsGEDf/jDH7jyyivZvn0748aNq9cKNkfqbvMyfkFw0cNw1XPHAhKYdekm7DHr0IVEm/mchv8VLhhrxjblZcDq6fDfsaZ81Ril/z5o5miqdJr3RTlmRvA9644duygH/nU9zL7NvYtPREQaTZ1C0o4dO+jWrRsAH374IVdffTXPPvss06dP53//+1+9VrA5OquWJTnb2Wv4n5Bv4LFFfxc9DrlbISTGzDre5y4z39Pnk+Gty2Hl3+G1IWZG8Lcuh2V/M+Fp7dvHJsxc82ZjXY2IiBynTiHJz8+P4uJiABYvXkxKSgoAERERrhYmqbuqkFShkNR0DfgNxPY0rUdJQ+CWf5lB3Ne8BNdNB99g2LvOhKiCfeYzywlLnoaPfg3fHBeMfvgAig+e+FxHDsHiJ03rVHlJ7ep35DBsXwZlRWdylSIiZ7U6jUm64IILGDduHIMHD2bNmjXMmTMHgC1bttCmTZt6rWBzpBm3zwIhrWDMiur7bTbofQe0v8Qsr7LpE4jpabrpNn1suuI2/MeUDY2HoEjYvwHW/58ZBP79f0ywShwEna+E3J/gmzfMk3MAae/BZX8ywez79+HHT48NOE95yjxd9/lk2PYFVFZAj5vMIHUREammTiHplVde4f777+eDDz5gxowZtG5tVnD/3//+xxVXXFGvFWyOXAvcqiXp7BUWD0P+YLYqve80T9t98CuwKuH8e02omfc7WPGC6X5b9lcTbjbONVuVqM7mibrcrfD+qJrP+a/rwWY3x67yw1y4+DGI6tAQVyki0qTVKSS1bduWTz/9tNr+F1988YwrJFrgtlnrfoOZtHLb59D/1ybUfPOmWVduyTOmTLfrTAvTvjSI6mgmsTz3drPMyoppsOEDyN8DEe2g/xjT7ffDh+Y4VqU5xyUTTYvUls9g1d9NN6CIiLip88JUTqeTjz/+mPT0dGw2G127duW6667D4XDUZ/2apaqn29Td1kx1vsJsVX61yHSRrX7VLLly45vg41f9e4Et4fIn4bInzDin0DgzgSaY7rletwMWtOln9g1+0ISktPdMa1JoTO3qV+k0S7L4Bhzbd+Sw6TpsdzG0TKzDRYuIeJ86haSffvqJK6+8kr1799K5c2csy2LLli0kJCQwf/582rdvX9/1bFY0T5K48Q2AK541czQFtKj5ibrj2e0QXsPYwDZ93d+3HWgW8t2zxnTnDf8rlBWb9et8g8zUB34hZgkXMAPE17xp5nyyLBg9H1p1MXND/d9NcOBHs5jwefeaugZFwKGdZnB4VOf6WSw4Z6tZNiak1ZkfS0TkFOr0X63f//73tG/fntWrVxMREQFAbm4ud955J7///e+ZP39+vVayuXHNuK2WJDleUET9Hs9mg0seM2OV1rwByRfCpw9B4X73cq37QadhsHoGHDnuKbv3bjVh6IunzbIsPgFm3NTqV2H9vyCmu5lIE8xnSRdAz1+YweIOX9j4Eez8CoZOAv8QU86yzFN/Md3NVArH27MW3h5mAtyoT6B1n5Nfn2WZaxQRqaM6TQGwbNkypk6d6gpIAJGRkfzlL39h2bJl9Va55qpq4HaFUyFJGlj7S8xTcpYTZt9uApJfqGmtsfuaMnvXmvFQRw5CdBe49hWzgPChHfDJb01Aiu4CD6yFO+eaMVCl+SYg2ezmeBUl8NNiM73Bf0bDgc0w9z7zZN7CCcfqs+E/8OZl8K8bwVkBFaWmNarSCfPHmUHrpfnwfzdC5vcnvq5DO+H5LuYczooGvIFeoqLUDMIvK/Z0TUTOKnVqSfL396egoKDa/sLCQvz8ahgrIafF52h3imbclkaR8jRsTYXKcojsCL/67NhCvIXZ8PVrsGWhGRx+/n2mFah1H/jncLCAwb+D/r8xrUEtEqDdJZA+z3TDdbsOwlqbLrxNH5u5nH781AQoZ5k5x7ezoNNw6DzcTK4JkLESPn0QMr42T+xFdTLH8A+HyPaw71sTpi5+FAY9aLry/vNLyNoAv/yfafUqzILv5wA28PGHvd+aAeo/73ZsKCX5ZsB90gUN36L1v0dg3T9NV+dVzzXsuUSakTq1JF199dXcd999fP3111iWhWVZrF69mjFjxnDttdee1rGmT59OcnIyAQEB9O3bl+XLl5+wbGZmJrfffjudO3fGbrczduzYGst9+OGHdOvWDX9/f7p168ZHH310RudtbFrgVhpVZHsY/hfocDmM/OhYQAIz9ueyP8NvvjLr0DmOti7FdIexG+APP5oFe6u6y8CMiep+PQx6wIQmu92MXbr4UbjiL6ZMca6ZUPOcW837eQ+YJ/Cyvgfb0cHm6//PBCQwAQnMHFAj50LHFBOyPp8Mnz8JGavNlAi5W2HxJEh791h9vp8N375j5pt6f9TJJ+asTx/8Et65GlL/XP/HLis2a/vl7zPjtL6dZfZ/P0etSSL1qE4tSS+//DJ33XUXAwcOxNfX/EezvLyc6667jmnTptX6OHPmzGHs2LFMnz6dwYMH849//IPhw4ezadMm2rZtW618aWkp0dHRTJw48YTTDaxatYoRI0bw1FNPccMNN/DRRx9xyy23sGLFCvr371+n8zY2u9Zuk8Z23j1mOx0B4ad/nn6/gj3fmIk0U54yc0NlbzLh6MO7TZlet5mn99a+bcLQpX8y3XA2u/m+3QG3v28+nz/OrI+366tj50j7P/Mzoh1cMM60siQOgoPb4OB2+OeVUF5kBqWff585n2+AGcNUuN8sIXN8y095iely3PutGRCfOMiU2bfeHDt7k5lZPSIZItqbcVeFWaZ7EWDlyxDTA3qNOHbMfethwR8huBXE9TLdl626Qvy5J753WT+YFrody019nGXg8IfIDqa7FExX5KZP4NzbTv/fpq4qyuBwRu3m2io/AiV57msgingxm2XV/S/xTz/9RHp6OpZl0a1bNzp0OL0J6fr370+fPn2YMWOGa1/Xrl25/vrrmTJlykm/e/HFF3PuuedWC2UjRowgPz/fbQ25K664gpYtW/Lee++d8Xmr5OfnEx4eTl5eHmFhYbX6Tm19nr6fu99ZS6824XzywAX1emwRj6usNLOAV00VkLfXdJ0VZJr39y0zweHQThM+TtZV9e9fwNZFR9/YzHiorKNjlVKeMa1ZVQO4M7+HN4eCs9T9GC2TTQvVN2/DrhXQ5WoTrrYvgW1LTKj7+Xd8Asw4IGr4z6fDD4KjIX+vOfahHSbMjPg/6JRirveNS6oPkAfT7Tjwt6ZlLrqrCW+Z38P8P5inEI8XEG4CR9W197jRtMYlDoZfLjDXve1zMzVE6+O6GPeth/X/Ni2AoTEmOIIJlYd2mta5vr+E5CEnvu9VnOUw82rYvRoufdwc80QKD8DbKeYc17wEfU4w6ekpz1lRP09KSrN1On+/a/2bNm7cuJN+vnTpUtfrF1544ZTHKysrY926dTz66KNu+1NSUli5cmVtq1XNqlWreOihh9z2DRs2zBWm6nre0tJSSkuP/YeyIdeoc00BoJYkORvZ7e5zKYW3Ni1D/7oe2px3rDUlIvnUx0p5Gn763LSkdLkKLnoEXr/ITMh57u2mTFXIijsHbnvPtDq1HWS65r56yYSYD3517Jg/fmq244XEmLod3mVadKoWH+75Cxj0OzN2K3cbbF1olnzJ32uma7j3C7PUTPo8MzD+/PvM54X7oVU3OPcO0xKVtxt2rYQt/zMbQHiCefJvwR/NoHm7D3S6AjpebpadiWgHX/8DljwLfUeZcWEbPzLX9/lk8zTgjmUmtP1mlWnpqayEub+GnM3m+i97At6+wkwyesssM0B//w8mON23tOZ7vnUxLPiDCWP+YSYggXnKsap1rmp+riplxeZpyKpANu93JuAN+t2p/42r5O2BhY/B5v/B0Cdh4P21/65IHdU6JK1fv75W5Wy1HKCYk5OD0+kkJsZ9AruYmBiysrJqW61qsrKyTnrMup53ypQpPPnkk3Wu1+lwuJYlaZTTiXhe3Dnwh80mCJyO6M5w8QQzm/jFj5qWpF/+z0wfUNOUCR0uMxtAx6EmpKT+CdbNhMQLzASbS6eYAdfJF0K3ayHpQjNuq+q/beUlpjvNZjfdZFU6Xm4CwooXTHhJedrU4ea3zVN9P3xopkcACIwwga1l0rHvH9hixldlbTCTc+btPtYFGd/HlP95N9WAMUdnZj9at05XwOYFZoB8FWcZLBhvxpulf2ICEsD2pbD7uFay2cd10e1bD4d3mzFlYAJNdroJXql/NqH00M7jrj3FtOh99qiZ9b3XCDPbe1i8+fzTh0wXYUALM15t3Uwz43uLtmZw/4lUtQLuWw//vMp0k4J5ItI/pO6tUSK1VOv/Ii1ZsqRBKvDzUGVZVq2D1pkc83TPO2HCBLfWtPz8fBISEs6onifiWuBWA7elOakaFH66Lvqj2aq0HVD77waEma6fyyebVhGbzXSJVTqrt4ZU8Q1wDzfHs9vN3FEXjj+2z+ELN75huryy0813e9xU/RjRneDWf5vXRw7Dh/fAT6mm2+3OD088T9bx/926foZpTcpYbc7b/QZ47zbTdbjq1WMD2mN6mBaj8iJTjxaJptUJmxl3lbcb0v8L/X5pxnwtfxHKjnuiues1JtTlbIY+d5l7+OXfzDkKs0wL3arpprUnrpcZPG+zm+tLusC0OK16BT6+30w2Wn7ELNZcmG1a7LDMeX2DTdfhwsdNXVv3NXX/9h3TQldZYcapgQlwCx8z4a2iBIZPhV63QsF+SPu3eboyJBaun+7+cMLpqKmr78gh87tzot8XadI81rEbFRWFw+Go1nqTnZ1drZXndMTGxp70mHU9r7+/P/7+/nWu1+moCkkVlWpKEmkUPx+EXt9/8OwOM9aotgJbwO1zTBdc/LngH1r77/X7pdmqXDDWLIy8aKJ57xcKd/0XPhoDu7+GW/5luu6WTjEhpHC/aRH64QPT+rV3rfleaLzpGu1yNQz6vZkyIusHiO9tgtpFD8PgsaZFqWow/VfHrQk4eKwJSGC6yzK/g53L4ePfuF/DDx+4v591nRln5vAzXYJhrc351s00LVS7VpnQs+YNU6cq/33QTP2w4I9QdODozu/MeLCrXjBhurTAzBS/ayUU5ZiWyKQhJrD+3Ce/hU3zzNiydheZfVtTTQhtmWRaMisrzJOYBftN2LzokVPPkC9ezWMhyc/Pj759+5KamsoNN9zg2p+amsp1152k+fUUBg4cSGpqqtu4pEWLFjFo0KAGPW99crUkqSFJpPmyO2o3ePpUhvzBDLBOn2daay562LRK3T7HtJhVtYwMO7qAct4eE5L2rjPvA1uaVpkeN7v/wbf7V59zyscPul5ttvT/wse/hdI8aNXdhIgqDh+4+Z8mIJXmm+7HyPamO27ncrOv4zBY/tyxgfh9f3lsuZ2rp5nQtvRZ2PD+seN2vda04i2eZMZ+/We02R/dxXz/6xmmpenfN5/8nrU5Dy582LQqwtHB7kefmpx9B/xyvnmq8NNxJpjlbj3WNfrz43QcaroNN30M3/7LdOH2HqmWpybCo48IjBs3jpEjR9KvXz8GDhzI66+/TkZGBmPGjAFMF9fevXuZNWuW6ztpaWmAmbjywIEDpKWl4efnR7du3QB48MEHufDCC/nrX//KddddxyeffMLixYtZsWJFrc/raa4pAJSSRORM+fjD0CfMVn7EPJkHpjWmpqfEwtuYFqW960zZ29+HhPNP/7xdrzFdY9+/bwbR+/ysJT4kGu78oPr3ju86dfiYAeE+gTDkuIeHbDa4+BET0rYtMS1CCf3NeWw2uOEfMGMwFGVD3Lkw6mMT9nr+Aj6fBD99Afl7zJxcLRLMd0PjIDMNdq4wTzS+NwKueRn6jDR1APOUYlkBvHMNxJ4DeRlmgH3Pm003Z2i8mcohZ4sJe2n/hoTz4P27TJcnmCcO182EEf82LXMN5dBOU5+aFsOWWjujKQDqw/Tp05k6dSqZmZn06NGDF198kQsvvBCA0aNHs3PnTrcn52oaN5SYmMjOnTtd7z/44AMef/xxtm/fTvv27XnmmWe48cYba33e2mjIKQDSdh/m+le/onWLQL569NJ6PbaIyCltmgeLn4Bhz5qZ0D3FWWEGu0d3PdaqU1vZP5onBfv+8tgizccrPmjGEv08KBZmmwH0VS1HbQceXWLHYZ5W/PQhM+N7lVvfgy5Xuh9jX5p5ytLhbz7b+JF53fNm08JWmm+C2ej5Jx+L5zy6DE9N49GKD5pxWO0vNdewZaGpp38YbPnMdKVGdTIPDsT2rM0dc3c4wzz1eKLxd03Y6fz99nhIaqoaMiRt2JPHNa+sIC48gFUTLqvXY4uIyClYlnn6btUrx/b1uQuufdl0UW76GL55y7RSXfFszd9/7QIzOL7K6PlmTNbB7fCPi003ZO+RpkuuVTfT4rTjS1j0J9Pide7tpltw7zozZUVsTzMo3icQ/ILg+/+YVq3z7oEB98Or/d3HZFVx+ME5I8yWONh0mVqWCVJfvWyeyhwyzlzX4V1mfFr+PnM8Z7mpd01L+ZQWwJrXTdmE/uYJzJZJ9TuH1falkHxRvS/ro5DUCBoyJG3cl8dVL6+gVag/ayYOrddji4hILWX9YAaYF+eYp+hqO4AezJN+Cx8zr/uONk8AVtn0iVki53jn3mEWKa44Yt4HtICSw7U4kc08QZiZBjE9TXdfRDsztcLnk4/NuwVm0HubfmZOr+MD3PC/mUH6u1fDkPGmFalqrFdIDPziHTMofd9684RmRYnplizKdq+Kw89Mg3H5U0cHxH8F3a43D0ZsXmDmD7P7mlbBlklmjrM1r5s6t7/UTLtR5fv3Ye695jpunlmvA+AVkhpBQ4akH7PyuWLacqJC/Fj7+OX1emwREWkEhQfglX6m+2vM8updfiteNBNj2n3NTO9VYnvC/k1mLqrgVnDTm2burKJsM8aovMg8PZd8oenGq3oa0OaA+1eZucOqWJYJKt/PgY2fmNarKg4/0wK080TrltpMkDm048TXGNHOrPm4Z43p3qwKeG3OM4GqssKMa/MPcw9U4W1h9Kfw+sVmotQq3a6Hq543U2C8fhGUFcJFj8IlE05chzpQSGoEDRmStu4v4PIXv6RFkC9pfz7NfngREfEORbmm++lU6xxu/NisQ5jQ34wh2rPWhJ9BvzdP/Z1Ifia8ct7Rbrd74arnTly2vMRMz5C32ww2b9PPtBK9d6vZHxpnxp+tfduU7zPKLDPz4b0mKPkGmW7B+N6mRS0kGrpcc2xgeGWlqfPHvzHhCMx58nab1yGxkDTYTLdQkHmspSyyo6nLhv+Y79l9zPGPHDLTMYz6pN6fBFRIagQNGZK2Hyjk0ueXERrgw4ZJw+r12CIi4oUqK+vWpbT5M9OlNvTJmgeon0pZkWmRan+ZmdF98SQT0m55p26Tbm77wnQ19rrNTJq65xvTMtTuYhOodq00i0xXrXv4y88gcaAZ7D7vd8emfAiKhDFfQVjc6dfhFBSSGkFDhqRduUVc9LelBPs52Dj5ino9toiIiEctnmS6G/uMgmv/7v7ZwR1mxvjWfWue1LMeNMgCt9J4XPMkKb+KiMjZ5rInzMSfsedU/ywiuXaLWzcShSQvdGztNg9XREREpL7ZbNC6j6drUStaVMYLVYUktSSJiIh4jkKSF9KyJCIiIp6nkOSFqlqSACoVlERERDxCIckLHR+SKhSSREREPEIhyQu5tSRpXJKIiIhHKCR5Icdxi/lpXJKIiIhnKCR5oeMnXdUTbiIiIp6hkOSFjm9J0sBtERERz1BI8kLHj0lSd5uIiIhnKCR5IZvNRlVjkrrbREREPEMhyUs5NKGkiIiIRykkeSnX0iQKSSIiIh6hkOSltMitiIiIZykkeSlXd5vGJImIiHiEQpKXsqu7TURExKMUkryUq7tNLUkiIiIeoZDkpex6uk1ERMSjFJK8lOPov4xCkoiIiGcoJHkpzZMkIiLiWQpJXsrh0NNtIiIinqSQ5KWqWpK0wK2IiIhnKCR5KU0BICIi4lkKSV5Kk0mKiIh4lkKSl9KyJCIiIp6lkOSl7GpJEhER8SiFJC/lcI1JUlOSiIiIJ3g8JE2fPp3k5GQCAgLo27cvy5cvP2n5ZcuW0bdvXwICAmjXrh2vvfaa2+cXX3wxNput2nbVVVe5ykyaNKna57GxsQ1yfXV1LCR5uCIiIiLNlEdD0pw5cxg7diwTJ05k/fr1DBkyhOHDh5ORkVFj+R07dnDllVcyZMgQ1q9fz2OPPcbvf/97PvzwQ1eZuXPnkpmZ6dp++OEHHA4Hv/jFL9yO1b17d7dyGzZsaNBrPV0OPd0mIiLiUT6ePPkLL7zA3XffzT333APAtGnTWLhwITNmzGDKlCnVyr/22mu0bduWadOmAdC1a1fWrl3Lc889x0033QRARESE23dmz55NUFBQtZDk4+Pjda1Hx3PNk6QxSSIiIh7hsZaksrIy1q1bR0pKitv+lJQUVq5cWeN3Vq1aVa38sGHDWLt2LeXl5TV+56233uLWW28lODjYbf/WrVuJj48nOTmZW2+9le3bt5+0vqWlpeTn57ttDcmutdtEREQ8ymMhKScnB6fTSUxMjNv+mJgYsrKyavxOVlZWjeUrKirIycmpVn7NmjX88MMPrpaqKv3792fWrFksXLiQN954g6ysLAYNGkRubu4J6ztlyhTCw8NdW0JCQm0vtU5cUwCoJUlERMQjPD5w23a0W6mKZVnV9p2qfE37wbQi9ejRg/PPP99t//Dhw7npppvo2bMnQ4cOZf78+QC88847JzzvhAkTyMvLc227d+8++YWdIbsWuBUREfEoj41JioqKwuFwVGs1ys7OrtZaVCU2NrbG8j4+PkRGRrrtLy4uZvbs2UyePPmUdQkODqZnz55s3br1hGX8/f3x9/c/5bHqS1VLUoVCkoiIiEd4rCXJz8+Pvn37kpqa6rY/NTWVQYMG1fidgQMHViu/aNEi+vXrh6+vr9v+999/n9LSUu68885T1qW0tJT09HTi4uJO8yoajha4FRER8SyPdreNGzeON998k7fffpv09HQeeughMjIyGDNmDGC6uEaNGuUqP2bMGHbt2sW4ceNIT0/n7bff5q233mL8+PHVjv3WW29x/fXXV2thAhg/fjzLli1jx44dfP3119x8883k5+dz1113NdzFnibXFAAakyQiIuIRHp0CYMSIEeTm5jJ58mQyMzPp0aMHCxYsIDExEYDMzEy3OZOSk5NZsGABDz30EK+++irx8fG8/PLLrsf/q2zZsoUVK1awaNGiGs+7Z88ebrvtNnJycoiOjmbAgAGsXr3adV5vcGztNoUkERERT7BZlpoq6iI/P5/w8HDy8vIICwur9+P/9t1vmf99JpOu6cbowcn1fnwREZHm6HT+fnv86TapmcO1wK2HKyIiItJMKSR5KXW3iYiIeJZCkpdyzZOk3lARERGPUEjyUg4tSyIiIuJRCkleynF08TaFJBEREc9QSPJSakkSERHxLIUkL+WacVtjkkRERDxCIclL2e1a4FZERMSTFJK8lENPt4mIiHiUQpKXcjhMSKrQbJIiIiIeoZDkpWJCAwDYd/iIh2siIiLSPCkkeankqGAAduQUebgmIiIizZNCkpc6PiRpaRIREZHGp5Dkpdq0DMTHbqO0opKs/BJPV0dERKTZUUjyUj4OO20jgwB1uYmIiHiCQpIXa3e0y227QpKIiEijU0jyYkmRR8clHVBIEhERaWwKSV4sObpq8Hahh2siIiLS/CgkeTFNAyAiIuI5CklerF1UCAC7Dx2h3Fnp4dqIiIg0LwpJXiwmzJ9AXwfOSovdB4s9XR0REZFmRSHJi9lsNpKOdrn9lK1xSSIiIo1JIcnLnZsQDkDqpv0eromIiEjzopDk5W7s0waA+RsyKSqt8HBtREREmg+FJC/XL7ElSZFBFJc5+d8PWZ6ujoiISLOhkOTlbDYbN/c1rUkfrNvt4dqIiIg0HwpJTcCNfdpgs8Hq7QfJzDvi6eqIiIg0CwpJTUB8i0C6xIYBsHFvvodrIyIi0jwoJDURnWLMxJJbsgs8XBMREZHmQSGpiegUEwrA1v2aL0lERKQxKCQ1ER1bHW1J2q+WJBERkcagkNREVLUk/ZRdiLPS8nBtREREzn4eD0nTp08nOTmZgIAA+vbty/Lly09aftmyZfTt25eAgADatWvHa6+95vb5zJkzsdls1baSkpIzOq+nJUQE4e9jp7SiUuu4iYiINAKPhqQ5c+YwduxYJk6cyPr16xkyZAjDhw8nIyOjxvI7duzgyiuvZMiQIaxfv57HHnuM3//+93z44Ydu5cLCwsjMzHTbAgIC6nxeb+Cw22gfrS43ERGRxuLRkPTCCy9w9913c88999C1a1emTZtGQkICM2bMqLH8a6+9Rtu2bZk2bRpdu3blnnvu4Ve/+hXPPfecWzmbzUZsbKzbdibn9RZVT7ht1WK3IiIiDc5jIamsrIx169aRkpLitj8lJYWVK1fW+J1Vq1ZVKz9s2DDWrl1LeXm5a19hYSGJiYm0adOGq6++mvXr15/Reb1Fx6PjkjZnqSVJRESkoXksJOXk5OB0OomJiXHbHxMTQ1ZWzWuUZWVl1Vi+oqKCnJwcALp06cLMmTOZN28e7733HgEBAQwePJitW7fW+bwApaWl5Ofnu22NrWrwtrrbREREGp7HB27bbDa395ZlVdt3qvLH7x8wYAB33nknvXr1YsiQIbz//vt06tSJv//972d03ilTphAeHu7aEhISTn1x9ayqu237gSI94SYiItLAPBaSoqKicDgc1VpvsrOzq7XyVImNja2xvI+PD5GRkTV+x263c95557lakupyXoAJEyaQl5fn2nbvbvzFZlu3CMTXYaPMWak13ERERBqYx0KSn58fffv2JTU11W1/amoqgwYNqvE7AwcOrFZ+0aJF9OvXD19f3xq/Y1kWaWlpxMXF1fm8AP7+/oSFhbltjc3HYSehZRAAGbmaBkBERKQhebS7bdy4cbz55pu8/fbbpKen89BDD5GRkcGYMWMA03ozatQoV/kxY8awa9cuxo0bR3p6Om+//TZvvfUW48ePd5V58sknWbhwIdu3byctLY27776btLQ01zFrc15vlhhpQtJOhSQREZEG5ePJk48YMYLc3FwmT55MZmYmPXr0YMGCBSQmJgKQmZnpNndRcnIyCxYs4KGHHuLVV18lPj6el19+mZtuuslV5vDhw9x3331kZWURHh5O7969+fLLLzn//PNrfV5vlhgZDBxgV26Rp6siIiJyVrNZVSOf5bTk5+cTHh5OXl5eo3a9zfxqB5P+u4lh3WP4x8h+jXZeERGRs8Hp/P32+NNtcnpMSxLsUnebiIhIg1JIamKqxiTtyi1GjYAiIiINRyGpiWnTMgi7DY6UOzlQUOrp6oiIiJy1FJKaGD8fO61bBgJ6wk1ERKQhKSQ1QUlHxyXt1BNuIiIiDUYhqQmqGpekCSVFREQajkJSE5QYoZYkERGRhqaQ1AQlRZmQ9MPePD3hJiIi0kAUkpqgge0jCfR1sDO3mPW7D3u6OiIiImclhaQmKMTfh+E9YgH4YN0eD9dGRETk7KSQ1ETd3LcNAP/9bh8l5U4P10ZEROTso5DURA1oF0nrFoEUlFSwcGOWp6sjIiJy1lFIaqLsdhs39WkNwP+t3uXh2oiIiJx9FJKasDsGJOLrsPHNzkN8m3HI09URERE5qygkNWExYQFcd65pTXrjy+0ero2IiMjZRSGpibvvwnYAfLYxi505mlxSRESkvigkNXGdYkK5tEsrLAte/nyrp6sjIiJy1lBIOguMHdoRgI/S9vJjVr6HayMiInJ2UEg6C5zTpgVX9YzDsuC5hZs9XR0REZGzgkLSWWJcSiccdhuL07P5fs9hT1dHRESkyVNIOku0jw7hmnPiAJi1SvMmiYiInCmFpLPIyIFJgFmq5FBRmWcrIyIi0sQpJJ1F+rRtQff4MEorKvnPut2ero6IiEiTppB0FrHZbIwamAjA2yt28t3uw56tkIiISBOmkHSWubZXa1q3CCQrv4Trp3/FlAXpVFZanq6WiIhIk6OQdJYJ9HPw8W8Hc2Pv1lgW/OPL7fxu9npKK5yerpqIiEiTopB0FooO9eeFEefy8m298XXYmP99JqPf/ob8knJPV01ERKTJUEg6i13bK55/jj6fYD8Hq7bnMuIfq1m36yCWpe43ERGRU1FIOstd0DGKOb8eSFSIP+mZ+dw0YxVXvryC5VsPeLpqIiIiXs1mqVmhTvLz8wkPDycvL4+wsDBPV+eUdh8s5qXPt/Lp9/soKa8EYGC7SPomtmRAu0gGtIvAx6HMLCIiZ7fT+futkFRHTS0kVckrLuelz7fyzqqdOI976i0qxI/+yZH0Sgjn9v6JhPj7eLCWIiIiDUMhqRE01ZBUZUdOEcu3HuD7PXl8nr6fQ8XHBnWfnxTBv+45H38fhwdrKCIiUv9O5++3mguaqeSoYJKjggEod1byzY6DfLcnj+lLfmLNzoM8NCeN285vS2JEMG0jg1zlfOw2bDabJ6suIiLSKDw+CGX69OkkJycTEBBA3759Wb58+UnLL1u2jL59+xIQEEC7du147bXX3D5/4403GDJkCC1btqRly5YMHTqUNWvWuJWZNGkSNpvNbYuNja33a2sqfB12BnWI4jcXt+e1kX3xsdtYsCGLkW+t4cK/LeHivy1h6AvL6PT4/xj6wjLe+HI7O3KK9JSciIic1TwakubMmcPYsWOZOHEi69evZ8iQIQwfPpyMjIway+/YsYMrr7ySIUOGsH79eh577DF+//vf8+GHH7rKLF26lNtuu40lS5awatUq2rZtS0pKCnv37nU7Vvfu3cnMzHRtGzZsaNBrbSoGd4jiHyP7MrhDJJ1jQvF12NiZW8xP2YVYFmw7UMQzC9K55LmlDP7LF3yStldhSUREzkoeHZPUv39/+vTpw4wZM1z7unbtyvXXX8+UKVOqlX/kkUeYN28e6enprn1jxozhu+++Y9WqVTWew+l00rJlS1555RVGjRoFmJakjz/+mLS0tDrXvamPSaqtgpJyvt5+EJsNOsWEsnxrDp+k7WV9xmHKnOYpuUu7tOLuC5IZ2C4Su11dcSIi4r2axJiksrIy1q1bx6OPPuq2PyUlhZUrV9b4nVWrVpGSkuK2b9iwYbz11luUl5fj6+tb7TvFxcWUl5cTERHhtn/r1q3Ex8fj7+9P//79efbZZ2nXrt0J61taWkppaanrfX5+/imv8WwQGuDL0G4xrve392/L7f3bUlLu5PUvt/P3L7byxY/ZfPFjNv4+dmLCAhjUPpK7L0imY0yoB2suIiJyZjwWknJycnA6ncTExLjtj4mJISsrq8bvZGVl1Vi+oqKCnJwc4uLiqn3n0UcfpXXr1gwdOtS1r3///syaNYtOnTqxf/9+nn76aQYNGsTGjRuJjIys8dxTpkzhySefPN3LPGsF+Dr4/WUdGd4jlndW7eSTtH0UlFSQcbCYjIPFzP5mN1Eh/sSE+VNQUkHLIF+evr4nPduEe7rqIiIiteLxp9t+/qSUZVknfXqqpvI17QeYOnUq7733HkuXLiUgIMC1f/jw4a7XPXv2ZODAgbRv35533nmHcePG1XjeCRMmuH2Wn59PQkLCSa6seegYE8rT1/fkz1d3JzPvCDtzi3n3610s2rSfnMJScgpN61vGQfjFP1Yy5qL2OGw2zklowYUdo/SknIiIeC2PhaSoqCgcDke1VqPs7OxqrUVVYmNjayzv4+NTrQXoueee49lnn2Xx4sWcc845J61LcHAwPXv2ZOvWrScs4+/vj7+//0mP05z5+dhJjAwmMTKYizpFk19STkZuMdkFJYT4+/Lqkp9YtuUA0xYfu8d9E1syckAiF3WKpmWwnwdrLyIiUp3HQpKfnx99+/YlNTWVG264wbU/NTWV6667rsbvDBw4kP/+979u+xYtWkS/fv3cxiP97W9/4+mnn2bhwoX069fvlHUpLS0lPT2dIUOG1PFq5OfCAnzp0TocMN1rfdr2460VO/h+bx4+dhsLN2axbtch1u06hN0Gvdu2pGfrcPbnl+DjsHNeUksu7dKKNi2DPHshIiLSbHn06bY5c+YwcuRIXnvtNQYOHMjrr7/OG2+8wcaNG0lMTGTChAns3buXWbNmAWYKgB49evDrX/+ae++9l1WrVjFmzBjee+89brrpJsB0sf3pT3/i3XffZfDgwa5zhYSEEBISAsD48eO55ppraNu2LdnZ2Tz99NMsW7aMDRs2kJiYWKu6N5en2xrK/vwS/rVqF4vT9/NjVkGNZRx2G9ef25rfX9aBxMjgRq6hiIicjZrUsiTTp09n6tSpZGZm0qNHD1588UUuvPBCAEaPHs3OnTtZunSpq/yyZct46KGH2LhxI/Hx8TzyyCOMGTPG9XlSUhK7du2qdp4nnniCSZMmAXDrrbfy5ZdfkpOTQ3R0NAMGDOCpp56iW7duta63QlL92Xv4CF/8mM2unCLiWwRSVFrB8q05rNl5EABfh42RA5JoFebPwaIycgvLiAj25d4h7WgVFnDKcWwiIiJVmlRIaqoUkhpe2u7DPL9oM8u35tT4ebCfgw4xofyYmU/P1uHce2E7ftibR3pmAZd2acV158YTrIV6RUTkOApJjUAhqXFYlsWSzdl8uG4vfj52IoP9aBnsR+qm/aTtPnzS74YG+HD3BcncNTBJA8NFRARQSGoUCkmeVVlpsWzLAfJLymkfHcL7a3ezYEMm3eLD6Z3Qgnnf7WNHTpGrfFSIP+2OLup7btsWdI4NZev+ArLySokI9iUqxJ/IEH+iQvyICvUnLKD6xKQiItL0KSQ1AoUk71ZZabHgh0xe+eKnEw4MP5lucWFc3zuejq1CKXNW8tVPOfyYWUBWfgltWgZye/+2XNAhCofdxoINmWzOKuSeIcnEtwhsgKsREZH6opDUCBSSmo6CknJ25BSxI6eILfsL+GbHIbbnFNKhVQhJkcEcKjaDwXMKS8ktLKOgtKJO52kZ5Mvt/duy4qdcfO02buzThs6xZmmWthFBRIf6U1LupNKyCPIzY6UKSyvwsdsI8HVUO15lpYXNVvNEqSIiUjcKSY1AIensdbCojPnf72PJ5gPszy+hwmlxfnIE/ZJaEhMWwMqfcvhg3R725ZUA0C46GD+H/ZQtVkF+DorLnPjYbVzSpRUAX/yYja/DRv/kSC7sFE2X2FA+T89m5bYcduYWERnsz9M39OCSzq3cjlVcVkHekXLiwtVyJSJyOhSSGoFCkpSUO8k/Uk50qD+lFZU8v2gz6ZkFXNEjliNlTuZ9t4+8I+U4Ky325R3hTP6X1rN1OD4O06J0pMzJ1uxCnJUW5ydFcHGXaHYcKGLz/gK2ZRcSGx7AwPaRxIUHEhrgQ2iAD21aBtEvsaVapUSk2VNIagQKSXI6issqyMorITLEn+z8Ej5J20elZXFD79ZUWvDllgN8ufUAm7MKGNAukit7xtIxJpR/r87g7a921HhMm43TCl4dWoVwWZdWVFoW+/JK2HOwmLBAXxIigjindTg924QTGxZAgK+DorIKQvx9XN2CIiJnC4WkRqCQJI1lc1YBGQeLXe8ddugSG4bdZuNfq3eyK7eYDq1C6BwTSvtWIWw/UMS3GYc4VFRGYWkF+SXlpGUcpqjMedrnDg/0xc/HDkCovw8+DhuZeSVUVlokRQUTFuCL07JIjgymb2JL2kQE0io0gFZh/vyYWcA7q3YS4ufDI8O7EKFpGETECygkNQKFJGlK8kvK+ejbvezKLcbHYaNVqD9tWgaRf6Sc7TlFpO0+xJb9hRwsKmuQ80eF+HFeUgTZBaV0igllUPtIusaFkRQZhI/D3iDnFBGpiUJSI1BIkrNRWUUlFZWVBPo6KCg1XYQVTgsLi4KSCsqdlcSFBwA2duYUUVzuxLIs0jML2LD3MFl5JWQXlFJQUoG/j53rz23NtxmH2JpdWOP57DaIDPGnTctA2keHsPtgMd/tOUxcuHm/7/ARSsqdDO8Zy7kJLdmVW0RpRSUBvg4CfR2EBPhwflIEseEBlJQ72bK/gB8zCyhzVhIV4kfvtmawvWVZHCwqc31XrVoizZdCUiNQSBI5sSNlTmw2CPB1UFLu5KP1eykpdxIR7Md3u/NYu+sgP2UXUlyHLsCatG4RSGbeESp/9l8zmw16tWnB3sNHOFBQ6tofHepPVIiZksFug0A/BxVOC7vNRp/EFvRPjqR1y0DCAnyxLIs9h4+wLbuQSssiwNdBh+gQWrcMZH9+KeXOSmLDA4gPDyTQz0G5s/Lo+oJ+rq5KEfEeCkmNQCFJ5MxUVlrkFJaSXVDKrtxith0oJCLYdMtl5Zew40AhrVsGUVLuZO63e9ifX0pydDAhfj4cKXdypNxJdn4J3+3Jcx0zItiPrnGhBPn5sO/wETbuy3c7p6/DRrmz4f6TFxbgQ1GZE2elhd0GceGBJEYGEeLvc7SFrZzSikocdht+Djv+vnb8fRz4+9gJC/ClQ6sQEiICCQ/0JSzAlyB/H3IKStmaXcjKbTnkl1QwckAiF3aM4qttORSXOYkI8iMi2I9APwebswo4VFzGRZ1a0Tk2lOKyClZty2X19lw6xoRyY+/W6t6UZk8hqREoJIl4h+z8En46UEj76BBahfq7TXOw+2Axq7bnkhQZzDltws2Te6UVbN5fQEFJBYG+DpyVFiXlThx2G8VlTlZty2HD3jyy8kooLK3AbrcRHeJPp5hQ/H3tFJRUsGV/AVl5JcSGB+DrsJN5+IjbwPjTffKwIQT7OaoN1k+MDKJn63D8fRxUVJqwFhcegN1mIzu/FIfDRkSQWR8x1N+HgtIKjpRV4O/jIMDXjp+Pnay8UnbmFtExJoSLOkWTnV/Kqu25zP8+E4AHLu3AjX1aU1RqpsgoKqsgLMCX0AAfKi2oqKykwmkdnZ6i+vI/lmVRWFqBBQT7+eCwm3/PquBZm2ksikormLZ4C6u3H+QPKZ24+GfzjEnzppDUCBSSRKSKZVnkl1SwP7+E8EBfokP8ySkqZffBYnblFlNUWkGrsADX04KWZVFaXklpRdXmJLewjK3ZBezPLyX/SDn5JeUUllQQEeJH24gg+iVGUFLh5LWl28gvqaBn63BiwgI4VFzGwaIyCkoqaBcdTIi/Dyu25lDmrAQgPjyAge2jWLI5u8EG5tdVVIg/QX4OKi2LthFBRIX48/WOXPbnm67R8EBfruwZR1beEZZtOUBsWAA924Sz9/ARDhaW0b5VCC2D/MgtKqVVaABDOkaRcbCY/6zdw97DR1znGdEvgfgWgYQE+BAV4ke506KotIKOMSF0jw/nSJmTorIK/Bx2SsqdHCwqw8/HTosgP5yVFoeLy0jPzCe/pIIB7SI4p00LfB12svJKSM/Kp0N0CAkRQYAJc+mZ+RSVVtC9dTgh/mYajcpKi/0FJbQKDXAFv+NZlsWeQ0dIz8ynW3wYbY62opY5K0+6lmS5s5Kt+wvZX1BCZLAf57RpUY//QmcnhaRGoJAkIp5QUu6kpNxJi6ATDz7PLyknO7+UVmH+hPr7YLPZKCytIHVTFoeKTJefr8NGmbOSzMMlVFoWMWEBrkBwsLicwpJyQgJ8CfJ1UFrhpLSi8ui4Mn/aRgTxzc6DrNt1iDYtA+nROpxh3WPYe7iEaYu3UFBilvYJ8nMQ5OegoKSC0goT2uw28LHbXSGuobRuEch5SS35OG1fgxzfz8dOWcWxa2gfHYyP3c6+w0dcSxvZbJAUGUybloGkZxaQU1hKVIgfgztEEeDj4FBxGT9lF3KouIwKp+W2JFJyVDC7DxZTaVkM7xnH8B6xVDgtcovKyC0sJSrEHwt4e8UOt0B4QYcohnSMIiu/hKy8Eg4Xl3Nu2xZc1CmaqBB/DheXsXbXIfwcdgZ3iMLXYSO3qIzYsABatwjE/rMAl1dczu5Dxew5VMy+wyXkl5TTPT6cXgnhRAb7Y7dBmbMSX7vdhPhl25n//T4SI4MZ2C6SG/u0JjLEn7zichwOmys0epJCUiNQSBIRqa60wklxqZOQAB98jxv/VO6sxGGzuf4I55eUsyunmDKnE8uC7QeKyMovoXfbFvRp2xKH3cbanYf4bGMmLQL9uKZXPNkFJWzOKiAhIojIYD+27C+kqLSCiGA/tuwvYPX2XOJbBHJx52iu6RVPkJ8Pn6fvZ/nWHEorKikoKSe30LQS+fnY2bAnj6z8EnzsNoL8HJQ7Lfx87EQE+1FWUcnh4jJ8HHZC/H3oGBNCkJ+Dr37KJe9IOWACX2JkMBkHi3Ee99RAqL+Z6b5q6aLa8rHbSIoKZtuBwtPqrg0N8KF1i0C2HSg8ozF3PnYblZZ5gKFFkB+lFU5X4D3ZdyoqLdc4uyPl7l28fj52kiKD2LK/ELsNuseH4+9j5/CRckL8fQjx9+HwkTJ8HXYGt48iMsSPXbnFxIYHcEGHKLrFhVULbmdKIakRKCSJiDRtlmVRXOYkyM9R6yV7KistDh8pd4WzYH8fDhWVsX73IfwcDiJD/OgUE4rDbiO7oISf9heScbCYthFBnNu2Bd/uOsx3ew4DEOLvQ4dWIUSH+mO32YhvEUCQnw/Z+SX8sC+Pjq1CKSyt4O0VO9iRU4S/r+kCjAz2Izu/lINFZVzZM5Zbz29LgK+D3QeLeWvFDg4XlxEbHkhceAABvnZW/JRL2u5D5B8xU3P0aduSorIK1uw4iI/dRkSIH1l5JScMWFEhfrRuGUSbFuYJzvUZh9h2oKjGsgkRgfz+0o7kHSnnv9/tc3uwoi4Gd4jk3/cMOKNj/JxCUiNQSBIRkaasstLCdnQwfIWzkgOFpTjsNpyVZl4xX4edNi0Da1yeqMJZyeEj5VQ4LQL9zFQfeUfKSYoMdk19YVkWabsPsz+/hL6JEVRUVrJu1yEcNhthgb4UllZQVFpBiyBfDhaVs2LrAUrKK2kbGcS27EJWb89l1KAkHrmiS71et0JSI1BIEhERaThlFZWUVDhPOnC9Lk7n77fnR1CJiIiI/EzV2DFP0qxiIiIiIjVQSBIRERGpgUKSiIiISA0UkkRERERqoJAkIiIiUgOFJBEREZEaKCSJiIiI1EAhSURERKQGCkkiIiIiNVBIEhEREamBQpKIiIhIDRSSRERERGqgkCQiIiJSAx9PV6CpsiwLgPz8fA/XRERERGqr6u921d/xk1FIqqOCggIAEhISPFwTEREROV0FBQWEh4eftIzNqk2UkmoqKyvZt28foaGh2Gy2ej12fn4+CQkJ7N69m7CwsHo9thyj+9x4dK8bh+5z49G9bhwNcZ8ty6KgoID4+Hjs9pOPOlJLUh3Z7XbatGnToOcICwvT//gage5z49G9bhy6z41H97px1Pd9PlULUhUN3BYRERGpgUKSiIiISA0UkryQv78/TzzxBP7+/p6uyllN97nx6F43Dt3nxqN73Tg8fZ81cFtERESkBmpJEhEREamBQpKIiIhIDRSSRERERGqgkCQiIiJSA4UkLzN9+nSSk5MJCAigb9++LF++3NNVatImTZqEzWZz22JjY12fW5bFpEmTiI+PJzAwkIsvvpiNGzd6sMZNx5dffsk111xDfHw8NpuNjz/+2O3z2tzb0tJSfve73xEVFUVwcDDXXnste/bsacSraBpOda9Hjx5d7fd8wIABbmV0r09typQpnHfeeYSGhtKqVSuuv/56Nm/e7FZGv9dnrjb32Vt+pxWSvMicOXMYO3YsEydOZP369QwZMoThw4eTkZHh6ao1ad27dyczM9O1bdiwwfXZ1KlTeeGFF3jllVf45ptviI2N5fLLL3etzScnVlRURK9evXjllVdq/Lw293bs2LF89NFHzJ49mxUrVlBYWMjVV1+N0+lsrMtoEk51rwGuuOIKt9/zBQsWuH2ue31qy5Yt47e//S2rV68mNTWViooKUlJSKCoqcpXR7/WZq819Bi/5nbbEa5x//vnWmDFj3PZ16dLFevTRRz1Uo6bviSeesHr16lXjZ5WVlVZsbKz1l7/8xbWvpKTECg8Pt1577bVGquHZAbA++ugj1/va3NvDhw9bvr6+1uzZs11l9u7da9ntduuzzz5rtLo3NT+/15ZlWXfddZd13XXXnfA7utd1k52dbQHWsmXLLMvS73VD+fl9tizv+Z1WS5KXKCsrY926daSkpLjtT0lJYeXKlR6q1dlh69atxMfHk5yczK233sr27dsB2LFjB1lZWW733N/fn4suukj3/AzV5t6uW7eO8vJytzLx8fH06NFD978Oli5dSqtWrejUqRP33nsv2dnZrs90r+smLy8PgIiICEC/1w3l5/e5ijf8TiskeYmcnBycTicxMTFu+2NiYsjKyvJQrZq+/v37M2vWLBYuXMgbb7xBVlYWgwYNIjc313Vfdc/rX23ubVZWFn5+frRs2fKEZaR2hg8fzr///W+++OILnn/+eb755hsuvfRSSktLAd3rurAsi3HjxnHBBRfQo0cPQL/XDaGm+wze8zvtU29Hknphs9nc3luWVW2f1N7w4cNdr3v27MnAgQNp374977zzjmsQoO55w6nLvdX9P30jRoxwve7Rowf9+vUjMTGR+fPnc+ONN57we7rXJ/bAAw/w/fffs2LFimqf6fe6/pzoPnvL77RakrxEVFQUDoejWgLOzs6u9v9apO6Cg4Pp2bMnW7dudT3lpnte/2pzb2NjYykrK+PQoUMnLCN1ExcXR2JiIlu3bgV0r0/X7373O+bNm8eSJUto06aNa79+r+vXie5zTTz1O62Q5CX8/Pzo27cvqampbvtTU1MZNGiQh2p19iktLSU9PZ24uDiSk5OJjY11u+dlZWUsW7ZM9/wM1ebe9u3bF19fX7cymZmZ/PDDD7r/Zyg3N5fdu3cTFxcH6F7XlmVZPPDAA8ydO5cvvviC5ORkt8/1e10/TnWfa+Kx3+l6GwIuZ2z27NmWr6+v9dZbb1mbNm2yxo4dawUHB1s7d+70dNWarD/84Q/W0qVLre3bt1urV6+2rr76ais0NNR1T//yl79Y4eHh1ty5c60NGzZYt912mxUXF2fl5+d7uOber6CgwFq/fr21fv16C7BeeOEFa/369dauXbssy6rdvR0zZozVpk0ba/Hixda3335rXXrppVavXr2siooKT12WVzrZvS4oKLD+8Ic/WCtXrrR27NhhLVmyxBo4cKDVunVr3evT9Jvf/MYKDw+3li5damVmZrq24uJiVxn9Xp+5U91nb/qdVkjyMq+++qqVmJho+fn5WX369HF7JFJO34gRI6y4uDjL19fXio+Pt2688UZr48aNrs8rKyutJ554woqNjbX8/f2tCy+80NqwYYMHa9x0LFmyxAKqbXfddZdlWbW7t0eOHLEeeOABKyIiwgoMDLSuvvpqKyMjwwNX491Odq+Li4utlJQUKzo62vL19bXatm1r3XXXXdXuo+71qdV0jwHrn//8p6uMfq/P3Knuszf9TtuOVlhEREREjqMxSSIiIiI1UEgSERERqYFCkoiIiEgNFJJEREREaqCQJCIiIlIDhSQRERGRGigkiYiIiNRAIUlEpJ4sXboUm83G4cOHPV0VEakHCkkiIiIiNVBIEhEREamBQpKInDUsy2Lq1Km0a9eOwMBAevXqxQcffAAc6wqbP38+vXr1IiAggP79+7Nhwwa3Y3z44Yd0794df39/kpKSeP75590+Ly0t5eGHHyYhIQF/f386duzIW2+95VZm3bp19OvXj6CgIAYNGsTmzZsb9sJFpEEoJInIWePxxx/nn//8JzNmzGDjxo089NBD3HnnnSxbtsxV5o9//CPPPfcc33zzDa1ateLaa6+lvLwcMOHmlltu4dZbb2XDhg1MmjSJP/3pT8ycOdP1/VGjRjF79mxefvll0tPTee211wgJCXGrx8SJE3n++edZu3YtPj4+/OpXv2qU6xeR+qUFbkXkrFBUVERUVBRffPEFAwcOdO2/5557KC4u5r777uOSSy5h9uzZjBgxAoCDBw/Spk0bZs6cyS233MIdd9zBgQMHWLRokev7Dz/8MPPnz2fjxo1s2bKFzp07k5qaytChQ6vVYenSpVxyySUsXryYyy67DIAFCxZw1VVXceTIEQICAhr4LohIfVJLkoicFTZt2kRJSQmXX345ISEhrm3WrFls27bNVe74ABUREUHnzp1JT08HID09ncGDB7sdd/DgwWzduhWn00laWhoOh4OLLrropHU555xzXK/j4uIAyM7OPuNrFJHG5ePpCoiI1IfKykoA5s+fT+vWrd0+8/f3dwtKP2ez2QAzpqnqdZXjG9sDAwNrVRdfX99qx66qn4g0HWpJEpGzQrdu3fD39ycjI4MOHTq4bQkJCa5yq1evdr0+dOgQW7ZsoUuXLq5jrFixwu24K1eupFOnTjgcDnr27EllZaXbGCcROXupJUlEzgqhoaGMHz+ehx56iMrKSi644ALy8/NZuXIlISEhJCYmAjB58mQiIyOJiYlh4sSJREVFcf311wPwhz/8gfPOO4+nnnqKESNGsGrVKl555RWmT58OQFJSEnfddRe/+tWvePnll+nVqxe7du0iOzubW265xVOXLiINRCFJRM4aTz31FK1atWLKlCls376dFi1a0KdPHx577DFXd9df/vIXHnzwQbZu3UqvXr2YN28efn5+APTp04f333+fP//5zzz11FPExcUxefJkRo8e7TrHjBkzeOyxx7j//vvJzc2lbdu2PPbYY564XBFpYHq6TUSahaonzw4dOkSLFi08XR0RaQI0JklERESkBgpJIiIiIjVQd5uIiIhIDdSSJCIiIlIDhSQRERGRGigkiYiIiNRAIUlERESkBgpJIiIiIjVQSBIRERGpgUKSiIiISA0UkkRERERqoJAkIiIiUoP/B2fSqrKlml4+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize Loss over Epochs\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "54095735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Use encoder to compress feature set\n",
    "encoder_layer = auto_encoder.get_layer('sequential_30')\n",
    "compressed_x_train = encoder_layer.predict(x_train)\n",
    "compressed_x_test = encoder_layer.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3d0447c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.129429</td>\n",
       "      <td>0.659867</td>\n",
       "      <td>0.372233</td>\n",
       "      <td>0.481571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203629</td>\n",
       "      <td>0.245352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235153</td>\n",
       "      <td>2.957923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.615705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.536298</td>\n",
       "      <td>2.508671</td>\n",
       "      <td>1.292538</td>\n",
       "      <td>0.371254</td>\n",
       "      <td>0.733047</td>\n",
       "      <td>2.353041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.278037</td>\n",
       "      <td>0.652384</td>\n",
       "      <td>0.347162</td>\n",
       "      <td>0.763701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.239037</td>\n",
       "      <td>0.198944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157370</td>\n",
       "      <td>3.017387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.639920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.340200</td>\n",
       "      <td>2.564614</td>\n",
       "      <td>1.535829</td>\n",
       "      <td>0.364640</td>\n",
       "      <td>0.711831</td>\n",
       "      <td>2.298459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.338092</td>\n",
       "      <td>0.549237</td>\n",
       "      <td>0.230091</td>\n",
       "      <td>0.915651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.207198</td>\n",
       "      <td>0.360410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145847</td>\n",
       "      <td>2.961971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.501976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.411254</td>\n",
       "      <td>2.758990</td>\n",
       "      <td>1.527724</td>\n",
       "      <td>0.286859</td>\n",
       "      <td>0.489885</td>\n",
       "      <td>2.420020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.453497</td>\n",
       "      <td>0.570307</td>\n",
       "      <td>0.234019</td>\n",
       "      <td>1.103108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159045</td>\n",
       "      <td>0.140924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230472</td>\n",
       "      <td>2.829405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.375467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.200684</td>\n",
       "      <td>2.795933</td>\n",
       "      <td>1.390138</td>\n",
       "      <td>0.155520</td>\n",
       "      <td>0.460575</td>\n",
       "      <td>2.401308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.609910</td>\n",
       "      <td>0.610873</td>\n",
       "      <td>0.475947</td>\n",
       "      <td>1.510426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006023</td>\n",
       "      <td>0.087941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449100</td>\n",
       "      <td>2.686879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.415587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.232843</td>\n",
       "      <td>2.953841</td>\n",
       "      <td>0.992162</td>\n",
       "      <td>0.238241</td>\n",
       "      <td>0.642544</td>\n",
       "      <td>2.744876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>1.418223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.417169</td>\n",
       "      <td>0.894491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.122465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.602502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.234043</td>\n",
       "      <td>0.056794</td>\n",
       "      <td>0.909818</td>\n",
       "      <td>1.885588</td>\n",
       "      <td>0.171583</td>\n",
       "      <td>1.137320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>1.410015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.405182</td>\n",
       "      <td>0.885633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.040888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.203109</td>\n",
       "      <td>0.051988</td>\n",
       "      <td>0.999603</td>\n",
       "      <td>1.846804</td>\n",
       "      <td>0.310786</td>\n",
       "      <td>1.118265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>1.404045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.401526</td>\n",
       "      <td>0.581040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.091026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.612194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.569267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.828611</td>\n",
       "      <td>1.671095</td>\n",
       "      <td>0.321171</td>\n",
       "      <td>1.031428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>1.482400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.440743</td>\n",
       "      <td>0.492311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.109247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.767942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.902361</td>\n",
       "      <td>1.613792</td>\n",
       "      <td>0.326046</td>\n",
       "      <td>1.004676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>1.513950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.536425</td>\n",
       "      <td>0.438080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.091367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.552361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.927238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.034124</td>\n",
       "      <td>1.626701</td>\n",
       "      <td>0.429530</td>\n",
       "      <td>0.883739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1994 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0      1.129429   0.659867   0.372233   0.481571        0.0   0.203629   \n",
       "1      1.278037   0.652384   0.347162   0.763701        0.0   0.239037   \n",
       "2      1.338092   0.549237   0.230091   0.915651        0.0   0.207198   \n",
       "3      1.453497   0.570307   0.234019   1.103108        0.0   0.159045   \n",
       "4      1.609910   0.610873   0.475947   1.510426        0.0   0.006023   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1989   1.418223   0.000000   1.417169   0.894491        0.0   0.000000   \n",
       "1990   1.410015   0.000000   1.405182   0.885633        0.0   0.000000   \n",
       "1991   1.404045   0.000000   1.401526   0.581040        0.0   0.000000   \n",
       "1992   1.482400   0.000000   1.440743   0.492311        0.0   0.000000   \n",
       "1993   1.513950   0.000000   1.536425   0.438080        0.0   0.000000   \n",
       "\n",
       "      feature_6  feature_7  feature_8  feature_9  ...  feature_15  feature_16  \\\n",
       "0      0.245352        0.0   0.235153   2.957923  ...         0.0         0.0   \n",
       "1      0.198944        0.0   0.157370   3.017387  ...         0.0         0.0   \n",
       "2      0.360410        0.0   0.145847   2.961971  ...         0.0         0.0   \n",
       "3      0.140924        0.0   0.230472   2.829405  ...         0.0         0.0   \n",
       "4      0.087941        0.0   0.449100   2.686879  ...         0.0         0.0   \n",
       "...         ...        ...        ...        ...  ...         ...         ...   \n",
       "1989   3.122465        0.0   0.000000   0.000000  ...         0.0         0.0   \n",
       "1990   3.040888        0.0   0.000000   0.000000  ...         0.0         0.0   \n",
       "1991   3.091026        0.0   0.000000   0.000000  ...         0.0         0.0   \n",
       "1992   3.109247        0.0   0.000000   0.000000  ...         0.0         0.0   \n",
       "1993   3.091367        0.0   0.000000   0.120122  ...         0.0         0.0   \n",
       "\n",
       "      feature_17  feature_18  feature_19  feature_20  feature_21  feature_22  \\\n",
       "0       1.615705         0.0    1.536298    2.508671    1.292538    0.371254   \n",
       "1       1.639920         0.0    1.340200    2.564614    1.535829    0.364640   \n",
       "2       1.501976         0.0    1.411254    2.758990    1.527724    0.286859   \n",
       "3       1.375467         0.0    1.200684    2.795933    1.390138    0.155520   \n",
       "4       1.415587         0.0    1.232843    2.953841    0.992162    0.238241   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1989    0.602502         0.0    2.234043    0.056794    0.909818    1.885588   \n",
       "1990    0.555224         0.0    2.203109    0.051988    0.999603    1.846804   \n",
       "1991    0.612194         0.0    2.569267    0.000000    0.828611    1.671095   \n",
       "1992    0.544297         0.0    2.767942    0.000000    0.902361    1.613792   \n",
       "1993    0.552361         0.0    2.927238    0.000000    1.034124    1.626701   \n",
       "\n",
       "      feature_23  feature_24  \n",
       "0       0.733047    2.353041  \n",
       "1       0.711831    2.298459  \n",
       "2       0.489885    2.420020  \n",
       "3       0.460575    2.401308  \n",
       "4       0.642544    2.744876  \n",
       "...          ...         ...  \n",
       "1989    0.171583    1.137320  \n",
       "1990    0.310786    1.118265  \n",
       "1991    0.321171    1.031428  \n",
       "1992    0.326046    1.004676  \n",
       "1993    0.429530    0.883739  \n",
       "\n",
       "[1994 rows x 25 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_x_train = pd.DataFrame(compressed_x_train)\n",
    "reduced_x_train = reduced_x_train.add_prefix('feature_')\n",
    "reduced_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c272ccaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.883946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.958386</td>\n",
       "      <td>0.656623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.733975</td>\n",
       "      <td>1.358591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.796669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.158719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.332968</td>\n",
       "      <td>0.656067</td>\n",
       "      <td>1.418490</td>\n",
       "      <td>0.452777</td>\n",
       "      <td>1.437478</td>\n",
       "      <td>3.428514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.988717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.039818</td>\n",
       "      <td>0.449455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.639677</td>\n",
       "      <td>1.652762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.907489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.200513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.933307</td>\n",
       "      <td>0.645944</td>\n",
       "      <td>1.230042</td>\n",
       "      <td>0.317304</td>\n",
       "      <td>1.368100</td>\n",
       "      <td>3.255668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.089873</td>\n",
       "      <td>0.691743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.652891</td>\n",
       "      <td>1.248741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.890294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.014237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.222146</td>\n",
       "      <td>0.579825</td>\n",
       "      <td>1.518593</td>\n",
       "      <td>0.516824</td>\n",
       "      <td>1.435570</td>\n",
       "      <td>3.133197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.077303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.039955</td>\n",
       "      <td>0.596185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447947</td>\n",
       "      <td>1.565864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.985224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.012446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.838722</td>\n",
       "      <td>0.670411</td>\n",
       "      <td>1.323819</td>\n",
       "      <td>0.387159</td>\n",
       "      <td>1.269864</td>\n",
       "      <td>3.140002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.026295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.018371</td>\n",
       "      <td>0.780565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433554</td>\n",
       "      <td>1.400370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.965193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.590205</td>\n",
       "      <td>0.687527</td>\n",
       "      <td>1.508043</td>\n",
       "      <td>0.438106</td>\n",
       "      <td>1.250265</td>\n",
       "      <td>3.125806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>1.484246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.425248</td>\n",
       "      <td>0.595036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.416561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.637459</td>\n",
       "      <td>1.574180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.490906</td>\n",
       "      <td>1.667312</td>\n",
       "      <td>1.612548</td>\n",
       "      <td>1.557061</td>\n",
       "      <td>0.559185</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>1.537713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.437422</td>\n",
       "      <td>0.773136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.392286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.617793</td>\n",
       "      <td>1.676421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.820278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.350427</td>\n",
       "      <td>1.819476</td>\n",
       "      <td>1.651765</td>\n",
       "      <td>1.572475</td>\n",
       "      <td>0.322832</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1.397562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.392630</td>\n",
       "      <td>0.575648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.714412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.762051</td>\n",
       "      <td>1.762808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.716624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.784898</td>\n",
       "      <td>2.073496</td>\n",
       "      <td>1.406416</td>\n",
       "      <td>1.536110</td>\n",
       "      <td>0.027911</td>\n",
       "      <td>0.106460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1.546995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.251007</td>\n",
       "      <td>0.372537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.853937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620853</td>\n",
       "      <td>1.845041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.194513</td>\n",
       "      <td>2.182602</td>\n",
       "      <td>1.305064</td>\n",
       "      <td>1.270736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1.446537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.051504</td>\n",
       "      <td>0.200863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.718912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437314</td>\n",
       "      <td>1.823268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.902940</td>\n",
       "      <td>1.945203</td>\n",
       "      <td>1.555036</td>\n",
       "      <td>0.859223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0     0.883946        0.0   0.958386   0.656623        0.0   0.733975   \n",
       "1     0.988717        0.0   1.039818   0.449455        0.0   0.639677   \n",
       "2     0.985075        0.0   1.089873   0.691743        0.0   0.652891   \n",
       "3     1.077303        0.0   1.039955   0.596185        0.0   0.447947   \n",
       "4     1.026295        0.0   1.018371   0.780565        0.0   0.433554   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "493   1.484246        0.0   1.425248   0.595036        0.0   0.000000   \n",
       "494   1.537713        0.0   1.437422   0.773136        0.0   0.000000   \n",
       "495   1.397562        0.0   1.392630   0.575648        0.0   0.000000   \n",
       "496   1.546995        0.0   1.251007   0.372537        0.0   0.000000   \n",
       "497   1.446537        0.0   1.051504   0.200863        0.0   0.000000   \n",
       "\n",
       "     feature_6  feature_7  feature_8  feature_9  ...  feature_15  feature_16  \\\n",
       "0     1.358591        0.0   0.000000   1.796669  ...         0.0         0.0   \n",
       "1     1.652762        0.0   0.000000   1.907489  ...         0.0         0.0   \n",
       "2     1.248741        0.0   0.000000   1.890294  ...         0.0         0.0   \n",
       "3     1.565864        0.0   0.000000   1.985224  ...         0.0         0.0   \n",
       "4     1.400370        0.0   0.000000   1.965193  ...         0.0         0.0   \n",
       "..         ...        ...        ...        ...  ...         ...         ...   \n",
       "493   1.416561        0.0   0.637459   1.574180  ...         0.0         0.0   \n",
       "494   1.392286        0.0   0.617793   1.676421  ...         0.0         0.0   \n",
       "495   1.714412        0.0   0.762051   1.762808  ...         0.0         0.0   \n",
       "496   1.853937        0.0   0.620853   1.845041  ...         0.0         0.0   \n",
       "497   1.718912        0.0   0.437314   1.823268  ...         0.0         0.0   \n",
       "\n",
       "     feature_17  feature_18  feature_19  feature_20  feature_21  feature_22  \\\n",
       "0      1.158719         0.0    2.332968    0.656067    1.418490    0.452777   \n",
       "1      1.200513         0.0    2.933307    0.645944    1.230042    0.317304   \n",
       "2      1.014237         0.0    2.222146    0.579825    1.518593    0.516824   \n",
       "3      1.012446         0.0    2.838722    0.670411    1.323819    0.387159   \n",
       "4      0.816667         0.0    2.590205    0.687527    1.508043    0.438106   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "493    0.866810         0.0    1.490906    1.667312    1.612548    1.557061   \n",
       "494    0.820278         0.0    1.350427    1.819476    1.651765    1.572475   \n",
       "495    0.716624         0.0    1.784898    2.073496    1.406416    1.536110   \n",
       "496    0.714014         0.0    2.194513    2.182602    1.305064    1.270736   \n",
       "497    0.488416         0.0    1.902940    1.945203    1.555036    0.859223   \n",
       "\n",
       "     feature_23  feature_24  \n",
       "0      1.437478    3.428514  \n",
       "1      1.368100    3.255668  \n",
       "2      1.435570    3.133197  \n",
       "3      1.269864    3.140002  \n",
       "4      1.250265    3.125806  \n",
       "..          ...         ...  \n",
       "493    0.559185    0.000000  \n",
       "494    0.322832    0.000000  \n",
       "495    0.027911    0.106460  \n",
       "496    0.000000    0.166245  \n",
       "497    0.000000    0.000000  \n",
       "\n",
       "[498 rows x 25 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_x_test = pd.DataFrame(compressed_x_test)\n",
    "reduced_x_test = reduced_x_test.add_prefix('feature_')\n",
    "reduced_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3251e09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'compressed_x_train' (ndarray)\n",
      "Stored 'compressed_x_test' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "# Store compressed feature set for use by wGAN-GP\n",
    "%store compressed_x_train\n",
    "%store compressed_x_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wgan-gp",
   "language": "python",
   "name": "wgan-gp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
