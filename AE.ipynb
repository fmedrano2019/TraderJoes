{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6691ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import math\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4843048e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2492, 50)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "data = pd.read_csv('fulldata.csv', index_col = 'Date')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f03f7b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Sentiment Data\n",
    "data = data.drop('vader_polarity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11c1c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read over ARIMA predictions\n",
    "%store -r full_arima_predictions\n",
    "\n",
    "# Increment Indices\n",
    "arima_predictions_list = full_arima_predictions.tolist()\n",
    "arima_predictions_list.append(arima_predictions_list.pop(0))\n",
    "\n",
    "# Append ARIMA predictions to dataframe\n",
    "data['arima'] = arima_predictions_list\n",
    "\n",
    "# Append close to dataframe\n",
    "data['y'] = data['close_aapl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c245f4d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_aapl</th>\n",
       "      <th>high_aapl</th>\n",
       "      <th>low_aapl</th>\n",
       "      <th>close_aapl</th>\n",
       "      <th>volume_aapl</th>\n",
       "      <th>open_googl</th>\n",
       "      <th>high_googl</th>\n",
       "      <th>low_googl</th>\n",
       "      <th>close_googl</th>\n",
       "      <th>volume_googl</th>\n",
       "      <th>...</th>\n",
       "      <th>macd</th>\n",
       "      <th>momentum</th>\n",
       "      <th>rsi_5</th>\n",
       "      <th>rsi_15</th>\n",
       "      <th>rsi_ratio</th>\n",
       "      <th>tr</th>\n",
       "      <th>atr</th>\n",
       "      <th>roc</th>\n",
       "      <th>arima</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5/9/2013</th>\n",
       "      <td>16.421786</td>\n",
       "      <td>16.535714</td>\n",
       "      <td>16.270714</td>\n",
       "      <td>16.313214</td>\n",
       "      <td>398749904</td>\n",
       "      <td>21.792098</td>\n",
       "      <td>22.012812</td>\n",
       "      <td>21.726785</td>\n",
       "      <td>21.808114</td>\n",
       "      <td>87945080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329583</td>\n",
       "      <td>15.313214</td>\n",
       "      <td>66.171526</td>\n",
       "      <td>64.804242</td>\n",
       "      <td>1.021099</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.419158</td>\n",
       "      <td>0.165081</td>\n",
       "      <td>16.313212</td>\n",
       "      <td>16.313214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/10/2013</th>\n",
       "      <td>16.356071</td>\n",
       "      <td>16.418214</td>\n",
       "      <td>16.088572</td>\n",
       "      <td>16.177500</td>\n",
       "      <td>334849928</td>\n",
       "      <td>21.903956</td>\n",
       "      <td>22.034833</td>\n",
       "      <td>21.825130</td>\n",
       "      <td>22.027075</td>\n",
       "      <td>75955060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325128</td>\n",
       "      <td>15.177500</td>\n",
       "      <td>57.572386</td>\n",
       "      <td>61.822287</td>\n",
       "      <td>0.931256</td>\n",
       "      <td>0.329643</td>\n",
       "      <td>0.412934</td>\n",
       "      <td>0.159885</td>\n",
       "      <td>16.191360</td>\n",
       "      <td>16.177500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/13/2013</th>\n",
       "      <td>16.125357</td>\n",
       "      <td>16.353572</td>\n",
       "      <td>16.125000</td>\n",
       "      <td>16.240714</td>\n",
       "      <td>317109240</td>\n",
       "      <td>21.993543</td>\n",
       "      <td>22.083127</td>\n",
       "      <td>21.855684</td>\n",
       "      <td>21.959510</td>\n",
       "      <td>57893080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322504</td>\n",
       "      <td>15.240714</td>\n",
       "      <td>60.556778</td>\n",
       "      <td>62.679325</td>\n",
       "      <td>0.966136</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.404487</td>\n",
       "      <td>0.140643</td>\n",
       "      <td>16.231099</td>\n",
       "      <td>16.240714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/14/2013</th>\n",
       "      <td>16.208928</td>\n",
       "      <td>16.257143</td>\n",
       "      <td>15.791071</td>\n",
       "      <td>15.852143</td>\n",
       "      <td>447115760</td>\n",
       "      <td>21.958759</td>\n",
       "      <td>22.238780</td>\n",
       "      <td>21.949751</td>\n",
       "      <td>22.198992</td>\n",
       "      <td>63190600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288120</td>\n",
       "      <td>14.852143</td>\n",
       "      <td>39.310535</td>\n",
       "      <td>54.606048</td>\n",
       "      <td>0.719893</td>\n",
       "      <td>0.466071</td>\n",
       "      <td>0.379742</td>\n",
       "      <td>0.092901</td>\n",
       "      <td>15.893159</td>\n",
       "      <td>15.852143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/15/2013</th>\n",
       "      <td>15.684286</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.084286</td>\n",
       "      <td>15.316071</td>\n",
       "      <td>741612360</td>\n",
       "      <td>22.409198</td>\n",
       "      <td>22.931701</td>\n",
       "      <td>22.372159</td>\n",
       "      <td>22.919439</td>\n",
       "      <td>159658020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218220</td>\n",
       "      <td>14.316071</td>\n",
       "      <td>24.492002</td>\n",
       "      <td>45.872465</td>\n",
       "      <td>0.533915</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.412962</td>\n",
       "      <td>0.057682</td>\n",
       "      <td>15.359893</td>\n",
       "      <td>15.316071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/27/2023</th>\n",
       "      <td>159.940000</td>\n",
       "      <td>160.770000</td>\n",
       "      <td>157.870000</td>\n",
       "      <td>158.280000</td>\n",
       "      <td>52390266</td>\n",
       "      <td>104.615000</td>\n",
       "      <td>104.760000</td>\n",
       "      <td>101.927300</td>\n",
       "      <td>102.460000</td>\n",
       "      <td>31120864</td>\n",
       "      <td>...</td>\n",
       "      <td>2.923728</td>\n",
       "      <td>157.280000</td>\n",
       "      <td>58.221301</td>\n",
       "      <td>60.577495</td>\n",
       "      <td>0.961104</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>3.498250</td>\n",
       "      <td>0.028928</td>\n",
       "      <td>158.428987</td>\n",
       "      <td>158.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/28/2023</th>\n",
       "      <td>157.970000</td>\n",
       "      <td>158.490000</td>\n",
       "      <td>155.980000</td>\n",
       "      <td>157.650000</td>\n",
       "      <td>45992152</td>\n",
       "      <td>102.440000</td>\n",
       "      <td>102.450000</td>\n",
       "      <td>99.740000</td>\n",
       "      <td>101.030000</td>\n",
       "      <td>32057865</td>\n",
       "      <td>...</td>\n",
       "      <td>2.811818</td>\n",
       "      <td>156.650000</td>\n",
       "      <td>53.185052</td>\n",
       "      <td>59.113390</td>\n",
       "      <td>0.899712</td>\n",
       "      <td>2.510000</td>\n",
       "      <td>3.543964</td>\n",
       "      <td>0.039908</td>\n",
       "      <td>157.627915</td>\n",
       "      <td>157.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/29/2023</th>\n",
       "      <td>159.370000</td>\n",
       "      <td>161.050000</td>\n",
       "      <td>159.350000</td>\n",
       "      <td>160.770000</td>\n",
       "      <td>51305691</td>\n",
       "      <td>102.280000</td>\n",
       "      <td>102.490000</td>\n",
       "      <td>100.650000</td>\n",
       "      <td>101.390000</td>\n",
       "      <td>28779572</td>\n",
       "      <td>...</td>\n",
       "      <td>2.940983</td>\n",
       "      <td>159.770000</td>\n",
       "      <td>69.511345</td>\n",
       "      <td>63.760854</td>\n",
       "      <td>1.090188</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.478964</td>\n",
       "      <td>0.051678</td>\n",
       "      <td>160.714492</td>\n",
       "      <td>160.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/30/2023</th>\n",
       "      <td>161.530000</td>\n",
       "      <td>162.470000</td>\n",
       "      <td>161.271000</td>\n",
       "      <td>162.360000</td>\n",
       "      <td>49501689</td>\n",
       "      <td>100.910000</td>\n",
       "      <td>101.155000</td>\n",
       "      <td>99.780000</td>\n",
       "      <td>100.890000</td>\n",
       "      <td>33086183</td>\n",
       "      <td>...</td>\n",
       "      <td>3.135504</td>\n",
       "      <td>161.360000</td>\n",
       "      <td>75.053359</td>\n",
       "      <td>65.878571</td>\n",
       "      <td>1.139268</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>3.362507</td>\n",
       "      <td>0.078159</td>\n",
       "      <td>162.273604</td>\n",
       "      <td>162.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/31/2023</th>\n",
       "      <td>162.440000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>161.910000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>68749792</td>\n",
       "      <td>101.300000</td>\n",
       "      <td>103.890000</td>\n",
       "      <td>101.040000</td>\n",
       "      <td>103.730000</td>\n",
       "      <td>36863369</td>\n",
       "      <td>...</td>\n",
       "      <td>3.454795</td>\n",
       "      <td>163.900000</td>\n",
       "      <td>81.696912</td>\n",
       "      <td>68.981102</td>\n",
       "      <td>1.184338</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>3.194650</td>\n",
       "      <td>0.110438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2492 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            open_aapl   high_aapl    low_aapl  close_aapl  volume_aapl  \\\n",
       "Date                                                                     \n",
       "5/9/2013    16.421786   16.535714   16.270714   16.313214    398749904   \n",
       "5/10/2013   16.356071   16.418214   16.088572   16.177500    334849928   \n",
       "5/13/2013   16.125357   16.353572   16.125000   16.240714    317109240   \n",
       "5/14/2013   16.208928   16.257143   15.791071   15.852143    447115760   \n",
       "5/15/2013   15.684286   15.750000   15.084286   15.316071    741612360   \n",
       "...               ...         ...         ...         ...          ...   \n",
       "3/27/2023  159.940000  160.770000  157.870000  158.280000     52390266   \n",
       "3/28/2023  157.970000  158.490000  155.980000  157.650000     45992152   \n",
       "3/29/2023  159.370000  161.050000  159.350000  160.770000     51305691   \n",
       "3/30/2023  161.530000  162.470000  161.271000  162.360000     49501689   \n",
       "3/31/2023  162.440000  165.000000  161.910000  164.900000     68749792   \n",
       "\n",
       "           open_googl  high_googl   low_googl  close_googl  volume_googl  ...  \\\n",
       "Date                                                                      ...   \n",
       "5/9/2013    21.792098   22.012812   21.726785    21.808114      87945080  ...   \n",
       "5/10/2013   21.903956   22.034833   21.825130    22.027075      75955060  ...   \n",
       "5/13/2013   21.993543   22.083127   21.855684    21.959510      57893080  ...   \n",
       "5/14/2013   21.958759   22.238780   21.949751    22.198992      63190600  ...   \n",
       "5/15/2013   22.409198   22.931701   22.372159    22.919439     159658020  ...   \n",
       "...               ...         ...         ...          ...           ...  ...   \n",
       "3/27/2023  104.615000  104.760000  101.927300   102.460000      31120864  ...   \n",
       "3/28/2023  102.440000  102.450000   99.740000   101.030000      32057865  ...   \n",
       "3/29/2023  102.280000  102.490000  100.650000   101.390000      28779572  ...   \n",
       "3/30/2023  100.910000  101.155000   99.780000   100.890000      33086183  ...   \n",
       "3/31/2023  101.300000  103.890000  101.040000   103.730000      36863369  ...   \n",
       "\n",
       "               macd    momentum      rsi_5     rsi_15  rsi_ratio        tr  \\\n",
       "Date                                                                         \n",
       "5/9/2013   0.329583   15.313214  66.171526  64.804242   1.021099  0.295000   \n",
       "5/10/2013  0.325128   15.177500  57.572386  61.822287   0.931256  0.329643   \n",
       "5/13/2013  0.322504   15.240714  60.556778  62.679325   0.966136  0.228572   \n",
       "5/14/2013  0.288120   14.852143  39.310535  54.606048   0.719893  0.466071   \n",
       "5/15/2013  0.218220   14.316071  24.492002  45.872465   0.533915  0.767857   \n",
       "...             ...         ...        ...        ...        ...       ...   \n",
       "3/27/2023  2.923728  157.280000  58.221301  60.577495   0.961104  2.900000   \n",
       "3/28/2023  2.811818  156.650000  53.185052  59.113390   0.899712  2.510000   \n",
       "3/29/2023  2.940983  159.770000  69.511345  63.760854   1.090188  3.400000   \n",
       "3/30/2023  3.135504  161.360000  75.053359  65.878571   1.139268  1.700000   \n",
       "3/31/2023  3.454795  163.900000  81.696912  68.981102   1.184338  3.090000   \n",
       "\n",
       "                atr       roc       arima           y  \n",
       "Date                                                   \n",
       "5/9/2013   0.419158  0.165081   16.313212   16.313214  \n",
       "5/10/2013  0.412934  0.159885   16.191360   16.177500  \n",
       "5/13/2013  0.404487  0.140643   16.231099   16.240714  \n",
       "5/14/2013  0.379742  0.092901   15.893159   15.852143  \n",
       "5/15/2013  0.412962  0.057682   15.359893   15.316071  \n",
       "...             ...       ...         ...         ...  \n",
       "3/27/2023  3.498250  0.028928  158.428987  158.280000  \n",
       "3/28/2023  3.543964  0.039908  157.627915  157.650000  \n",
       "3/29/2023  3.478964  0.051678  160.714492  160.770000  \n",
       "3/30/2023  3.362507  0.078159  162.273604  162.360000  \n",
       "3/31/2023  3.194650  0.110438    0.000000  164.900000  \n",
       "\n",
       "[2492 rows x 51 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data preview\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "221080f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2492, 51)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5af3a696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1994"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data to numpy array\n",
    "dataset = data.values\n",
    "\n",
    "# Get training set size 80:20 split\n",
    "training_data_len = math.ceil(len(dataset) * 0.8)\n",
    "training_data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6742431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler for data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7b9ff87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1994, 50)\n",
      "y_train shape: (1994,)\n",
      "\n",
      "x_test shape: (498, 50)\n",
      "y_test shape: (498,)\n"
     ]
    }
   ],
   "source": [
    "# Create training dataset\n",
    "train_data = dataset[0:training_data_len,:]\n",
    "\n",
    "# Split to x_train and y_train\n",
    "x_train = train_data[:,:50]\n",
    "y_train = train_data[:,50]\n",
    "\n",
    "# Create test dataset\n",
    "test_data = dataset[training_data_len:,:]\n",
    "\n",
    "# Split to x_test and y_test\n",
    "x_test = test_data[:,:50]\n",
    "y_test = test_data[:,50]\n",
    "\n",
    "# Show shapes of sets\n",
    "print('x_train shape: ' + str(x_train.shape))\n",
    "print('y_train shape: ' + str(y_train.shape))\n",
    "print()\n",
    "print('x_test shape: ' + str(x_test.shape))\n",
    "print('y_test shape: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66a8e2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01885966, 0.01712881, 0.01868894, ..., 0.03001138, 0.78375968,\n",
       "        0.01733483],\n",
       "       [0.01835269, 0.01623046, 0.01726017, ..., 0.02908139, 0.77392832,\n",
       "        0.01639152],\n",
       "       [0.01657281, 0.01573623, 0.01754592, ..., 0.02781943, 0.73751712,\n",
       "        0.01669916],\n",
       "       ...,\n",
       "       [0.86290998, 0.86872551, 0.87268769, ..., 0.36950964, 0.50650193,\n",
       "        0.87993629],\n",
       "       [0.88697981, 0.88761008, 0.89920129, ..., 0.3486992 , 0.55632543,\n",
       "        0.8986756 ],\n",
       "       [0.8935373 , 0.90787084, 0.90665333, ..., 0.36806892, 0.66708059,\n",
       "        0.91915718]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert training and testing sets to numpy arrays\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Scale data\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "y_train = scaler.fit_transform(y_train.reshape(-1,1))\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "y_test = scaler.fit_transform(y_test.reshape(-1,1))\n",
    "\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58ede46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01885966 0.01712881 0.01868894 ... 0.03001138 0.78375968 0.01733483]\n",
      " [0.01835269 0.01623046 0.01726017 ... 0.02908139 0.77392832 0.01639152]\n",
      " [0.01657281 0.01573623 0.01754592 ... 0.02781943 0.73751712 0.01669916]\n",
      " ...\n",
      " [0.86290998 0.86872551 0.87268769 ... 0.36950964 0.50650193 0.87993629]\n",
      " [0.88697981 0.88761008 0.89920129 ... 0.3486992  0.55632543 0.8986756 ]\n",
      " [0.8935373  0.90787084 0.90665333 ... 0.36806892 0.66708059 0.91915718]]\n",
      "[[0.15739028 0.14082333 0.14735361 ... 0.15673105 0.73666547 0.72379143]\n",
      " [0.15604506 0.17186964 0.17021277 ... 0.17602588 0.72425698 0.73813039]\n",
      " [0.19808307 0.17770154 0.16537718 ... 0.1834807  0.68942875 0.72892185]\n",
      " ...\n",
      " [0.60887843 0.6245283  0.65236504 ... 0.34200967 0.61482211 0.88487621]\n",
      " [0.64519926 0.64888508 0.68614384 ... 0.31817763 0.69149945 0.8934605 ]\n",
      " [0.66050109 0.6922813  0.69737999 ... 0.28382698 0.7849625  0.        ]]\n",
      "[[0.01742606]\n",
      " [0.0163748 ]\n",
      " [0.01686447]\n",
      " ...\n",
      " [0.88179379]\n",
      " [0.90084931]\n",
      " [0.92126041]]\n",
      "[[0.14297772]\n",
      " [0.19682647]\n",
      " [0.1563133 ]\n",
      " [0.1980081 ]\n",
      " [0.19226874]\n",
      " [0.20374747]\n",
      " [0.17454423]\n",
      " [0.18112762]\n",
      " [0.15479406]\n",
      " [0.19496962]\n",
      " [0.20172181]\n",
      " [0.19615125]\n",
      " [0.18247806]\n",
      " [0.18079001]\n",
      " [0.14669142]\n",
      " [0.16492235]\n",
      " [0.08575287]\n",
      " [0.08997299]\n",
      " [0.11765699]\n",
      " [0.12559082]\n",
      " [0.06887238]\n",
      " [0.05300473]\n",
      " [0.        ]\n",
      " [0.03713707]\n",
      " [0.07900068]\n",
      " [0.0590817 ]\n",
      " [0.03511141]\n",
      " [0.03241053]\n",
      " [0.07663741]\n",
      " [0.04490209]\n",
      " [0.07309251]\n",
      " [0.06971641]\n",
      " [0.06887238]\n",
      " [0.04237002]\n",
      " [0.03106009]\n",
      " [0.02548953]\n",
      " [0.03865631]\n",
      " [0.01299797]\n",
      " [0.05266712]\n",
      " [0.05283592]\n",
      " [0.06701553]\n",
      " [0.07359892]\n",
      " [0.05638082]\n",
      " [0.07731263]\n",
      " [0.13014855]\n",
      " [0.11596894]\n",
      " [0.12457799]\n",
      " [0.15226199]\n",
      " [0.12981094]\n",
      " [0.16087103]\n",
      " [0.18923025]\n",
      " [0.18450371]\n",
      " [0.17960837]\n",
      " [0.17454423]\n",
      " [0.20273464]\n",
      " [0.22889939]\n",
      " [0.2395341 ]\n",
      " [0.24476705]\n",
      " [0.29017556]\n",
      " [0.32494936]\n",
      " [0.3679946 ]\n",
      " [0.34554355]\n",
      " [0.37711006]\n",
      " [0.36681296]\n",
      " [0.38605672]\n",
      " [0.44530722]\n",
      " [0.4339973 ]\n",
      " [0.39871708]\n",
      " [0.33220797]\n",
      " [0.39466577]\n",
      " [0.3820054 ]\n",
      " [0.40563808]\n",
      " [0.43534774]\n",
      " [0.44260635]\n",
      " [0.40513167]\n",
      " [0.3749156 ]\n",
      " [0.38605672]\n",
      " [0.38977043]\n",
      " [0.38403106]\n",
      " [0.41509115]\n",
      " [0.40817016]\n",
      " [0.41002701]\n",
      " [0.39449696]\n",
      " [0.39365294]\n",
      " [0.3853815 ]\n",
      " [0.38977043]\n",
      " [0.4409183 ]\n",
      " [0.4444632 ]\n",
      " [0.47856178]\n",
      " [0.46286293]\n",
      " [0.39821067]\n",
      " [0.40395003]\n",
      " [0.42910196]\n",
      " [0.4547603 ]\n",
      " [0.45324105]\n",
      " [0.43197164]\n",
      " [0.41812964]\n",
      " [0.43602296]\n",
      " [0.51232275]\n",
      " [0.49054693]\n",
      " [0.50202566]\n",
      " [0.52126941]\n",
      " [0.53224173]\n",
      " [0.57258609]\n",
      " [0.54591492]\n",
      " [0.52835922]\n",
      " [0.44226874]\n",
      " [0.45205942]\n",
      " [0.42792032]\n",
      " [0.44328157]\n",
      " [0.43923025]\n",
      " [0.39314652]\n",
      " [0.34047941]\n",
      " [0.34875084]\n",
      " [0.38960162]\n",
      " [0.4061445 ]\n",
      " [0.40766374]\n",
      " [0.38149899]\n",
      " [0.32309251]\n",
      " [0.33862255]\n",
      " [0.31617151]\n",
      " [0.33558406]\n",
      " [0.27633356]\n",
      " [0.30958812]\n",
      " [0.32461175]\n",
      " [0.34638758]\n",
      " [0.33980419]\n",
      " [0.33828494]\n",
      " [0.31634031]\n",
      " [0.30621202]\n",
      " [0.3543214 ]\n",
      " [0.37255233]\n",
      " [0.40141796]\n",
      " [0.43872384]\n",
      " [0.44716408]\n",
      " [0.45087779]\n",
      " [0.4375422 ]\n",
      " [0.43669818]\n",
      " [0.44817691]\n",
      " [0.44024308]\n",
      " [0.50303849]\n",
      " [0.45627954]\n",
      " [0.44209993]\n",
      " [0.45999325]\n",
      " [0.48480756]\n",
      " [0.4758609 ]\n",
      " [0.48126266]\n",
      " [0.46708305]\n",
      " [0.47332883]\n",
      " [0.42454423]\n",
      " [0.4237002 ]\n",
      " [0.45948683]\n",
      " [0.45965564]\n",
      " [0.47653612]\n",
      " [0.51856853]\n",
      " [0.59250506]\n",
      " [0.63774477]\n",
      " [0.6456786 ]\n",
      " [0.65226199]\n",
      " [0.66120864]\n",
      " [0.57461175]\n",
      " [0.63251182]\n",
      " [0.71792708]\n",
      " [0.70898042]\n",
      " [0.69193113]\n",
      " [0.65952059]\n",
      " [0.71826469]\n",
      " [0.81718433]\n",
      " [0.88301823]\n",
      " [0.87424038]\n",
      " [0.95678596]\n",
      " [0.89415935]\n",
      " [0.87035787]\n",
      " [0.95425388]\n",
      " [0.83541526]\n",
      " [0.81650912]\n",
      " [0.79304524]\n",
      " [0.84773801]\n",
      " [0.8924713 ]\n",
      " [0.90327481]\n",
      " [0.97164078]\n",
      " [0.95408508]\n",
      " [0.95560432]\n",
      " [0.93568535]\n",
      " [0.92505064]\n",
      " [1.        ]\n",
      " [0.96100608]\n",
      " [0.88031735]\n",
      " [0.83102633]\n",
      " [0.83389602]\n",
      " [0.83423363]\n",
      " [0.88301823]\n",
      " [0.89061445]\n",
      " [0.83423363]\n",
      " [0.84908845]\n",
      " [0.79388926]\n",
      " [0.73362593]\n",
      " [0.70459149]\n",
      " [0.66914247]\n",
      " [0.65580689]\n",
      " [0.62474679]\n",
      " [0.62322755]\n",
      " [0.61529372]\n",
      " [0.80283592]\n",
      " [0.87795409]\n",
      " [0.8750844 ]\n",
      " [0.8958474 ]\n",
      " [0.84621877]\n",
      " [0.83760972]\n",
      " [0.82528697]\n",
      " [0.87879811]\n",
      " [0.90327481]\n",
      " [0.83305199]\n",
      " [0.7743079 ]\n",
      " [0.77835922]\n",
      " [0.84436192]\n",
      " [0.8403106 ]\n",
      " [0.77835922]\n",
      " [0.75168805]\n",
      " [0.7013842 ]\n",
      " [0.62964213]\n",
      " [0.67471303]\n",
      " [0.71033086]\n",
      " [0.71488859]\n",
      " [0.68247806]\n",
      " [0.73919649]\n",
      " [0.73362593]\n",
      " [0.68197164]\n",
      " [0.61664416]\n",
      " [0.58524646]\n",
      " [0.67825793]\n",
      " [0.60347738]\n",
      " [0.53950034]\n",
      " [0.47012154]\n",
      " [0.54557731]\n",
      " [0.6215395 ]\n",
      " [0.6389264 ]\n",
      " [0.69564483]\n",
      " [0.71927752]\n",
      " [0.77734639]\n",
      " [0.80081026]\n",
      " [0.86596894]\n",
      " [0.87694126]\n",
      " [0.89179608]\n",
      " [0.94851452]\n",
      " [0.92842674]\n",
      " [0.8750844 ]\n",
      " [0.87002026]\n",
      " [0.93973666]\n",
      " [0.88268062]\n",
      " [0.82815665]\n",
      " [0.8333896 ]\n",
      " [0.7987846 ]\n",
      " [0.7255233 ]\n",
      " [0.75776502]\n",
      " [0.80401756]\n",
      " [0.71775827]\n",
      " [0.71404456]\n",
      " [0.7533761 ]\n",
      " [0.75050641]\n",
      " [0.73683322]\n",
      " [0.65867657]\n",
      " [0.6770763 ]\n",
      " [0.57444294]\n",
      " [0.57056043]\n",
      " [0.68990547]\n",
      " [0.58879136]\n",
      " [0.59402431]\n",
      " [0.61968265]\n",
      " [0.73008103]\n",
      " [0.57393653]\n",
      " [0.58254558]\n",
      " [0.49442944]\n",
      " [0.53578663]\n",
      " [0.40057394]\n",
      " [0.33406482]\n",
      " [0.41087103]\n",
      " [0.38436867]\n",
      " [0.44682647]\n",
      " [0.30469278]\n",
      " [0.24611749]\n",
      " [0.2501688 ]\n",
      " [0.34334909]\n",
      " [0.29692775]\n",
      " [0.29962863]\n",
      " [0.35465901]\n",
      " [0.45357866]\n",
      " [0.44007427]\n",
      " [0.43787981]\n",
      " [0.48008103]\n",
      " [0.38166779]\n",
      " [0.39449696]\n",
      " [0.43787981]\n",
      " [0.42521945]\n",
      " [0.33541526]\n",
      " [0.24240378]\n",
      " [0.15378123]\n",
      " [0.16863606]\n",
      " [0.21370695]\n",
      " [0.12305874]\n",
      " [0.14837947]\n",
      " [0.22113437]\n",
      " [0.21235652]\n",
      " [0.26164754]\n",
      " [0.31887238]\n",
      " [0.31887238]\n",
      " [0.24763673]\n",
      " [0.2778528 ]\n",
      " [0.23548278]\n",
      " [0.27278866]\n",
      " [0.31718433]\n",
      " [0.3401418 ]\n",
      " [0.39804186]\n",
      " [0.4096894 ]\n",
      " [0.37305874]\n",
      " [0.38977043]\n",
      " [0.38352465]\n",
      " [0.43382849]\n",
      " [0.46252532]\n",
      " [0.41019581]\n",
      " [0.47653612]\n",
      " [0.51097232]\n",
      " [0.54996624]\n",
      " [0.52869683]\n",
      " [0.50945307]\n",
      " [0.48666442]\n",
      " [0.57427414]\n",
      " [0.58372721]\n",
      " [0.67083052]\n",
      " [0.65395003]\n",
      " [0.6286293 ]\n",
      " [0.73193788]\n",
      " [0.72653612]\n",
      " [0.7187711 ]\n",
      " [0.71066847]\n",
      " [0.71151249]\n",
      " [0.78443619]\n",
      " [0.77177583]\n",
      " [0.83271438]\n",
      " [0.85111411]\n",
      " [0.84841323]\n",
      " [0.87407157]\n",
      " [0.86731938]\n",
      " [0.8229237 ]\n",
      " [0.75624578]\n",
      " [0.75050641]\n",
      " [0.75557056]\n",
      " [0.79777178]\n",
      " [0.68956786]\n",
      " [0.65175557]\n",
      " [0.61006077]\n",
      " [0.58153275]\n",
      " [0.59402431]\n",
      " [0.55773126]\n",
      " [0.53612424]\n",
      " [0.56026334]\n",
      " [0.53494261]\n",
      " [0.58406482]\n",
      " [0.68636057]\n",
      " [0.5244767 ]\n",
      " [0.54929102]\n",
      " [0.49966239]\n",
      " [0.47147198]\n",
      " [0.53528022]\n",
      " [0.57613099]\n",
      " [0.52245105]\n",
      " [0.50590817]\n",
      " [0.46691425]\n",
      " [0.47265361]\n",
      " [0.48936529]\n",
      " [0.45695476]\n",
      " [0.33271438]\n",
      " [0.2604659 ]\n",
      " [0.33220797]\n",
      " [0.39382174]\n",
      " [0.39888589]\n",
      " [0.38251182]\n",
      " [0.29237002]\n",
      " [0.29794058]\n",
      " [0.27363268]\n",
      " [0.26282917]\n",
      " [0.34132343]\n",
      " [0.26350439]\n",
      " [0.33153275]\n",
      " [0.3541526 ]\n",
      " [0.35600945]\n",
      " [0.34807562]\n",
      " [0.41357191]\n",
      " [0.45037137]\n",
      " [0.49915598]\n",
      " [0.44868332]\n",
      " [0.37187711]\n",
      " [0.55654963]\n",
      " [0.51603646]\n",
      " [0.47062795]\n",
      " [0.37575962]\n",
      " [0.27194463]\n",
      " [0.26350439]\n",
      " [0.27261985]\n",
      " [0.28241053]\n",
      " [0.20425388]\n",
      " [0.40681972]\n",
      " [0.45459149]\n",
      " [0.4306212 ]\n",
      " [0.46033086]\n",
      " [0.43923025]\n",
      " [0.47180959]\n",
      " [0.48143147]\n",
      " [0.42606347]\n",
      " [0.46269413]\n",
      " [0.47771776]\n",
      " [0.42775152]\n",
      " [0.36208643]\n",
      " [0.31060095]\n",
      " [0.42640108]\n",
      " [0.43112762]\n",
      " [0.42268737]\n",
      " [0.4027684 ]\n",
      " [0.33997299]\n",
      " [0.30671843]\n",
      " [0.33558406]\n",
      " [0.32731263]\n",
      " [0.36664416]\n",
      " [0.38318704]\n",
      " [0.34503714]\n",
      " [0.23176907]\n",
      " [0.19817691]\n",
      " [0.16205267]\n",
      " [0.16087103]\n",
      " [0.21404456]\n",
      " [0.1596894 ]\n",
      " [0.15344362]\n",
      " [0.12255233]\n",
      " [0.05519919]\n",
      " [0.11546253]\n",
      " [0.12086428]\n",
      " [0.03882512]\n",
      " [0.06060095]\n",
      " [0.03798109]\n",
      " [0.11563133]\n",
      " [0.12457799]\n",
      " [0.13436867]\n",
      " [0.18095881]\n",
      " [0.17960837]\n",
      " [0.20239703]\n",
      " [0.222316  ]\n",
      " [0.20999325]\n",
      " [0.21100608]\n",
      " [0.25489534]\n",
      " [0.30958812]\n",
      " [0.33355841]\n",
      " [0.32224848]\n",
      " [0.3576975 ]\n",
      " [0.39095206]\n",
      " [0.34149223]\n",
      " [0.36326806]\n",
      " [0.38251182]\n",
      " [0.47349764]\n",
      " [0.53561783]\n",
      " [0.48885888]\n",
      " [0.5381499 ]\n",
      " [0.49206617]\n",
      " [0.47434166]\n",
      " [0.47670493]\n",
      " [0.52464551]\n",
      " [0.51367319]\n",
      " [0.54962863]\n",
      " [0.52228224]\n",
      " [0.50270088]\n",
      " [0.4339973 ]\n",
      " [0.44125591]\n",
      " [0.44952735]\n",
      " [0.40411884]\n",
      " [0.42454423]\n",
      " [0.41593518]\n",
      " [0.38048616]\n",
      " [0.39061445]\n",
      " [0.47704254]\n",
      " [0.5243079 ]\n",
      " [0.48666442]\n",
      " [0.50810263]\n",
      " [0.46961512]\n",
      " [0.43433491]\n",
      " [0.46758947]\n",
      " [0.5033761 ]\n",
      " [0.51012829]\n",
      " [0.55840648]\n",
      " [0.54405807]\n",
      " [0.58457124]\n",
      " [0.61630655]\n",
      " [0.59182984]\n",
      " [0.61039838]\n",
      " [0.63268062]\n",
      " [0.59942606]\n",
      " [0.58879136]\n",
      " [0.64145847]\n",
      " [0.66829845]\n",
      " [0.71117488]]\n"
     ]
    }
   ],
   "source": [
    "# Train Split Preview\n",
    "print(x_train)\n",
    "print(x_test)\n",
    "\n",
    "# Test Split Preview\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73facdac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "125/125 [==============================] - 4s 8ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.1926 - val_mae: 0.1926\n",
      "Epoch 2/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0594 - mae: 0.0594 - val_loss: 0.1744 - val_mae: 0.1744\n",
      "Epoch 3/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0466 - mae: 0.0466 - val_loss: 0.1555 - val_mae: 0.1555\n",
      "Epoch 4/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0416 - mae: 0.0416 - val_loss: 0.1466 - val_mae: 0.1466\n",
      "Epoch 5/250\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0394 - mae: 0.0394 - val_loss: 0.1394 - val_mae: 0.1394\n",
      "Epoch 6/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0372 - mae: 0.0372 - val_loss: 0.1378 - val_mae: 0.1378\n",
      "Epoch 7/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0342 - mae: 0.0342 - val_loss: 0.1360 - val_mae: 0.1360\n",
      "Epoch 8/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0320 - mae: 0.0320 - val_loss: 0.1310 - val_mae: 0.1310\n",
      "Epoch 9/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0309 - mae: 0.0309 - val_loss: 0.1280 - val_mae: 0.1280\n",
      "Epoch 10/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0298 - mae: 0.0298 - val_loss: 0.1274 - val_mae: 0.1274\n",
      "Epoch 11/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0287 - mae: 0.0287 - val_loss: 0.1223 - val_mae: 0.1223\n",
      "Epoch 12/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0274 - mae: 0.0274 - val_loss: 0.1206 - val_mae: 0.1206\n",
      "Epoch 13/250\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0271 - mae: 0.0271 - val_loss: 0.1198 - val_mae: 0.1198\n",
      "Epoch 14/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0269 - mae: 0.0269 - val_loss: 0.1217 - val_mae: 0.1217\n",
      "Epoch 15/250\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0263 - mae: 0.0263 - val_loss: 0.1187 - val_mae: 0.1187\n",
      "Epoch 16/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0258 - mae: 0.0258 - val_loss: 0.1177 - val_mae: 0.1177\n",
      "Epoch 17/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0255 - mae: 0.0255 - val_loss: 0.1176 - val_mae: 0.1176\n",
      "Epoch 18/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0258 - mae: 0.0258 - val_loss: 0.1191 - val_mae: 0.1191\n",
      "Epoch 19/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0255 - mae: 0.0255 - val_loss: 0.1155 - val_mae: 0.1155\n",
      "Epoch 20/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0249 - mae: 0.0249 - val_loss: 0.1182 - val_mae: 0.1182\n",
      "Epoch 21/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0245 - mae: 0.0245 - val_loss: 0.1186 - val_mae: 0.1186\n",
      "Epoch 22/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0244 - mae: 0.0244 - val_loss: 0.1183 - val_mae: 0.1183\n",
      "Epoch 23/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0242 - mae: 0.0242 - val_loss: 0.1165 - val_mae: 0.1165\n",
      "Epoch 24/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0241 - mae: 0.0241 - val_loss: 0.1178 - val_mae: 0.1178\n",
      "Epoch 25/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0237 - mae: 0.0237 - val_loss: 0.1165 - val_mae: 0.1165\n",
      "Epoch 26/250\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0241 - mae: 0.0241 - val_loss: 0.1164 - val_mae: 0.1164\n",
      "Epoch 27/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0237 - mae: 0.0237 - val_loss: 0.1173 - val_mae: 0.1173\n",
      "Epoch 28/250\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0233 - mae: 0.0233 - val_loss: 0.1147 - val_mae: 0.1147\n",
      "Epoch 29/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0233 - mae: 0.0233 - val_loss: 0.1169 - val_mae: 0.1169\n",
      "Epoch 30/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0233 - mae: 0.0233 - val_loss: 0.1144 - val_mae: 0.1144\n",
      "Epoch 31/250\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0231 - mae: 0.0231 - val_loss: 0.1130 - val_mae: 0.1130\n",
      "Epoch 32/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0228 - mae: 0.0228 - val_loss: 0.1144 - val_mae: 0.1144\n",
      "Epoch 33/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0228 - mae: 0.0228 - val_loss: 0.1153 - val_mae: 0.1153\n",
      "Epoch 34/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0224 - mae: 0.0224 - val_loss: 0.1136 - val_mae: 0.1136\n",
      "Epoch 35/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0221 - mae: 0.0221 - val_loss: 0.1140 - val_mae: 0.1140\n",
      "Epoch 36/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0223 - mae: 0.0223 - val_loss: 0.1133 - val_mae: 0.1133\n",
      "Epoch 37/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0220 - mae: 0.0220 - val_loss: 0.1141 - val_mae: 0.1141\n",
      "Epoch 38/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.1114 - val_mae: 0.1114\n",
      "Epoch 39/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0216 - mae: 0.0216 - val_loss: 0.1099 - val_mae: 0.1099\n",
      "Epoch 40/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0211 - mae: 0.0211 - val_loss: 0.1118 - val_mae: 0.1118\n",
      "Epoch 41/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0213 - mae: 0.0213 - val_loss: 0.1114 - val_mae: 0.1114\n",
      "Epoch 42/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.1120 - val_mae: 0.1120\n",
      "Epoch 43/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0206 - mae: 0.0206 - val_loss: 0.1118 - val_mae: 0.1118\n",
      "Epoch 44/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.1147 - val_mae: 0.1147\n",
      "Epoch 45/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0206 - mae: 0.0206 - val_loss: 0.1105 - val_mae: 0.1105\n",
      "Epoch 46/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.1140 - val_mae: 0.1140\n",
      "Epoch 47/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0199 - mae: 0.0199 - val_loss: 0.1113 - val_mae: 0.1113\n",
      "Epoch 48/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.1113 - val_mae: 0.1113\n",
      "Epoch 49/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.1116 - val_mae: 0.1116\n",
      "Epoch 50/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.1126 - val_mae: 0.1126\n",
      "Epoch 51/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.1108 - val_mae: 0.1108\n",
      "Epoch 52/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.1094 - val_mae: 0.1094\n",
      "Epoch 53/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.1127 - val_mae: 0.1127\n",
      "Epoch 54/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.1132 - val_mae: 0.1132\n",
      "Epoch 55/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.1129 - val_mae: 0.1129\n",
      "Epoch 56/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.1125 - val_mae: 0.1125\n",
      "Epoch 57/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.1107 - val_mae: 0.1107\n",
      "Epoch 58/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.1110 - val_mae: 0.1110\n",
      "Epoch 59/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.1120 - val_mae: 0.1120\n",
      "Epoch 60/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.1115 - val_mae: 0.1115\n",
      "Epoch 61/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.1103 - val_mae: 0.1103\n",
      "Epoch 62/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.1135 - val_mae: 0.1135\n",
      "Epoch 63/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.1115 - val_mae: 0.1115\n",
      "Epoch 64/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.1098 - val_mae: 0.1098\n",
      "Epoch 65/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.1108 - val_mae: 0.1108\n",
      "Epoch 66/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.1103 - val_mae: 0.1103\n",
      "Epoch 67/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.1095 - val_mae: 0.1095\n",
      "Epoch 68/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.1114 - val_mae: 0.1114\n",
      "Epoch 69/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.1107 - val_mae: 0.1107\n",
      "Epoch 70/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.1106 - val_mae: 0.1106\n",
      "Epoch 71/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.1106 - val_mae: 0.1106\n",
      "Epoch 72/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.1093 - val_mae: 0.1093\n",
      "Epoch 73/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.1084 - val_mae: 0.1084\n",
      "Epoch 74/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.1094 - val_mae: 0.1094\n",
      "Epoch 75/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.1101 - val_mae: 0.1101\n",
      "Epoch 76/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.1096 - val_mae: 0.1096\n",
      "Epoch 77/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.1087 - val_mae: 0.1087\n",
      "Epoch 78/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.1085 - val_mae: 0.1085\n",
      "Epoch 79/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.1086 - val_mae: 0.1086\n",
      "Epoch 80/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.1093 - val_mae: 0.1093\n",
      "Epoch 81/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.1090 - val_mae: 0.1090\n",
      "Epoch 82/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.1094 - val_mae: 0.1094\n",
      "Epoch 83/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.1098 - val_mae: 0.1098\n",
      "Epoch 84/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.1089 - val_mae: 0.1089\n",
      "Epoch 85/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.1097 - val_mae: 0.1097\n",
      "Epoch 86/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.1125 - val_mae: 0.1125\n",
      "Epoch 87/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.1095 - val_mae: 0.1095\n",
      "Epoch 88/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.1113 - val_mae: 0.1113\n",
      "Epoch 89/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.1085 - val_mae: 0.1085\n",
      "Epoch 90/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.1093 - val_mae: 0.1093\n",
      "Epoch 91/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.1085 - val_mae: 0.1085\n",
      "Epoch 92/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.1077 - val_mae: 0.1077\n",
      "Epoch 93/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.1076 - val_mae: 0.1076\n",
      "Epoch 94/250\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.1084 - val_mae: 0.1084\n",
      "Epoch 95/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.1098 - val_mae: 0.1098\n",
      "Epoch 96/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.1091 - val_mae: 0.1091\n",
      "Epoch 97/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.1073 - val_mae: 0.1073\n",
      "Epoch 98/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.1083 - val_mae: 0.1083\n",
      "Epoch 99/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.1089 - val_mae: 0.1089\n",
      "Epoch 100/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.1094 - val_mae: 0.1094\n",
      "Epoch 101/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.1096 - val_mae: 0.1096\n",
      "Epoch 102/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.1092 - val_mae: 0.1092\n",
      "Epoch 103/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.1094 - val_mae: 0.1094\n",
      "Epoch 104/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.1094 - val_mae: 0.1094\n",
      "Epoch 105/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.1092 - val_mae: 0.1092\n",
      "Epoch 106/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.1087 - val_mae: 0.1087\n",
      "Epoch 107/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.1097 - val_mae: 0.1097\n",
      "Epoch 108/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.1095 - val_mae: 0.1095\n",
      "Epoch 109/250\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.1108 - val_mae: 0.1108\n",
      "Epoch 110/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.1087 - val_mae: 0.1087\n",
      "Epoch 111/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.1093 - val_mae: 0.1093\n",
      "Epoch 112/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.1077 - val_mae: 0.1077\n",
      "Epoch 113/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.1117 - val_mae: 0.1117\n",
      "Epoch 114/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.1096 - val_mae: 0.1096\n",
      "Epoch 115/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.1083 - val_mae: 0.1083\n",
      "Epoch 116/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.1079 - val_mae: 0.1079\n",
      "Epoch 117/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.1073 - val_mae: 0.1073\n",
      "Epoch 118/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.1081 - val_mae: 0.1081\n",
      "Epoch 119/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.1087 - val_mae: 0.1087\n",
      "Epoch 120/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.1064 - val_mae: 0.1064\n",
      "Epoch 121/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.1049 - val_mae: 0.1049\n",
      "Epoch 122/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.1058 - val_mae: 0.1058\n",
      "Epoch 123/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.1084 - val_mae: 0.1084\n",
      "Epoch 124/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.1053 - val_mae: 0.1053\n",
      "Epoch 125/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.1051 - val_mae: 0.1051\n",
      "Epoch 126/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.1034 - val_mae: 0.1034\n",
      "Epoch 127/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.1061 - val_mae: 0.1061\n",
      "Epoch 128/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.1046 - val_mae: 0.1046\n",
      "Epoch 129/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.1059 - val_mae: 0.1059\n",
      "Epoch 130/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.1084 - val_mae: 0.1084\n",
      "Epoch 131/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.1060 - val_mae: 0.1060\n",
      "Epoch 132/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.1019 - val_mae: 0.1019\n",
      "Epoch 133/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.1033 - val_mae: 0.1033\n",
      "Epoch 134/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.1046 - val_mae: 0.1046\n",
      "Epoch 135/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.1027 - val_mae: 0.1027\n",
      "Epoch 136/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.1026 - val_mae: 0.1026\n",
      "Epoch 137/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.1024 - val_mae: 0.1024\n",
      "Epoch 138/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.1033 - val_mae: 0.1033\n",
      "Epoch 139/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.1042 - val_mae: 0.1042\n",
      "Epoch 140/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.1029 - val_mae: 0.1029\n",
      "Epoch 141/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.1035 - val_mae: 0.1035\n",
      "Epoch 142/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.1032 - val_mae: 0.1032\n",
      "Epoch 143/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.1035 - val_mae: 0.1035\n",
      "Epoch 144/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.1031 - val_mae: 0.1031\n",
      "Epoch 145/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.1049 - val_mae: 0.1049\n",
      "Epoch 146/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.1018 - val_mae: 0.1018\n",
      "Epoch 147/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.1021 - val_mae: 0.1021\n",
      "Epoch 148/250\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.1013 - val_mae: 0.1013\n",
      "Epoch 149/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.1025 - val_mae: 0.1025\n",
      "Epoch 150/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.1000 - val_mae: 0.1000\n",
      "Epoch 151/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.1008 - val_mae: 0.1008\n",
      "Epoch 152/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.1001 - val_mae: 0.1001\n",
      "Epoch 153/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.1010 - val_mae: 0.1010\n",
      "Epoch 154/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.1003 - val_mae: 0.1003\n",
      "Epoch 155/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0985 - val_mae: 0.0985\n",
      "Epoch 156/250\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.1006 - val_mae: 0.1006\n",
      "Epoch 157/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0987 - val_mae: 0.0987\n",
      "Epoch 158/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0988 - val_mae: 0.0988\n",
      "Epoch 159/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.1001 - val_mae: 0.1001\n",
      "Epoch 160/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0985 - val_mae: 0.0985\n",
      "Epoch 161/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0982 - val_mae: 0.0982\n",
      "Epoch 162/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0996 - val_mae: 0.0996\n",
      "Epoch 163/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0981 - val_mae: 0.0981\n",
      "Epoch 164/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0989 - val_mae: 0.0989\n",
      "Epoch 165/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0987 - val_mae: 0.0987\n",
      "Epoch 166/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0972 - val_mae: 0.0972\n",
      "Epoch 167/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0972 - val_mae: 0.0972\n",
      "Epoch 168/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0982 - val_mae: 0.0982\n",
      "Epoch 169/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0982 - val_mae: 0.0982\n",
      "Epoch 170/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0970 - val_mae: 0.0970\n",
      "Epoch 171/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0976 - val_mae: 0.0976\n",
      "Epoch 172/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0968 - val_mae: 0.0968\n",
      "Epoch 173/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0978 - val_mae: 0.0978\n",
      "Epoch 174/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0982 - val_mae: 0.0982\n",
      "Epoch 175/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0963 - val_mae: 0.0963\n",
      "Epoch 176/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0956 - val_mae: 0.0956\n",
      "Epoch 177/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0964 - val_mae: 0.0964\n",
      "Epoch 178/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0965 - val_mae: 0.0965\n",
      "Epoch 179/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0950 - val_mae: 0.0950\n",
      "Epoch 180/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0963 - val_mae: 0.0963\n",
      "Epoch 181/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0960 - val_mae: 0.0960\n",
      "Epoch 182/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0963 - val_mae: 0.0963\n",
      "Epoch 183/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0949 - val_mae: 0.0949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0957 - val_mae: 0.0957\n",
      "Epoch 185/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0945 - val_mae: 0.0945\n",
      "Epoch 186/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0959 - val_mae: 0.0959\n",
      "Epoch 187/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0968 - val_mae: 0.0968\n",
      "Epoch 188/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0968 - val_mae: 0.0968\n",
      "Epoch 189/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0958 - val_mae: 0.0958\n",
      "Epoch 190/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0961 - val_mae: 0.0961\n",
      "Epoch 191/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0958 - val_mae: 0.0958\n",
      "Epoch 192/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0943 - val_mae: 0.0943\n",
      "Epoch 193/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0948 - val_mae: 0.0948\n",
      "Epoch 194/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0954 - val_mae: 0.0954\n",
      "Epoch 195/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0944 - val_mae: 0.0944\n",
      "Epoch 196/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0954 - val_mae: 0.0954\n",
      "Epoch 197/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0952 - val_mae: 0.0952\n",
      "Epoch 198/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0950 - val_mae: 0.0950\n",
      "Epoch 199/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0946 - val_mae: 0.0946\n",
      "Epoch 200/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0979 - val_mae: 0.0979\n",
      "Epoch 201/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0921 - val_mae: 0.0921\n",
      "Epoch 202/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0945 - val_mae: 0.0945\n",
      "Epoch 203/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0928 - val_mae: 0.0928\n",
      "Epoch 204/250\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0959 - val_mae: 0.0959\n",
      "Epoch 205/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0947 - val_mae: 0.0947\n",
      "Epoch 206/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0961 - val_mae: 0.0961\n",
      "Epoch 207/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0962 - val_mae: 0.0962\n",
      "Epoch 208/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0940 - val_mae: 0.0940\n",
      "Epoch 209/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0948 - val_mae: 0.0948\n",
      "Epoch 210/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0956 - val_mae: 0.0956\n",
      "Epoch 211/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0929 - val_mae: 0.0929\n",
      "Epoch 212/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0953 - val_mae: 0.0953\n",
      "Epoch 213/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0952 - val_mae: 0.0952\n",
      "Epoch 214/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0947 - val_mae: 0.0947\n",
      "Epoch 215/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0933 - val_mae: 0.0933\n",
      "Epoch 216/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0951 - val_mae: 0.0951\n",
      "Epoch 217/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0948 - val_mae: 0.0948\n",
      "Epoch 218/250\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0946 - val_mae: 0.0946\n",
      "Epoch 219/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0968 - val_mae: 0.0968\n",
      "Epoch 220/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0972 - val_mae: 0.0972\n",
      "Epoch 221/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0948 - val_mae: 0.0948\n",
      "Epoch 222/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0940 - val_mae: 0.0940\n",
      "Epoch 223/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0944 - val_mae: 0.0944\n",
      "Epoch 224/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0948 - val_mae: 0.0948\n",
      "Epoch 225/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0947 - val_mae: 0.0947\n",
      "Epoch 226/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0952 - val_mae: 0.0952\n",
      "Epoch 227/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0952 - val_mae: 0.0952\n",
      "Epoch 228/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0947 - val_mae: 0.0947\n",
      "Epoch 229/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0926 - val_mae: 0.0926\n",
      "Epoch 230/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0921 - val_mae: 0.0921\n",
      "Epoch 231/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0918 - val_mae: 0.0918\n",
      "Epoch 232/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0932 - val_mae: 0.0932\n",
      "Epoch 233/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0928 - val_mae: 0.0928\n",
      "Epoch 234/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0950 - val_mae: 0.0950\n",
      "Epoch 235/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0945 - val_mae: 0.0945\n",
      "Epoch 236/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0942 - val_mae: 0.0942\n",
      "Epoch 237/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0959 - val_mae: 0.0959\n",
      "Epoch 238/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0936 - val_mae: 0.0936\n",
      "Epoch 239/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0938 - val_mae: 0.0938\n",
      "Epoch 240/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0925 - val_mae: 0.0925\n",
      "Epoch 241/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0947 - val_mae: 0.0947\n",
      "Epoch 242/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0938 - val_mae: 0.0938\n",
      "Epoch 243/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0953 - val_mae: 0.0953\n",
      "Epoch 244/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0949 - val_mae: 0.0949\n",
      "Epoch 245/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0941 - val_mae: 0.0941\n",
      "Epoch 246/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0922 - val_mae: 0.0922\n",
      "Epoch 247/250\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0923 - val_mae: 0.0923\n",
      "Epoch 248/250\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0946 - val_mae: 0.0946\n",
      "Epoch 249/250\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0945 - val_mae: 0.0945\n",
      "Epoch 250/250\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0932 - val_mae: 0.0932\n"
     ]
    }
   ],
   "source": [
    "# Build autoencoder\n",
    "# Code modified from: https://www.analyticsvidhya.com/blog/2021/06/dimensionality-reduction-using-autoencoders-in-python/\n",
    "class AutoEncoders(Model):\n",
    "\n",
    "    # Initializer\n",
    "    def __init__(self, output_units):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Build Encoder down to 10 features\n",
    "        self.encoder = Sequential(\n",
    "            [\n",
    "                Dense(50, activation=\"relu\"),\n",
    "                Dense(37, activation=\"relu\"),\n",
    "                Dense(25, activation=\"relu\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Build Decoder\n",
    "        self.decoder = Sequential(\n",
    "            [\n",
    "                Dense(37, activation=\"relu\"),\n",
    "                Dense(51, activation=\"relu\"),\n",
    "                Dense(output_units, activation=\"sigmoid\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Call Overwrite\n",
    "    def call(self, inputs):\n",
    "        # Encode\n",
    "        encoded = self.encoder(inputs)\n",
    "        \n",
    "        # Decode\n",
    "        decoded = self.decoder(encoded)\n",
    "        \n",
    "        # Return\n",
    "        return decoded\n",
    "    \n",
    "# Autoencoder Usage\n",
    "    # Instantiate Autoencoder\n",
    "auto_encoder = AutoEncoders(50)\n",
    "    \n",
    "    # Prep for training\n",
    "auto_encoder.compile( loss='mae', metrics=['mae'], optimizer='adam')\n",
    "\n",
    "    # Train\n",
    "history = auto_encoder.fit(\n",
    "    x_train, \n",
    "    x_train, \n",
    "    epochs=250, \n",
    "    batch_size=16, \n",
    "    validation_data=(x_test, x_test)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1af6350",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc0efddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize Loss over Epochs\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54095735",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: sequential_30. Existing layers are: ['sequential_6', 'sequential_7'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14268\\1109044867.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Use encoder to compress feature set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mencoder_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauto_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sequential_30'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcompressed_x_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcompressed_x_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mget_layer\u001b[1;34m(self, name, index)\u001b[0m\n\u001b[0;32m   3351\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3352\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3353\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   3354\u001b[0m                 \u001b[1;34mf\"No such layer: {name}. Existing layers are: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3355\u001b[0m                 \u001b[1;34mf\"{list(layer.name for layer in self.layers)}.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No such layer: sequential_30. Existing layers are: ['sequential_6', 'sequential_7']."
     ]
    }
   ],
   "source": [
    "# Use encoder to compress feature set\n",
    "encoder_layer = auto_encoder.get_layer('sequential_30')\n",
    "compressed_x_train = encoder_layer.predict(x_train)\n",
    "compressed_x_test = encoder_layer.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0447c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_x_train = pd.DataFrame(compressed_x_train)\n",
    "reduced_x_train = reduced_x_train.add_prefix('feature_')\n",
    "reduced_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c272ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_x_test = pd.DataFrame(compressed_x_test)\n",
    "reduced_x_test = reduced_x_test.add_prefix('feature_')\n",
    "reduced_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3251e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store compressed feature set for use by wGAN-GP\n",
    "%store compressed_x_train\n",
    "%store compressed_x_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wgan-gp",
   "language": "python",
   "name": "wgan-gp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
